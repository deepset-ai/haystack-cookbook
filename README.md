# üë©üèª‚Äçüç≥ Haystack Cookbook

<div align="center">
  <a href="https://haystack.deepset.ai/"><img src="https://github.com/deepset-ai/haystack/blob/main/docs/img/banner_20.png" alt="Green logo of a stylized white 'H' with the text 'Haystack, by deepset. Haystack 2.0 is live üéâ'¬†Abstract green and yellow diagrams in the background."></a>
</div>

A collection of example notebooks using [Haystack](https://github.com/deepset-ai/haystack) üëá

You can use these examples as guidelines on how to make use of different model providers, vector databases, retrieval techniques and more with Haystack. Most of them showcase a specific, small demo.

To learn more about _how_ to use Haystack, please visit our [Docs](https://docs.haystack.deepset.ai/docs) and official [Tutorials](https://haystack.deepset.ai/tutorials).

For more examples, you may also find our [Blog](https://haystack.deepset.ai/blog) useful.

**Note:** Unless '(Haystack 1.x)' is mentioned in the title, all of these examples use Haystack 2.0 onwards.

| Name | Colab|
| ---- | ---- |
| Speaker Diarization with AssemblyAI | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/using_speaker_diarization_with_assemblyai.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Advance Prompt Customization for Anthropic | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/prompt_customization_for_Anthropic.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Techcrunch News Digest with Local LLMs using TitanML Takeoff | <a href="https://colab.research.google.com/drive/10EralM_8pCJ5nXnGIZYr6atqefmi8r2z?usp=sharing" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Use Gemini Models with Vertex AI| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/vertexai-gemini-examples.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Gradient AI Embedders and Generators for RAG | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/gradient-embeders-and-generators-for-notion-rag.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Mixtral 8x7B with Hugging Face TGI for Web QA | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/mixtral-8x7b-for-web-qa.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Amazon Bedrock and OpenSearch for PDF QA | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/amazon_bedrock_for_documentation_qa.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Use Zephyr 7B Beta with Hugging Face for RAG | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/zephyr-7b-beta-for-rag.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Hacker News RAG with Custom Component | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/hackernews-custom-component-rag.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Use Chroma for RAG and Indexing | <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/chroma-indexing-and-rag-examples.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Using the Jina-embeddings-v2-base-en model in a Haystack RAG pipeline for legal document analsysis| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/jina-embeddings-v2-legal-analysis-rag.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Multilingual RAG from a podcast with Whisper, Qdrant and Mistral| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/multilingual_rag_podcast.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Improve retrieval by embedding meaningful metadata| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/improve-retrieval-by-embedding-metadata.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Information extraction via LLMs (Gorilla OpenFunctions)| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/information-extraction-gorilla.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Information extraction via LLMs (NexusRaven)| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/information_extraction_raven.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Using AstraDB as a data store in your Haystack pipelines| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/astradb_haystack_integration.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Streaming model explorer: compare how different models handle the same prompt.| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/model_explorer_streaming.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Function Calling with OpenAIChatGenerator| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/function_calling_with_OpenAIChatGenerator.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Use the vLLM inference engine in Haystack 2.x| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/vllm_inference_engine.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Build with Google Gemma: chat and RAG| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/gemma_chat_rag.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Optimizing Retrieval with HyDE| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/using_hyde_for_improved_retrieval.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| RAG pipeline using FastEmbed for embeddings generation| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/rag_fastembed.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Cohere for Multilingual QA (Haystack 1.x)| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/haystack-1.x/cohere-for-multilingual-qa.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| GPT-4 and Weaviate for Custom Documentation QA (Haystack 1.x)| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/haystack-1.x/gpt4-weaviate-custom-documentation-qa.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Whisper Transcriber and Weaviate for YouTube video QA (Haystack 1.x)| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/haystack-1.x/whisper-and-weaviate-for-youtube-rag.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|
| Evaluate a RAG pipeline using Ragas-Haystack integration (Haystack 2.x)| <a href="https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/rag_eval_ragas.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>|

## How to Contribute to this repository

If you have an example that uses Haystack, you can add it to this repository by creating a PR. You can also create a PR from Colab by creating a Fork of this repository and selecting "Save a Copy to GitHub". Once you add your example to your fork, you can create a PR onto this repository. 

1. Add your Notebook
2. Give a descriptive name to your file that includes the names of (if applicable) the model providers, databases the technologies you use in your example and/or the task you are completing in the example.
3. Make sure to add a row in the table above üéâ
