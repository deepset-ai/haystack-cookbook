{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ff7ed5-b796-4739-8db4-57ff8c59dd95",
   "metadata": {},
   "source": [
    "# RAG Pipeline with self Deployed NIMs using Haystack\n",
    "\n",
    "This notebook is accompanied by our article on using Nvidia NIMs with Haystack. \n",
    "\n",
    "The code examples below expect NIMs deployments of both LLMs and Retrieval Embedding models. \n",
    "\n",
    "If you do not yet have access to NIMs, you can also make use of models hosted by Nvidia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96de91c-8701-4740-8f1f-f7a4522bb5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install haystack-ai\n",
    "!pip install nvidia-haystack\n",
    "!pip install --upgrade setuptools==67.0\n",
    "!pip install pip install pydantic==1.9.0\n",
    "!pip install pypdf\n",
    "!pip install hayhooks\n",
    "!pip install qdrant-haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bed90b",
   "metadata": {},
   "source": [
    "Below, we are setting the name and URL of our NUM models, as well as where we expect our QdrantDocumentStore to be running. Adjust these according to your setup. \n",
    "\n",
    "You can also find the **ChipNeMo.pdf** file we will be using [here](https://raw.githubusercontent.com/deepset-ai/haystack-cookbook/main/data/rag-with-nims/ChipNeMo.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7deffa36-67ef-4388-a54a-d436249e0b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "import os\n",
    "\n",
    "# LLM NIM\n",
    "llm_nim_model_name = \"meta-llama3-8b-instruct\"\n",
    "llm_nim_base_url = \"http://nims.example.com/llm\"\n",
    "\n",
    "# Embedding NIM\n",
    "\n",
    "embedding_nim_model = \"NV-Embed-QA\"\n",
    "embedding_nim_api_url = \"http://nims.example.com/embedding\"\n",
    "\n",
    "# Qdrant Vector Database\n",
    "qdrant_endpoint = \"http://vectordb.example.com:30030\"\n",
    "\n",
    "# Document sources to index for embeddings\n",
    "\n",
    "document_sources = [\"./data/ChipNeMo.pdf\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca10672-60ee-460f-b8d8-697d8463cd5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.0 Check Deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37420a-47ac-43d6-b662-71ec7f1ae462",
   "metadata": {},
   "source": [
    "### 1.1 LLM NIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be5097b-6f85-4d70-917e-63705af4474b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"meta-llama3-8b-instruct\",\"object\":\"model\",\"created\":1716465695,\"owned_by\":\"system\",\"root\":\"meta-llama3-8b-instruct\",\"parent\":null,\"permission\":[{\"id\":\"modelperm-6f996d60554743beab7b476f09356c6e\",\"object\":\"model_permission\",\"created\":1716465695,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":false,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]}]}"
     ]
    }
   ],
   "source": [
    "! curl '{llm_nim_base_url}/v1/models' -H 'Accept: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e50b63-8a6d-433c-9152-54050c2027d6",
   "metadata": {},
   "source": [
    "### 1.2 Embedding NIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c7d782-8214-40a9-839f-a2c9c0530bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"NV-Embed-QA\",\"created\":0,\"object\":\"model\",\"owned_by\":\"organization-owner\"}]}"
     ]
    }
   ],
   "source": [
    "! curl '{embedding_nim_api_url}/v1/models' -H 'Accept: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3aefd2-7801-44a2-a8d9-58dd4d1e8dd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 Qdrant Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2908943b-b0eb-4648-a6ee-ce861f8f7901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"qdrant - vector search engine\",\"version\":\"1.9.1\",\"commit\":\"97c107f21b8dbd1cb7190ecc732ff38f7cdd248f\"}"
     ]
    }
   ],
   "source": [
    "! curl '{qdrant_endpoint}' -H 'Accept: application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fecd94-8241-48b9-9450-17f41c6a4bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A workaround\n",
    "os.environ[\"NVIDIA_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea8780a-8227-4dc9-b658-d9fdd2f1fe08",
   "metadata": {},
   "source": [
    "## 2.0 Perform Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a8ed26-1e75-492c-8994-8033ca970b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "from haystack_integrations.components.embedders.nvidia import NvidiaDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea0f80f-9e04-46c3-97d2-42fdf3d462cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize document store\n",
    "document_store = QdrantDocumentStore(embedding_dim=1024, url=qdrant_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94814597-3541-4f7c-b2ad-665e7041d289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "converter = PyPDFToDocument()\n",
    "\n",
    "cleaner = DocumentCleaner()\n",
    "\n",
    "splitter = DocumentSplitter(split_by='word', split_length=100)\n",
    "\n",
    "# initialize NvidiaDocumentEmbedder with the self-hosted Embedding NIM URL\n",
    "embedder = NvidiaDocumentEmbedder(\n",
    "    model=embedding_nim_model,\n",
    "    api_url=f\"{embedding_nim_api_url}/v1\"\n",
    ")\n",
    "\n",
    "writer = DocumentWriter(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985aa203-c093-40d9-863e-c166cce46b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f267972b340>\n",
       "ðŸš… Components\n",
       "  - converter: PyPDFToDocument\n",
       "  - cleaner: DocumentCleaner\n",
       "  - splitter: DocumentSplitter\n",
       "  - embedder: NvidiaDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - converter.documents -> cleaner.documents (List[Document])\n",
       "  - cleaner.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> embedder.documents (List[Document])\n",
       "  - embedder.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline\n",
    "indexing = Pipeline()\n",
    "indexing.add_component(\"converter\", converter)\n",
    "indexing.add_component(\"cleaner\", cleaner)\n",
    "indexing.add_component(\"splitter\", splitter)\n",
    "indexing.add_component(\"embedder\", embedder)\n",
    "indexing.add_component(\"writer\", writer)\n",
    "\n",
    "indexing.connect(\"converter\", \"cleaner\")\n",
    "indexing.connect(\"cleaner\", \"splitter\")\n",
    "indexing.connect(\"splitter\", \"embedder\")\n",
    "indexing.connect(\"embedder\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8317d18c-7ce0-4315-ab03-d97871fafe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 15.85it/s]\n",
      "200it [00:00, 1293.90it/s]                        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedder': {'meta': {'usage': {'prompt_tokens': 0, 'total_tokens': 0}}},\n",
       " 'writer': {'documents_written': 108}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings\n",
    "indexing.run({\"converter\": {\"sources\": document_sources}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094e729-c39f-490f-a44a-0973e11511db",
   "metadata": {},
   "source": [
    "### 2.0.1 Check Embeddings in the Database\n",
    "\n",
    "http://vectordb.example.com:30030/dashboard\n",
    "\n",
    "![](/images/embeddings-1.png)\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/deepset-ai/haystack-cookbook/main/data/rag-with-nims/embeddings-1.png\"></center>\n",
    "<center><img src=\"https://raw.githubusercontent.com/deepset-ai/haystack-cookbook/main/data/rag-with-nims/embeddings-2.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7c3d0-c83c-4bca-a893-7f7941a3db1b",
   "metadata": {},
   "source": [
    "## Create RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc452a81-537d-4bc9-8fa4-56ebb0fa216f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from haystack import Pipeline\n",
    "from haystack.utils.auth import Secret\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack_integrations.components.embedders.nvidia import NvidiaTextEmbedder\n",
    "from haystack_integrations.components.generators.nvidia import NvidiaGenerator\n",
    "from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2202533e-1668-4221-bc39-eadc133350be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize NvidiaTextEmbedder with the self-hosted Embedding NIM URL, alternatively, \n",
    "embedder = NvidiaTextEmbedder(\n",
    "    model=embedding_nim_model,\n",
    "    api_url=f\"{embedding_nim_api_url}/v1\"\n",
    ")\n",
    "\n",
    "# initialize NvidiaGenerator with the self-hosted LLM NIM URL\n",
    "generator = NvidiaGenerator(\n",
    "    model=llm_nim_model_name,\n",
    "    api_url=f\"{llm_nim_base_url}/v1\",\n",
    "    model_arguments={\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.7,\n",
    "        \"max_tokens\": 2048,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0096c24e-ec66-4fc0-b032-7660a7c5c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = QdrantEmbeddingRetriever(document_store=document_store)\n",
    "\n",
    "prompt = \"\"\"Answer the question given the context.\n",
    "Question: {{ query }}\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "Answer:\"\"\"\n",
    "prompt_builder = PromptBuilder(template=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1d8554-bcd1-43df-9718-5718f077e6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f267956e130>\n",
       "ðŸš… Components\n",
       "  - embedder: NvidiaTextEmbedder\n",
       "  - retriever: QdrantEmbeddingRetriever\n",
       "  - prompt: PromptBuilder\n",
       "  - generator: NvidiaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt.documents (List[Document])\n",
       "  - prompt.prompt -> generator.prompt (str)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create RAG Pipeline\n",
    "rag = Pipeline()\n",
    "rag.add_component(\"embedder\", embedder)\n",
    "rag.add_component(\"retriever\", retriever)\n",
    "rag.add_component(\"prompt\", prompt_builder)\n",
    "rag.add_component(\"generator\", generator)\n",
    "\n",
    "rag.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag.connect(\"retriever.documents\", \"prompt.documents\")\n",
    "rag.connect(\"prompt\", \"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5363e9b-4ba9-4ac4-a304-cd13fe99884f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChipNeMo is a domain-adapted large language model (LLM) designed for chip design, which aims to explore the applications of LLMs for industrial chip design. It is developed by reusing public training data from other language models, with the intention of preserving general knowledge and natural language capabilities during domain adaptation. The model is trained using a combination of natural language and code datasets, including Wikipedia data and GitHub data, and is evaluated on various benchmarks, including multiple-choice questions, code generation, and human evaluation. ChipNeMo implements multiple domain adaptation techniques, including pre-training, domain adaptation, and fine-tuning, to adapt the LLM to the chip design domain. The model is capable of understanding internal HW designs and explaining complex design topics, generating EDA scripts, and summarizing and analyzing bugs.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG pipeline\n",
    "question = \"Describe chipnemo in detail?\"\n",
    "result = rag.run(\n",
    "    {\n",
    "        \"embedder\": {\"text\": question},\n",
    "        \"prompt\": {\"query\": question},\n",
    "    }, include_outputs_from=[\"prompt\"]\n",
    ")\n",
    "print(result[\"generator\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
