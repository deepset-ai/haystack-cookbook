{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7RLf9gpEoN"
      },
      "source": [
        "# Hybrid Retrieval: BM42 + Dense Retrieval\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/hybrid_retrieval_bm42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" width=\"200\"/></a>\n",
        "\n",
        "\n",
        "<img src=\"https://qdrant.tech/articles_data/bm42/preview/title.webp\" width=\"800\" style=\"display:inline;\"/>\n",
        "\n",
        "In this notebook, we will see how to create Hybrid Retrieval pipelines, combining BM42 (a new Sparse embedding Retrieval approach) and Dense embedding Retrieval.\n",
        "\n",
        "We will use the Qdrant Document Store and Fastembed Embedders.\n",
        "\n",
        "âš ï¸ Recent evaluations have raised questions about the validity of BM42. Future developments may address these concerns. Please keep this in mind while reviewing the content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "JB15A4Q0_2Ci"
      },
      "source": [
        ">[Hybrid Retrieval: BM42 + Dense Retrieval](#scrollTo=cb7RLf9gpEoN)\n",
        "\n",
        ">>[Why BM42?](#scrollTo=I2ATFcgVpTWc)\n",
        "\n",
        ">>[Install dependencies](#scrollTo=LQ-L4Gf2Hfci)\n",
        "\n",
        ">>[Hybrid Retrieval](#scrollTo=9RHRrrQh3wqL)\n",
        "\n",
        ">>>[Indexing](#scrollTo=XxKy73D1wPhH)\n",
        "\n",
        ">>>>[Create a Qdrant Document Store](#scrollTo=8pw_uDcZwdDb)\n",
        "\n",
        ">>>>[Download Wikipedia pages and create raw documents](#scrollTo=x8Bpy1ri_Ipx)\n",
        "\n",
        ">>>>[Indexing pipeline](#scrollTo=DLiNhYKV_g8u)\n",
        "\n",
        ">>>>[Let's index our documents!](#scrollTo=hmLUyhjZyfWv)\n",
        "\n",
        ">>>[Retrieval](#scrollTo=AZFoiFczyvBx)\n",
        "\n",
        ">>>>[Retrieval pipeline](#scrollTo=L-mUxbqn3l63)\n",
        "\n",
        ">>>>[Try the retrieval pipeline](#scrollTo=sQnk_qCW890T)\n",
        "\n",
        ">>[ğŸ“š Resources](#scrollTo=5mHu_jbeFcyQ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2ATFcgVpTWc"
      },
      "source": [
        "## Why BM42?\n",
        "\n",
        "[Qdrant introduced BM42](https://qdrant.tech/articles/bm42/), an algorithm designed to replace BM25 in hybrid RAG pipelines (dense + sparse retrieval).\n",
        "\n",
        "They found that BM25, while relevant for a long time, has some limitations in common RAG scenarios.\n",
        "\n",
        "Let's first take a look at BM25 and SPLADE to understand the motivation and the inspiration for BM42.\n",
        "\n",
        "**BM25**\n",
        "\\begin{equation}\n",
        "\\text{score}(D,Q) = \\sum_{i=1}^{N} \\text{IDF}(q_i) \\times \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot \\left(1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}}\\right)}\\\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "BM25 is an evolution of TF-IDF and has two components:\n",
        "- Inverse Document Frequency = term importance within a collection\n",
        "- a component incorporating Term Frequency = term importance within a document\n",
        "\n",
        "Qdrant folks observed that the TF component relies on document statistics, which only makes sense for longer texts.\n",
        "This is not the case with common RAG pipelines, where documents are short.\n",
        "\n",
        "**SPLADE**\n",
        "\n",
        "Another interesting approach is SPLADE, which uses a BERT-based model to create a bag-of-words representation of the text.\n",
        "While it generally performs better than BM25, it has some drawbacks:\n",
        "- tokenization issues with out-of-vocabulary words\n",
        "- adaptation to new domains requires fine-tuning\n",
        "- computationally heavy\n",
        "\n",
        "*For using SPLADE with Haystack, see [this notebook](https://github.com/deepset-ai/haystack-cookbook/blob/main/notebooks/sparse_embedding_retrieval.ipynb).*\n",
        "\n",
        "**BM42**\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{score}(D,Q) = \\sum_{i=1}^{N} \\text{IDF}(q_i) \\times \\text{Attention}(\\text{CLS}, q_i)\n",
        "\\end{equation}\n",
        "\n",
        "Taking inspiration from SPLADE, the Qdrant team developed BM42 to improve BM25.\n",
        "\n",
        "IDF works well, so they kept it.\n",
        "\n",
        "But how to quantify term importance within a document?\n",
        "\n",
        "The attention matrix of Transformer models comes to our aid:\n",
        "we can the use attention row for the [CLS] token!\n",
        "\n",
        "To fix tokenization issues, BM42 merges subwords and sums their attention weights.\n",
        "\n",
        "In their implementation, Qdrant team used all-MiniLM-L6-v2 model, but this technique can work with any Transformer, no fine-tuning needed.\n",
        "\n",
        "\n",
        "âš ï¸ Recent evaluations have raised questions about the validity of BM42. Future developments may address these concerns. Please keep this in mind while reviewing the content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ-L4Gf2Hfci"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tnSq1XK_ovZV",
        "outputId": "c3ef26d6-457a-4a6b-f739-42065d2fe203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastembed-haystack\n",
            "  Downloading fastembed_haystack-1.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting qdrant-haystack\n",
            "  Downloading qdrant_haystack-4.1.0-py3-none-any.whl (21 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastembed>=0.2.5 (from fastembed-haystack)\n",
            "  Downloading fastembed-0.3.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting haystack-ai>=2.0.1 (from fastembed-haystack)\n",
            "  Downloading haystack_ai-2.2.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m345.2/345.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qdrant-client>=1.10.0 (from qdrant-haystack)\n",
            "  Downloading qdrant_client-1.10.0-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Collecting PyStemmer<3.0.0,>=2.2.0 (from fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading PyStemmer-2.2.0.1.tar.gz (303 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.0/303.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3<5.0,>=4.0 (from fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx<2.0.0,>=1.15.0 (from fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<2.0.0,>=1.17.0 (from fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow<11.0.0,>=10.3.0 (from fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from fastembed>=0.2.5->fastembed-haystack) (2.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.0.1->fastembed-haystack) (3.1.4)\n",
            "Collecting lazy-imports (from haystack-ai>=2.0.1->fastembed-haystack)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.0.1->fastembed-haystack) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.0.1->fastembed-haystack) (3.3)\n",
            "Collecting openai>=1.1.0 (from haystack-ai>=2.0.1->fastembed-haystack)\n",
            "  Downloading openai-1.35.9-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.0.1->fastembed-haystack) (2.0.3)\n",
            "Collecting posthog (from haystack-ai>=2.0.1->fastembed-haystack)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.0.1->fastembed-haystack) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.0.1->fastembed-haystack) (8.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.0.1->fastembed-haystack) (4.12.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client>=1.10.0->qdrant-haystack) (1.64.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[http2]>=0.20.0 (from qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker<3.0.0,>=2.7.0 (from qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client>=1.10.0->qdrant-haystack) (2.7.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client>=1.10.0->qdrant-haystack) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.10.0->qdrant-haystack) (67.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack) (1.3.1)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.5->fastembed-haystack) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.5->fastembed-haystack) (1.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->haystack-ai>=2.0.1->fastembed-haystack) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client>=1.10.0->qdrant-haystack) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client>=1.10.0->qdrant-haystack) (2.18.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai>=2.0.1->fastembed-haystack) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai>=2.0.1->fastembed-haystack) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai>=2.0.1->fastembed-haystack) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->haystack-ai>=2.0.1->fastembed-haystack) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai>=2.0.1->fastembed-haystack)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai>=2.0.1->fastembed-haystack)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack) (1.2.1)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.10.0->qdrant-haystack)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.5->fastembed-haystack)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.5->fastembed-haystack) (1.3.0)\n",
            "Building wheels for collected packages: wikipedia, PyStemmer\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=b2f144474f00297940804c8757269777c76a7568ea062a8733fff660a1a60855\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "  Building wheel for PyStemmer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyStemmer: filename=PyStemmer-2.2.0.1-cp310-cp310-linux_x86_64.whl size=579704 sha256=4d4daf6acaa66bb28c6f8a7d135de7659c0b163a771151421d25781cdda24889\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/7d/2c/a7ebb8319e01acc5306fa1f8558bf24063d6cec2c02de330c9\n",
            "Successfully built wikipedia PyStemmer\n",
            "Installing collected packages: PyStemmer, monotonic, mmh3, protobuf, portalocker, pillow, loguru, lazy-imports, hyperframe, humanfriendly, hpack, h11, backoff, wikipedia, posthog, onnx, httpcore, h2, grpcio-tools, coloredlogs, onnxruntime, httpx, transformers, openai, fastembed, qdrant-client, haystack-ai, qdrant-haystack, fastembed-haystack\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-api-core 2.16.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.57.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigtable 2.24.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyStemmer-2.2.0.1 backoff-2.2.1 coloredlogs-15.0.1 fastembed-0.3.1 fastembed-haystack-1.2.0 grpcio-tools-1.64.1 h11-0.14.0 h2-4.1.0 haystack-ai-2.2.3 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 humanfriendly-10.0 hyperframe-6.0.1 lazy-imports-0.3.1 loguru-0.7.2 mmh3-4.1.0 monotonic-1.6 onnx-1.16.1 onnxruntime-1.18.1 openai-1.35.9 pillow-10.4.0 portalocker-2.10.0 posthog-3.5.0 protobuf-5.27.2 qdrant-client-1.10.0 qdrant-haystack-4.1.0 transformers-4.42.3 wikipedia-1.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "8671cdda3a8a40aca1d7b50e7af27a30",
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U fastembed-haystack qdrant-haystack wikipedia transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RHRrrQh3wqL"
      },
      "source": [
        "## Hybrid Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxKy73D1wPhH"
      },
      "source": [
        "### Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pw_uDcZwdDb"
      },
      "source": [
        "#### Create a Qdrant Document Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eAKP9icf1Inj"
      },
      "outputs": [],
      "source": [
        "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
        "\n",
        "document_store = QdrantDocumentStore(\n",
        "    \":memory:\",\n",
        "    recreate_index=True,\n",
        "    embedding_dim=384,\n",
        "    return_embedding=True,\n",
        "    use_sparse_embeddings=True,  # set this parameter to True, otherwise the collection schema won't allow to store sparse vectors\n",
        "    sparse_idf=True  # required for BM42, allows streaming updates of the sparse embeddings while keeping the IDF calculation up-to-date\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8Bpy1ri_Ipx"
      },
      "source": [
        "#### Download Wikipedia pages and create raw documents\n",
        "\n",
        "We download a few Wikipedia pages about animals and create Haystack documents from them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7FpCSSnUzuuP"
      },
      "outputs": [],
      "source": [
        "nice_animals= [\"Capybara\", \"Dolphin\", \"Orca\", \"Walrus\"]\n",
        "\n",
        "import wikipedia\n",
        "from haystack.dataclasses import Document\n",
        "\n",
        "raw_docs=[]\n",
        "for title in nice_animals:\n",
        "    page = wikipedia.page(title=title, auto_suggest=False)\n",
        "    doc = Document(content=page.content, meta={\"title\": page.title, \"url\":page.url})\n",
        "    raw_docs.append(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLiNhYKV_g8u"
      },
      "source": [
        "#### Indexing pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO4GvIkEGoJE"
      },
      "source": [
        "Our indexing pipeline includes both a Sparse Document Embedder (based on BM42) and a Dense Document Embedder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a1taDmfx1HCM"
      },
      "outputs": [],
      "source": [
        "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.document_stores.types import DuplicatePolicy\n",
        "from haystack import Pipeline\n",
        "from haystack_integrations.components.embedders.fastembed import FastembedSparseDocumentEmbedder, FastembedDocumentEmbedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs-oOLF1Y7PB",
        "outputId": "f5e0e3bb-52ff-4e27-f700-b31a911664aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fb6bc33a2f0>\n",
              "ğŸš… Components\n",
              "  - cleaner: DocumentCleaner\n",
              "  - splitter: DocumentSplitter\n",
              "  - sparse_doc_embedder: FastembedSparseDocumentEmbedder\n",
              "  - dense_doc_embedder: FastembedDocumentEmbedder\n",
              "  - writer: DocumentWriter\n",
              "ğŸ›¤ï¸ Connections\n",
              "  - cleaner.documents -> splitter.documents (List[Document])\n",
              "  - splitter.documents -> sparse_doc_embedder.documents (List[Document])\n",
              "  - sparse_doc_embedder.documents -> dense_doc_embedder.documents (List[Document])\n",
              "  - dense_doc_embedder.documents -> writer.documents (List[Document])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hybrid_indexing = Pipeline()\n",
        "hybrid_indexing.add_component(\"cleaner\", DocumentCleaner())\n",
        "hybrid_indexing.add_component(\"splitter\", DocumentSplitter(split_by='sentence', split_length=4))\n",
        "hybrid_indexing.add_component(\"sparse_doc_embedder\", FastembedSparseDocumentEmbedder(model=\"Qdrant/bm42-all-minilm-l6-v2-attentions\", meta_fields_to_embed=[\"title\"]))\n",
        "hybrid_indexing.add_component(\"dense_doc_embedder\", FastembedDocumentEmbedder(model=\"BAAI/bge-small-en-v1.5\", meta_fields_to_embed=[\"title\"]))\n",
        "hybrid_indexing.add_component(\"writer\", DocumentWriter(document_store=document_store, policy=DuplicatePolicy.OVERWRITE))\n",
        "\n",
        "hybrid_indexing.connect(\"cleaner\", \"splitter\")\n",
        "hybrid_indexing.connect(\"splitter\", \"sparse_doc_embedder\")\n",
        "hybrid_indexing.connect(\"sparse_doc_embedder\", \"dense_doc_embedder\")\n",
        "hybrid_indexing.connect(\"dense_doc_embedder\", \"writer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmLUyhjZyfWv"
      },
      "source": [
        "#### Let's index our documents!\n",
        "âš ï¸ If you are running this notebook on Google Colab, please note that Google Colab only provides 2 CPU cores, so the embedding generation with Fastembed could be not as fast as it can be on a standard machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyBwOzM-9Tqm",
        "outputId": "b49c2cba-28a9-432f-ccfe-7cb26724f275"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating sparse embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:27<00:00, 12.52it/s]\n",
            "Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [01:23<00:00,  4.07it/s]\n",
            "400it [00:00, 1179.66it/s]                         \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'writer': {'documents_written': 340}}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hybrid_indexing.run({\"documents\":raw_docs})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMB-AxGwyx1c",
        "outputId": "a3269ef5-9a91-4587-f639-899dbe90b6d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "340"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_store.count_documents()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZFoiFczyvBx"
      },
      "source": [
        "### Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mUxbqn3l63"
      },
      "source": [
        "#### Retrieval pipeline\n",
        "\n",
        "As already mentioned, BM42 is designed to perform best in Hybrid Retrieval (and Hybrid RAG) pipelines.\n",
        "\n",
        "- `FastembedSparseTextEmbedder`: transforms the query into a sparse embedding\n",
        "- `FastembedTextEmbedder`: transforms the query into a dense embedding\n",
        "- `QdrantHybridRetriever`: looks for relevant documents, based on the similarity of both the embeddings\n",
        "\n",
        "Qdrant Hybrid Retriever compares dense and sparse query and document embeddings and retrieves the most relevant documents, merging the scores with Reciprocal Rank Fusion.\n",
        "\n",
        "If you want to customize the fusion behavior more, see Hybrid Retrieval Pipelines ([tutorial](https://haystack.deepset.ai/tutorials/33_hybrid_retrieval))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTlEGit3_XFk",
        "outputId": "c598858a-a611-4c1d-cda3-20509a9877f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fb6bc33ae30>\n",
              "ğŸš… Components\n",
              "  - sparse_text_embedder: FastembedSparseTextEmbedder\n",
              "  - dense_text_embedder: FastembedTextEmbedder\n",
              "  - retriever: QdrantHybridRetriever\n",
              "ğŸ›¤ï¸ Connections\n",
              "  - sparse_text_embedder.sparse_embedding -> retriever.query_sparse_embedding (SparseEmbedding)\n",
              "  - dense_text_embedder.embedding -> retriever.query_embedding (List[float])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from haystack_integrations.components.retrievers.qdrant import QdrantHybridRetriever\n",
        "from haystack_integrations.components.embedders.fastembed import FastembedTextEmbedder, FastembedSparseTextEmbedder\n",
        "\n",
        "\n",
        "hybrid_query = Pipeline()\n",
        "hybrid_query.add_component(\"sparse_text_embedder\", FastembedSparseTextEmbedder(model=\"Qdrant/bm42-all-minilm-l6-v2-attentions\"))\n",
        "hybrid_query.add_component(\"dense_text_embedder\", FastembedTextEmbedder(model=\"BAAI/bge-small-en-v1.5\", prefix=\"Represent this sentence for searching relevant passages: \"))\n",
        "hybrid_query.add_component(\"retriever\", QdrantHybridRetriever(document_store=document_store, top_k=5))\n",
        "\n",
        "hybrid_query.connect(\"sparse_text_embedder.sparse_embedding\", \"retriever.query_sparse_embedding\")\n",
        "hybrid_query.connect(\"dense_text_embedder.embedding\", \"retriever.query_embedding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQnk_qCW890T"
      },
      "source": [
        "#### Try the retrieval pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpUwlxIj6O0R",
        "outputId": "c4ff0b37-bf61-4190-b868-fd4b94d4617e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating sparse embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 82.10it/s]\n",
            "Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.75it/s]\n"
          ]
        }
      ],
      "source": [
        "question = \"Who eats fish?\"\n",
        "\n",
        "results = hybrid_query.run(\n",
        "    {\"dense_text_embedder\": {\"text\": question},\n",
        "     \"sparse_text_embedder\": {\"text\": question}}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "rcFsJVoqQ4zQ",
        "outputId": "ee110953-12b3-4a61-dbf8-de23819198e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: 370071638e221257cf77702716695626d9b1b4dfe4212b4a10e255434bfeb08b\n",
              "Orca\n",
              " Some populations in the Norwegian and Greenland sea specialize in herring and follow that fish's autumnal \n",
              "migration to the Norwegian coast. Salmon account for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>% of northeast Pacific residents' diet, including <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65</span>% of \n",
              "large, fatty Chinook. Chum salmon are also eaten, but smaller sockeye and pink salmon are not a significant food \n",
              "item. Depletion of specific prey species in an area is, therefore, cause for concern for local populations, despite\n",
              "the high diversity of prey.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: 370071638e221257cf77702716695626d9b1b4dfe4212b4a10e255434bfeb08b\n",
              "Orca\n",
              " Some populations in the Norwegian and Greenland sea specialize in herring and follow that fish's autumnal \n",
              "migration to the Norwegian coast. Salmon account for \u001b[1;36m96\u001b[0m% of northeast Pacific residents' diet, including \u001b[1;36m65\u001b[0m% of \n",
              "large, fatty Chinook. Chum salmon are also eaten, but smaller sockeye and pink salmon are not a significant food \n",
              "item. Depletion of specific prey species in an area is, therefore, cause for concern for local populations, despite\n",
              "the high diversity of prey.\n",
              "score: \u001b[1;36m0.5\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: 1ed8f49561630f10202b55c8c7619a32cd9f6a11675cbb56c64a578826e488ef\n",
              "Orca\n",
              "; Ellis, Graeme M. <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2006</span><span style=\"font-weight: bold\">)</span>. <span style=\"color: #008000; text-decoration-color: #008000\">\"Selective foraging by fish-eating killer whales Orcinus orca in British Columbia\"</span>. \n",
              "Marine Ecology Progress Series.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: 1ed8f49561630f10202b55c8c7619a32cd9f6a11675cbb56c64a578826e488ef\n",
              "Orca\n",
              "; Ellis, Graeme M. \u001b[1m(\u001b[0m\u001b[1;36m2006\u001b[0m\u001b[1m)\u001b[0m. \u001b[32m\"Selective foraging by fish-eating killer whales Orcinus orca in British Columbia\"\u001b[0m. \n",
              "Marine Ecology Progress Series.\n",
              "score: \u001b[1;36m0.5\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: a9bb77dac4747c4fba48a7464038c9da206d7e3663d837f2c95f6d882de8111e\n",
              "Orca\n",
              " On average, an orca eats <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">227</span> kilograms <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> lb<span style=\"font-weight: bold\">)</span> each day. While salmon are usually hunted by an individual whale \n",
              "or a small group, herring are often caught using carousel feeding: the orcas force the herring into a tight ball by\n",
              "releasing bursts of bubbles or flashing their white undersides. They then slap the ball with their tail flukes, \n",
              "stunning or killing up to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> fish at a time, then eating them one by one. Carousel feeding has been documented only\n",
              "in the Norwegian orca population, as well as some oceanic dolphin species.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.41666666666666663</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: a9bb77dac4747c4fba48a7464038c9da206d7e3663d837f2c95f6d882de8111e\n",
              "Orca\n",
              " On average, an orca eats \u001b[1;36m227\u001b[0m kilograms \u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m lb\u001b[1m)\u001b[0m each day. While salmon are usually hunted by an individual whale \n",
              "or a small group, herring are often caught using carousel feeding: the orcas force the herring into a tight ball by\n",
              "releasing bursts of bubbles or flashing their white undersides. They then slap the ball with their tail flukes, \n",
              "stunning or killing up to \u001b[1;36m15\u001b[0m fish at a time, then eating them one by one. Carousel feeding has been documented only\n",
              "in the Norwegian orca population, as well as some oceanic dolphin species.\n",
              "score: \u001b[1;36m0.41666666666666663\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: 33fdef8b4f33f4c5ce00cbbc9e3cb3605b778131854436d4bb7e54f5adaf79ae\n",
              "Dolphin\n",
              " === Consumption === ==== Cuisine ==== In some parts of the world, such as Taiji, Japan and the Faroe Islands, \n",
              "dolphins are traditionally considered as food, and are killed in harpoon or drive hunts.\n",
              "Dolphin meat is consumed in a small number of countries worldwide, which include Japan and Peru <span style=\"font-weight: bold\">(</span>where it is \n",
              "referred to as chancho marino, or <span style=\"color: #008000; text-decoration-color: #008000\">\"sea pork\"</span><span style=\"font-weight: bold\">)</span>. While Japan may be the best-known and most controversial example, \n",
              "only a very small minority of the population has ever sampled it.\n",
              "Dolphin meat is dense and such a dark shade of red as to appear black.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3333333333333333</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: 33fdef8b4f33f4c5ce00cbbc9e3cb3605b778131854436d4bb7e54f5adaf79ae\n",
              "Dolphin\n",
              " === Consumption === ==== Cuisine ==== In some parts of the world, such as Taiji, Japan and the Faroe Islands, \n",
              "dolphins are traditionally considered as food, and are killed in harpoon or drive hunts.\n",
              "Dolphin meat is consumed in a small number of countries worldwide, which include Japan and Peru \u001b[1m(\u001b[0mwhere it is \n",
              "referred to as chancho marino, or \u001b[32m\"sea pork\"\u001b[0m\u001b[1m)\u001b[0m. While Japan may be the best-known and most controversial example, \n",
              "only a very small minority of the population has ever sampled it.\n",
              "Dolphin meat is dense and such a dark shade of red as to appear black.\n",
              "score: \u001b[1;36m0.3333333333333333\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: 6b643c8aa3d47fc198063f8bbc98828bd1d2368d22c95b6b97c36beb60b7fbd0\n",
              "Orca\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\" Although large variation in the ecological distinctiveness of different orca groups complicate simple </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">differentiation into types, research off the west coast of North America has identified fish-eating \"</span>residents\", \n",
              "mammal-eating <span style=\"color: #008000; text-decoration-color: #008000\">\"transients\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"offshores\"</span>. Other populations have not been as well studied, although specialized \n",
              "fish and mammal eating orcas have been distinguished elsewhere. Mammal-eating orcas in different regions were long \n",
              "thought likely to be closely related, but genetic testing has refuted this hypothesis. A <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> study supported the \n",
              "elevation of Eastern North American resident and transient orcas as distinct species, O.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3333333333333333</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: 6b643c8aa3d47fc198063f8bbc98828bd1d2368d22c95b6b97c36beb60b7fbd0\n",
              "Orca\n",
              "\u001b[32m\" Although large variation in the ecological distinctiveness of different orca groups complicate simple \u001b[0m\n",
              "\u001b[32mdifferentiation into types, research off the west coast of North America has identified fish-eating \"\u001b[0mresidents\", \n",
              "mammal-eating \u001b[32m\"transients\"\u001b[0m and \u001b[32m\"offshores\"\u001b[0m. Other populations have not been as well studied, although specialized \n",
              "fish and mammal eating orcas have been distinguished elsewhere. Mammal-eating orcas in different regions were long \n",
              "thought likely to be closely related, but genetic testing has refuted this hypothesis. A \u001b[1;36m2024\u001b[0m study supported the \n",
              "elevation of Eastern North American resident and transient orcas as distinct species, O.\n",
              "score: \u001b[1;36m0.3333333333333333\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import rich\n",
        "\n",
        "for d in results['retriever']['documents']:\n",
        "  rich.print(f\"\\nid: {d.id}\\n{d.meta['title']}\\n{d.content}\\nscore: {d.score}\\n---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC-CwKnkKzxn",
        "outputId": "7a3f3be9-5eac-4705-bda9-8be836794108"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating sparse embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 71.98it/s]\n",
            "Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.90it/s]\n"
          ]
        }
      ],
      "source": [
        "question = \"capybara social behavior\"\n",
        "\n",
        "results = hybrid_query.run(\n",
        "    {\"dense_text_embedder\": {\"text\": question},\n",
        "     \"sparse_text_embedder\": {\"text\": question}}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "IGayh5GTK_pb",
        "outputId": "ce00cc9d-3e50-418d-ceca-c90aa477e6b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: d35c090ebfdad52eb882915b0ee2a9578c751a243ecef3a2c941ef0713a7c9aa\n",
              "Capybara\n",
              " The capybara inhabits savannas and dense forests, and lives near bodies of water. It is a highly social species \n",
              "and can be found in groups as large as <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> individuals, but usually live in groups of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>â€“<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> individuals. The \n",
              "capybara is hunted for its meat and hide and also for grease from its thick fatty skin. == Etymology ==\n",
              "Its common name is derived from Tupi ka'apiÃ»ara, a complex agglutination of kaÃ¡ <span style=\"font-weight: bold\">(</span>leaf<span style=\"font-weight: bold\">)</span> + pÃ­i <span style=\"font-weight: bold\">(</span>slender<span style=\"font-weight: bold\">)</span> + Ãº <span style=\"font-weight: bold\">(</span>eat<span style=\"font-weight: bold\">)</span> + \n",
              "ara <span style=\"font-weight: bold\">(</span>a suffix for agent nouns<span style=\"font-weight: bold\">)</span>, meaning <span style=\"color: #008000; text-decoration-color: #008000\">\"one who eats slender leaves\"</span>, or <span style=\"color: #008000; text-decoration-color: #008000\">\"grass-eater\"</span>.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: d35c090ebfdad52eb882915b0ee2a9578c751a243ecef3a2c941ef0713a7c9aa\n",
              "Capybara\n",
              " The capybara inhabits savannas and dense forests, and lives near bodies of water. It is a highly social species \n",
              "and can be found in groups as large as \u001b[1;36m100\u001b[0m individuals, but usually live in groups of \u001b[1;36m10\u001b[0mâ€“\u001b[1;36m20\u001b[0m individuals. The \n",
              "capybara is hunted for its meat and hide and also for grease from its thick fatty skin. == Etymology ==\n",
              "Its common name is derived from Tupi ka'apiÃ»ara, a complex agglutination of kaÃ¡ \u001b[1m(\u001b[0mleaf\u001b[1m)\u001b[0m + pÃ­i \u001b[1m(\u001b[0mslender\u001b[1m)\u001b[0m + Ãº \u001b[1m(\u001b[0meat\u001b[1m)\u001b[0m + \n",
              "ara \u001b[1m(\u001b[0ma suffix for agent nouns\u001b[1m)\u001b[0m, meaning \u001b[32m\"one who eats slender leaves\"\u001b[0m, or \u001b[32m\"grass-eater\"\u001b[0m.\n",
              "score: \u001b[1;36m0.7\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: e1b0dcc9a1d01481052af5964616f438073f201ffaa0605282a7ddaf90fcafaf\n",
              "Capybara\n",
              " Males establish social bonds, dominance, or general group consensus. They can make dog-like barks when threatened \n",
              "or when females are herding young.\n",
              "Capybaras have two types of scent glands: a morrillo, located on the snout, and anal glands. Both sexes have these \n",
              "glands, but males have much larger morrillos and use their anal glands more frequently.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666666666666</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: e1b0dcc9a1d01481052af5964616f438073f201ffaa0605282a7ddaf90fcafaf\n",
              "Capybara\n",
              " Males establish social bonds, dominance, or general group consensus. They can make dog-like barks when threatened \n",
              "or when females are herding young.\n",
              "Capybaras have two types of scent glands: a morrillo, located on the snout, and anal glands. Both sexes have these \n",
              "glands, but males have much larger morrillos and use their anal glands more frequently.\n",
              "score: \u001b[1;36m0.6666666666666666\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: fd11addea30e8ae2f1d60274beae4d42646b075eb0579bef1c2899cde1e1bb2b\n",
              "Capybara\n",
              "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">1.31.0.1</span>.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: fd11addea30e8ae2f1d60274beae4d42646b075eb0579bef1c2899cde1e1bb2b\n",
              "Capybara\n",
              "\u001b[1;92m1.31.0.1\u001b[0m.\n",
              "score: \u001b[1;36m0.5\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: 1600c15a21aa722965ef2cc4fab4e622474fc8d1ff9e0c555c955e78b038ee2d\n",
              "Capybara\n",
              " In addition, a female alerts males she is in estrus by whistling through her nose. During mating, the female has \n",
              "the advantage and mating choice. Capybaras mate only in water, and if a female does not want to mate with a certain\n",
              "male, she either submerges or leaves the water. Dominant males are highly protective of the females, but they \n",
              "usually cannot prevent some of the subordinates from copulating.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: 1600c15a21aa722965ef2cc4fab4e622474fc8d1ff9e0c555c955e78b038ee2d\n",
              "Capybara\n",
              " In addition, a female alerts males she is in estrus by whistling through her nose. During mating, the female has \n",
              "the advantage and mating choice. Capybaras mate only in water, and if a female does not want to mate with a certain\n",
              "male, she either submerges or leaves the water. Dominant males are highly protective of the females, but they \n",
              "usually cannot prevent some of the subordinates from copulating.\n",
              "score: \u001b[1;36m0.25\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "id: 994f31c23e46c16744558b3a499cff0c446da33661a74bb2ddaede9e26e64e11\n",
              "Capybara\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> ft<span style=\"font-weight: bold\">)</span> in length, stand <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> cm <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> in<span style=\"font-weight: bold\">)</span> tall at the withers, and typically weigh <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span> kg <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span> \n",
              "lb<span style=\"font-weight: bold\">)</span>, with an average in the Venezuelan llanos of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.9</span> kg <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108</span> lb<span style=\"font-weight: bold\">)</span>. Females are slightly heavier than males. The top\n",
              "recorded weights are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91</span> kg <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201</span> lb<span style=\"font-weight: bold\">)</span> for a wild female from Brazil and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span>.\n",
              "score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25</span>\n",
              "---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "id: 994f31c23e46c16744558b3a499cff0c446da33661a74bb2ddaede9e26e64e11\n",
              "Capybara\n",
              "\u001b[1;36m40\u001b[0m ft\u001b[1m)\u001b[0m in length, stand \u001b[1;36m50\u001b[0m to \u001b[1;36m62\u001b[0m cm \u001b[1m(\u001b[0m\u001b[1;36m20\u001b[0m to \u001b[1;36m24\u001b[0m in\u001b[1m)\u001b[0m tall at the withers, and typically weigh \u001b[1;36m35\u001b[0m to \u001b[1;36m66\u001b[0m kg \u001b[1m(\u001b[0m\u001b[1;36m77\u001b[0m to \u001b[1;36m146\u001b[0m \n",
              "lb\u001b[1m)\u001b[0m, with an average in the Venezuelan llanos of \u001b[1;36m48.9\u001b[0m kg \u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m lb\u001b[1m)\u001b[0m. Females are slightly heavier than males. The top\n",
              "recorded weights are \u001b[1;36m91\u001b[0m kg \u001b[1m(\u001b[0m\u001b[1;36m201\u001b[0m lb\u001b[1m)\u001b[0m for a wild female from Brazil and \u001b[1;36m73\u001b[0m.\n",
              "score: \u001b[1;36m0.25\u001b[0m\n",
              "---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import rich\n",
        "\n",
        "for d in results['retriever']['documents']:\n",
        "  rich.print(f\"\\nid: {d.id}\\n{d.meta['title']}\\n{d.content}\\nscore: {d.score}\\n---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mHu_jbeFcyQ"
      },
      "source": [
        "## ğŸ“š Resources\n",
        "- [BM42: New Baseline for Hybrid Search - article by Qdrant](https://qdrant.tech/articles/bm42/)\n",
        "- [Sparse Embedding Retrieval with SPLADE - notebook](https://github.com/deepset-ai/haystack-cookbook/blob/main/notebooks/sparse_embedding_retrieval.ipynb)\n",
        "- Haystack docs:\n",
        "  - [Retrievers](https://docs.haystack.deepset.ai/docs/retrievers)\n",
        "  - [Qdrant Sparse Embedding Retriever](https://docs.haystack.deepset.ai/docs/qdrantsparseembeddingretriever)\n",
        "  - [Qdrant Hybrid Retriever](https://docs.haystack.deepset.ai/docs/qdranthybridretriever)\n",
        "  - [FastEmbed Sparse Text Embedder](https://docs.haystack.deepset.ai/docs/fastembedsparsetextembedder)\n",
        "  - [Fastembed Sparse Document Embedder](https://docs.haystack.deepset.ai/docs/fastembedsparsedocumentembedder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4i2BQL9En-H"
      },
      "source": [
        "(*Notebook by [Stefano Fiorucci](https://github.com/anakin87)*)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
