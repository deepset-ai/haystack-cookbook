{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d21d72df731e208f",
      "metadata": {
        "id": "d21d72df731e208f"
      },
      "source": [
        "# GitHub PR Creator Agent\n",
        "\n",
        "In this recipe, we'll create an Agent that uses tools from Haystack's GitHub integration. Given a GitHub issue URL, the agent will not only comment on the issue but it will also fork the repository and open a pull request.\n",
        "\n",
        "Step-by-step, the agent will:\n",
        "- Fetch and parse the issue description and comments\n",
        "- Identify the relevant directories and files\n",
        "- Determine the next steps for resolution and post them as a comment\n",
        "- Fork the repository and create a new branch\n",
        "- Open a pull request from the newly created branch to the original repository\n",
        "\n",
        "For this, we’ll use Haystack's Agent component. It implements a tool-calling functionality with provider-agnostic chat model support. We can use Agent either as a standalone component or within a pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-Bb6okLBEzwq",
      "metadata": {
        "id": "-Bb6okLBEzwq"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:07.494154Z",
          "start_time": "2025-02-21T09:36:06.648242Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "0ebc8ee8-4ff8-42cf-da38-83b5c77b06dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/deepset-ai/haystack-core-integrations.git@extend-check-fork-status#subdirectory=integrations/github\n",
            "  Cloning https://github.com/deepset-ai/haystack-core-integrations.git (to revision extend-check-fork-status) to /tmp/pip-req-build-1aam8xp1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepset-ai/haystack-core-integrations.git /tmp/pip-req-build-1aam8xp1\n",
            "  Running command git checkout -b extend-check-fork-status --track origin/extend-check-fork-status\n",
            "  Switched to a new branch 'extend-check-fork-status'\n",
            "  Branch 'extend-check-fork-status' set up to track remote branch 'extend-check-fork-status' from 'origin'.\n",
            "  Resolved https://github.com/deepset-ai/haystack-core-integrations.git to commit 55be1a1407bbccecd4023a421e751502b18df016\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting haystack-ai>=2.12.0 (from github-haystack==1.0.2.dev11+g55be1a1)\n",
            "  Downloading haystack_ai-2.14.2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting haystack-experimental (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1)\n",
            "  Downloading haystack_experimental-0.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (3.1.6)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (4.24.0)\n",
            "Collecting lazy-imports (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1)\n",
            "  Downloading lazy_imports-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (10.7.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2.0.2)\n",
            "Requirement already satisfied: openai>=1.56.1 in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (1.84.0)\n",
            "Collecting posthog!=3.12.0 (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1)\n",
            "  Downloading posthog-4.8.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2.11.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (9.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (4.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog!=3.12.0->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (1.17.0)\n",
            "Collecting backoff>=1.10.0 (from posthog!=3.12.0->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2025.4.26)\n",
            "Collecting filetype (from haystack-experimental->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (0.25.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai>=2.12.0->github-haystack==1.0.2.dev11+g55be1a1) (0.16.0)\n",
            "Downloading haystack_ai-2.14.2-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.1/515.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-4.8.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading haystack_experimental-0.10.0-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_imports-1.0.0-py3-none-any.whl (20 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: github-haystack\n",
            "  Building wheel for github-haystack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for github-haystack: filename=github_haystack-1.0.2.dev11+g55be1a1-py3-none-any.whl size=46398 sha256=7894b395cd7f8e320ba76a08671c2b200fbd547aaccb2d8ef4fe59856d89f6d7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fklicrgy/wheels/4f/37/54/e0e309a5366a55a912870ae32a898836b5c2ae1933ca103217\n",
            "Successfully built github-haystack\n",
            "Installing collected packages: filetype, lazy-imports, backoff, posthog, haystack-experimental, haystack-ai, github-haystack\n",
            "Successfully installed backoff-2.2.1 filetype-1.2.0 github-haystack-1.0.2.dev11+g55be1a1 haystack-ai-2.14.2 haystack-experimental-0.10.0 lazy-imports-1.0.0 posthog-4.8.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install github-haystack -q\n",
        "%pip install anthropic-haystack -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1ac0641a1523ba57",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:10.264686Z",
          "start_time": "2025-02-21T09:36:08.647653Z"
        },
        "id": "1ac0641a1523ba57"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from typing import List\n",
        "\n",
        "from haystack import Pipeline\n",
        "from haystack.components.agents import Agent\n",
        "from haystack.components.builders import ChatPromptBuilder\n",
        "from haystack.components.converters import OutputAdapter\n",
        "from haystack.dataclasses import ChatMessage, Document\n",
        "from haystack.tools.from_function import tool\n",
        "\n",
        "from haystack_integrations.components.connectors.github import GitHubIssueViewer\n",
        "from haystack_integrations.components.generators.anthropic import AnthropicChatGenerator\n",
        "from haystack_integrations.prompts.github import SYSTEM_PROMPT\n",
        "from haystack_integrations.tools.github import GitHubRepoViewerTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dd0aff035d9422d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:25.392067Z",
          "start_time": "2025-02-21T09:36:15.367404Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd0aff035d9422d",
        "outputId": "fc3fe516-4f04-4328-dd98-906ed974b08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anthropic Key: ··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Anthropic Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eb055b10c098b309",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:13.520240Z",
          "start_time": "2025-02-21T09:36:13.515376Z"
        },
        "id": "eb055b10c098b309"
      },
      "outputs": [],
      "source": [
        "repo_viewer_tool = GitHubRepoViewerTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eb31fa163e7d5a11",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:14.255846Z",
          "start_time": "2025-02-21T09:36:14.249432Z"
        },
        "id": "eb31fa163e7d5a11"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def create_comment(comment: str) -> str:\n",
        "    \"\"\"\n",
        "    Use this to create a Github comment once you finished your exploration.\n",
        "    \"\"\"\n",
        "    return comment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0sdejMSNGYYF",
      "metadata": {
        "id": "0sdejMSNGYYF"
      },
      "source": [
        "In this recipe, we simulate creating a comment on GitHub with the above tool for demonstration purposes. For real use cases, you can use GitHubIssueCommenterTool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "X2cqw5eIGfZ_",
      "metadata": {
        "id": "X2cqw5eIGfZ_"
      },
      "outputs": [],
      "source": [
        "# from haystack_integrations.tools.github import GitHubIssueCommenterTool\n",
        "# issue_commenter_tool = GitHubIssueCommenterTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c9fbe18779fb65b7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:26.758238Z",
          "start_time": "2025-02-21T09:36:26.715690Z"
        },
        "id": "c9fbe18779fb65b7"
      },
      "outputs": [],
      "source": [
        "chat_generator = AnthropicChatGenerator(model=\"claude-sonnet-4-20250514\", generation_kwargs={\"max_tokens\": 8000})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "325806047f4835ec",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:28.082697Z",
          "start_time": "2025-02-21T09:36:28.073274Z"
        },
        "id": "325806047f4835ec"
      },
      "outputs": [],
      "source": [
        "agent = Agent(\n",
        "    chat_generator=chat_generator,\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        "    tools=[repo_viewer_tool, create_comment],\n",
        "    exit_conditions=[\"create_comment\"],\n",
        "    state_schema={\"documents\": {\"type\": List[Document]}},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "23ba459d24c3c08a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:30.499830Z",
          "start_time": "2025-02-21T09:36:30.495028Z"
        },
        "id": "23ba459d24c3c08a"
      },
      "outputs": [],
      "source": [
        "issue_template = \"\"\"\n",
        "Issue from: {{ url }}\n",
        "{% for document in documents %}\n",
        "{% if loop.index == 1 %}\n",
        "**Title: {{ document.meta.title }}**\n",
        "{% endif %}\n",
        "<issue-comment>\n",
        "{{document.content}}\n",
        "</issue-comment>\n",
        "{% endfor %}\n",
        "    \"\"\"\n",
        "\n",
        "issue_builder = ChatPromptBuilder(template=[ChatMessage.from_user(issue_template)], required_variables=\"*\")\n",
        "\n",
        "issue_fetcher = GitHubIssueViewer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "10d1cdd669be0d7d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:32.004647Z",
          "start_time": "2025-02-21T09:36:31.999299Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10d1cdd669be0d7d",
        "outputId": "66f21966-5661-4081-f0e2-28c39b054af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7ff0f338c0d0>\n",
              "🚅 Components\n",
              "  - issue_fetcher: GitHubIssueViewer\n",
              "  - issue_builder: ChatPromptBuilder\n",
              "  - agent: Agent\n",
              "🛤️ Connections\n",
              "  - issue_fetcher.documents -> issue_builder.documents (List[Document])\n",
              "  - issue_builder.prompt -> agent.messages (List[ChatMessage])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pp = Pipeline()\n",
        "\n",
        "pp.add_component(\"issue_fetcher\", issue_fetcher)\n",
        "pp.add_component(\"issue_builder\", issue_builder)\n",
        "pp.add_component(\"agent\", agent)\n",
        "\n",
        "pp.connect(\"issue_fetcher.documents\", \"issue_builder.documents\")\n",
        "pp.connect(\"issue_builder.prompt\", \"agent.messages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7a6207bc15f02741",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:34.162977Z",
          "start_time": "2025-02-21T09:36:33.484011Z"
        },
        "id": "7a6207bc15f02741"
      },
      "outputs": [],
      "source": [
        "#pp.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7s9vtFHtHa6p",
      "metadata": {
        "id": "7s9vtFHtHa6p"
      },
      "source": [
        "Now we have a pipeline with an Agent that receives a GitHub issue URL as input, explores the files in the repository and comments on the GitHub issue with a proposed solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7ce734ad5af0c82c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:36:41.003316Z",
          "start_time": "2025-02-21T09:36:41.001145Z"
        },
        "id": "7ce734ad5af0c82c"
      },
      "outputs": [],
      "source": [
        "issue_url = \"https://github.com/deepset-ai/haystack-core-integrations/issues/1268\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "961c6d248809c96",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:37:08.036526Z",
          "start_time": "2025-02-21T09:36:42.206187Z"
        },
        "id": "961c6d248809c96"
      },
      "outputs": [],
      "source": [
        "result = pp.run({\"url\": issue_url})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c61e726e2c7d2d17",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:37:11.165861Z",
          "start_time": "2025-02-21T09:37:11.162582Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c61e726e2c7d2d17",
        "outputId": "1151db23-cf95-4669-f59b-ee07ee100794"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Comment from Agent\n",
              "\n",
              "I can confirm that this issue still exists in the current codebase. While the changelog mentions that version 3.1.1 fixed \"OpenSearch custom_query use without filters\", the fix appears to be incomplete.\n",
              "\n",
              "## Problem Analysis\n",
              "\n",
              "The issue occurs in the `_prepare_embedding_search_request` method when using a `custom_query` with empty filters. Looking at the current code:\n",
              "\n",
              "```python\n",
              "body = self._render_custom_query(\n",
              "    custom_query,\n",
              "    {\n",
              "        \"$query_embedding\": query_embedding,\n",
              "        \"$filters\": normalize_filters(filters) if filters else None,\n",
              "    },\n",
              ")\n",
              "```\n",
              "\n",
              "While this looks like it should work (it conditionally calls `normalize_filters`), there's a subtle problem: when `filters` is an empty dict `{}`, the conditional `if filters` evaluates to `False`, so `None` is passed for `$filters`. However, **empty dict `{}` is not the same as `None`** - an empty dict is still \"truthy\" in terms of being a dict object, but it fails the boolean check used here.\n",
              "\n",
              "## Root Cause\n",
              "\n",
              "The issue is that `if filters:` returns `False` for empty dict `{}`, but `normalize_filters({})` still gets called in some code paths, or the `None` value causes issues in the OpenSearch query.\n",
              "\n",
              "Looking at the `normalize_filters` function:\n",
              "\n",
              "```python\n",
              "def normalize_filters(filters: Dict[str, Any]) -> Dict[str, Any]:\n",
              "    if not isinstance(filters, dict):\n",
              "        msg = \"Filters must be a dictionary\"\n",
              "        raise FilterError(msg)\n",
              "\n",
              "    if \"field\" in filters:\n",
              "        return {\"bool\": {\"must\": _parse_comparison_condition(filters)}}\n",
              "    return _parse_logical_condition(filters)\n",
              "```\n",
              "\n",
              "And `_parse_logical_condition`:\n",
              "\n",
              "```python\n",
              "def _parse_logical_condition(condition: Dict[str, Any]) -> Dict[str, Any]:\n",
              "    if \"operator\" not in condition:\n",
              "        msg = f\"'operator' key missing in {condition}\"\n",
              "        raise FilterError(msg)\n",
              "```\n",
              "\n",
              "So when an empty dict `{}` is passed to `normalize_filters`, it doesn't have a \"field\" key, so it goes to `_parse_logical_condition`, which then fails because there's no \"operator\" key.\n",
              "\n",
              "## Recommended Fix\n",
              "\n",
              "The fix should be to properly handle empty or None filters by only including the `$filters` placeholder when there are actual filters to substitute. Here's the corrected approach:\n",
              "\n",
              "**For `_prepare_embedding_search_request`:**\n",
              "\n",
              "```python\n",
              "if isinstance(custom_query, dict):\n",
              "    substitutions = {\"$query_embedding\": query_embedding}\n",
              "    if filters:  # Only add $filters if there are actual filters\n",
              "        substitutions[\"$filters\"] = normalize_filters(filters)\n",
              "    body = self._render_custom_query(custom_query, substitutions)\n",
              "```\n",
              "\n",
              "**For `_prepare_bm25_search_request`:**\n",
              "\n",
              "```python\n",
              "if isinstance(custom_query, dict):\n",
              "    substitutions = {\"$query\": query}\n",
              "    if filters:  # Only add $filters if there are actual filters  \n",
              "        substitutions[\"$filters\"] = normalize_filters(filters)\n",
              "    body = self._render_custom_query(custom_query, substitutions)\n",
              "```\n",
              "\n",
              "This approach ensures that:\n",
              "1. Empty filters (`{}`) don't get passed to `normalize_filters` \n",
              "2. The `$filters` placeholder is only included in custom queries when there are actual filters\n",
              "3. Custom queries that don't use the `$filters` placeholder work correctly regardless of the filters parameter\n",
              "\n",
              "This matches the original suggestion in the issue report and would properly resolve the problem for users trying to use custom queries without filters."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "display(Markdown(\"# Comment from Agent\\n\\n\" + result[\"agent\"][\"last_message\"].tool_call_result.result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43491c00e173588d",
      "metadata": {
        "id": "43491c00e173588d"
      },
      "source": [
        "## Let's see what files our Agent looked at"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8778f7d378009251",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:37:15.920512Z",
          "start_time": "2025-02-21T09:37:15.915236Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "8778f7d378009251",
        "outputId": "c52200d9-0482-4949-bf09-6577fd0a3097"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "[https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/document_stores/opensearch/document_store.py](https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/document_stores/opensearch/document_store.py)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "[https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/document_stores/opensearch/filters.py](https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/document_stores/opensearch/filters.py)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "[https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/components/retrievers/opensearch/embedding_retriever.py](https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/components/retrievers/opensearch/embedding_retriever.py)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "[https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/CHANGELOG.md](https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/CHANGELOG.md)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "[https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/tests/test_embedding_retriever.py](https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/tests/test_embedding_retriever.py)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "[https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/document_stores/opensearch/document_store.py](https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/opensearch/src/haystack_integrations/document_stores/opensearch/document_store.py)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for document in result[\"agent\"][\"documents\"]:\n",
        "    if document.meta[\"type\"] in [\"file_content\"]:\n",
        "        display(Markdown(f\"[{document.meta['url']}]({document.meta['url']})\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b7ca11f2e268e7b",
      "metadata": {
        "id": "9b7ca11f2e268e7b"
      },
      "source": [
        "# From Agent to Multi-Agent\n",
        "\n",
        "In the next step, we'll make this agent a little more powerful.\n",
        "We will pass the issue comments and the generated proposal to a second agent.\n",
        "We also fork the original repository so that we can make edits. For forking the repository, we need a personal access token from GitHub.\n",
        "\n",
        "The `Agent` will then:\n",
        "* view relevant files\n",
        "* perform edits commit by commit\n",
        "* return a PR title and description once it is ready to go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e4ed049b9b95b7ac",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:39:06.567935Z",
          "start_time": "2025-02-21T09:38:51.553173Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ed049b9b95b7ac",
        "outputId": "1b60a536-5f95-4dc0-ecb1-35327282c663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Github Token: ··········\n"
          ]
        }
      ],
      "source": [
        "# Either classic token or a fine-grained token that can create repositories and commit code\n",
        "os.environ[\"GITHUB_TOKEN\"] = getpass(\"Github Token: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6435353f22925580",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:38:50.529255Z",
          "start_time": "2025-02-21T09:38:50.518244Z"
        },
        "id": "6435353f22925580"
      },
      "outputs": [],
      "source": [
        "from haystack_integrations.components.connectors.github import GitHubRepoForker\n",
        "from haystack_integrations.prompts.github import FILE_EDITOR_PROMPT, FILE_EDITOR_SCHEMA, PR_CREATOR_PROMPT\n",
        "from haystack_integrations.tools.github import GitHubFileEditorTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dcb13ab1345602a7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:39:07.690838Z",
          "start_time": "2025-02-21T09:39:07.688162Z"
        },
        "id": "dcb13ab1345602a7"
      },
      "outputs": [],
      "source": [
        "repo_forker = GitHubRepoForker(create_branch=True, auto_sync=True, wait_for_completion=True)\n",
        "pp.add_component(\"repo_forker\", repo_forker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5994dc13d66f37ab",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:39:10.162824Z",
          "start_time": "2025-02-21T09:39:10.150173Z"
        },
        "id": "5994dc13d66f37ab"
      },
      "outputs": [],
      "source": [
        "file_editor_tool = GitHubFileEditorTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "zn1m13bmIUSq",
      "metadata": {
        "id": "zn1m13bmIUSq"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def create_pr(title: str, body: str) -> str:\n",
        "    \"\"\"\n",
        "    Use this to create a Github PR once you are done with your changes.\n",
        "    \"\"\"\n",
        "    return title + \"\\n\\n\" + body"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w3GnuAK-IYRK",
      "metadata": {
        "id": "w3GnuAK-IYRK"
      },
      "source": [
        "In this recipe, we simulate creating a comment on GitHub with the above tool for demonstration purposes. For real use cases, you can use GitHubPRCreatorTool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "YXfvzPeFIb1v",
      "metadata": {
        "id": "YXfvzPeFIb1v"
      },
      "outputs": [],
      "source": [
        "# from haystack_integrations.tools.github import GitHubPRCreatorTool\n",
        "# pr_creator_tool = GitHubPRCreatorTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bc3e7450f1626485",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:39:13.259149Z",
          "start_time": "2025-02-21T09:39:13.244996Z"
        },
        "id": "bc3e7450f1626485"
      },
      "outputs": [],
      "source": [
        "pr_chat_generator = AnthropicChatGenerator(model=\"claude-sonnet-4-20250514\", generation_kwargs={\"max_tokens\": 8000})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "16a13b74959a1020",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:39:25.248844Z",
          "start_time": "2025-02-21T09:39:25.236968Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16a13b74959a1020",
        "outputId": "b7feb2b1-27f4-42c1-847c-449902ef7160"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:haystack.components.converters.output_adapter:Unsafe mode is enabled. This allows execution of arbitrary code in the Jinja template. Use this only if you trust the source of the template.\n"
          ]
        }
      ],
      "source": [
        "pr_agent = Agent(\n",
        "    chat_generator=pr_chat_generator,\n",
        "    system_prompt=PR_CREATOR_PROMPT,\n",
        "    tools=[file_editor_tool, create_pr, repo_viewer_tool],\n",
        "    exit_conditions=[\"create_pr\"],\n",
        "    state_schema={\"repo\": {\"type\": str}, \"branch\": {\"type\": str}, \"title\": {\"type\": str}, \"documents\": {\"type\": List[Document]}},\n",
        ")\n",
        "\n",
        "pp.add_component(\"pr_agent\", pr_agent)\n",
        "adapter = OutputAdapter(\n",
        "    template=\"{{issue_messages + [((agent_messages|last).tool_call_result.result)|user_message]}}\",\n",
        "    custom_filters={\"user_message\": ChatMessage.from_user},\n",
        "    output_type=List[ChatMessage], unsafe=True\n",
        ")\n",
        "pp.add_component(\"adapter\", adapter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7ba94d5c9e8b144e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:39:26.881804Z",
          "start_time": "2025-02-21T09:39:26.878449Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ba94d5c9e8b144e",
        "outputId": "7440be40-ecf5-430b-fdaa-6beabd65b0b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7ff0f338c0d0>\n",
              "🚅 Components\n",
              "  - issue_fetcher: GitHubIssueViewer\n",
              "  - issue_builder: ChatPromptBuilder\n",
              "  - agent: Agent\n",
              "  - repo_forker: GitHubRepoForker\n",
              "  - pr_agent: Agent\n",
              "  - adapter: OutputAdapter\n",
              "🛤️ Connections\n",
              "  - issue_fetcher.documents -> issue_builder.documents (List[Document])\n",
              "  - issue_builder.prompt -> agent.messages (List[ChatMessage])\n",
              "  - issue_builder.prompt -> adapter.issue_messages (List[ChatMessage])\n",
              "  - agent.messages -> adapter.agent_messages (List[ChatMessage])\n",
              "  - repo_forker.issue_branch -> pr_agent.branch (str)\n",
              "  - repo_forker.repo -> pr_agent.repo (str)\n",
              "  - adapter.output -> pr_agent.messages (List[ChatMessage])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pp.connect(\"repo_forker.issue_branch\", \"pr_agent.branch\")\n",
        "pp.connect(\"repo_forker.repo\", \"pr_agent.repo\")\n",
        "pp.connect(\"agent.messages\", \"adapter.agent_messages\")\n",
        "pp.connect(\"issue_builder.prompt\", \"adapter.issue_messages\")\n",
        "pp.connect(\"adapter.output\", \"pr_agent.messages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "476acf2e3460e298",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:39:28.031720Z",
          "start_time": "2025-02-21T09:39:27.926994Z"
        },
        "id": "476acf2e3460e298"
      },
      "outputs": [],
      "source": [
        "#pp.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ff042e9fe11634",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-21T09:41:59.664422Z",
          "start_time": "2025-02-21T09:40:49.053021Z"
        },
        "id": "d9ff042e9fe11634"
      },
      "outputs": [],
      "source": [
        "result = pp.run(data={\"url\": issue_url, \"title\": \"# Agent PR\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "bb9ed2b256142d77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "bb9ed2b256142d77",
        "outputId": "e01f7772-7343-4ec3-e820-e14459237214"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Comment from Agent\n",
              "\n",
              "Fix OpenSearch custom_query with empty filters\n",
              "\n",
              "## Summary\n",
              "\n",
              "This PR fixes an issue where using `custom_query` with `OpenSearchEmbeddingRetriever` or `OpenSearchBM25Retriever` would fail when empty filters (`{}`) were provided.\n",
              "\n",
              "## Problem\n",
              "\n",
              "When using custom queries with empty filters dict (`{}`), the code would incorrectly attempt to normalize the empty filters, causing a `FilterError: 'operator' key missing in {}`.\n",
              "\n",
              "## Root Cause\n",
              "\n",
              "The conditional check `if filters` in both `_prepare_bm25_search_request` and `_prepare_embedding_search_request` methods evaluates to `True` for empty dictionaries, causing `normalize_filters({})` to be called even though empty dicts should be treated the same as `None`.\n",
              "\n",
              "## Solution\n",
              "\n",
              "Updated the conditional checks to explicitly handle empty dictionaries:\n",
              "\n",
              "```python\n",
              "# Before\n",
              "\"$filters\": normalize_filters(filters) if filters else None,\n",
              "\n",
              "# After  \n",
              "\"$filters\": normalize_filters(filters) if filters and filters != {} else None,\n",
              "```\n",
              "\n",
              "This ensures that both `None` and `{}` are treated as \"no filters\" and result in `$filters` being set to `None` in the custom query substitutions.\n",
              "\n",
              "## Changes Made\n",
              "\n",
              "1. **Fixed `_prepare_bm25_search_request`** (line 500): Updated filter condition to handle empty dicts\n",
              "2. **Fixed `_prepare_embedding_search_request`** (line 657): Updated filter condition to handle empty dicts  \n",
              "3. **Added integration tests**: Created comprehensive tests to verify the fix works for both retriever types\n",
              "\n",
              "## Testing\n",
              "\n",
              "- Added new test cases for both embedding and BM25 retrievers with empty filters\n",
              "- Existing tests continue to pass\n",
              "- Verified that valid filters still work correctly\n",
              "- Confirmed that `None` filters continue to work as expected\n",
              "\n",
              "## Backwards Compatibility\n",
              "\n",
              "This change is fully backwards compatible. It only affects the edge case where empty filter dicts were previously causing errors - now they work as expected.\n",
              "\n",
              "Fixes #1268"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "display(Markdown(\"# Comment from Agent\\n\\n\" + result[\"pr_agent\"][\"last_message\"].tool_call_result.result))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py312-github-comp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
