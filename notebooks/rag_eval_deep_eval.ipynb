{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJBg1TcQksMo"
   },
   "source": [
    "# RAG pipeline evaluation using DeepEval\n",
    "\n",
    "[DeepEval](https://www.confident-ai.com/) is a framework to evaluate [Retrieval Augmented Generation](https://www.deepset.ai/blog/llms-retrieval-augmentation) (RAG) pipelines.\n",
    "It supports metrics like context relevance, answer correctness, faithfulness, and more.\n",
    "\n",
    "For more information about evaluators, supported metrics and usage, check out:\n",
    "\n",
    "* [DeepEvalEvaluator](https://docs.haystack.deepset.ai/docs/deepevalevaluator)\n",
    "* [Model based evaluation](https://docs.haystack.deepset.ai/docs/model-based-evaluation)\n",
    "\n",
    "This notebook shows how to use [DeepEval-Haystack](https://haystack.deepset.ai/integrations/deepeval) integration to evaluate a RAG pipeline against various metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsTU-Z2QjtwZ"
   },
   "source": [
    "## Prerequisites:\n",
    "\n",
    "- [OpenAI](https://openai.com/) key\n",
    "    - **DeepEval** uses  for computing some metrics, so we need an OpenAI key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18vjNnVwGwjH",
    "outputId": "6cee5f5d-66f6-4807-8a18-d66e994d8ac5"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter OpenAI API key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxMjhSB-10Ws"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7u0pxUg3JHn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haystack-ai in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (2.16.0rc0)\n",
      "Requirement already satisfied: docstring-parser in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (0.16)\n",
      "Requirement already satisfied: haystack-experimental in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (0.11.0)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (4.24.0)\n",
      "Requirement already satisfied: lazy-imports in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (0.4.0)\n",
      "Requirement already satisfied: more-itertools in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (10.7.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (3.5)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.56.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (1.93.1)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (4.2.0)\n",
      "Requirement already satisfied: pydantic in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (2.11.7)\n",
      "Requirement already satisfied: python-dateutil in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (9.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai) (4.13.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.56.1->haystack-ai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic->haystack-ai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic->haystack-ai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from posthog!=3.12.0->haystack-ai) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from posthog!=3.12.0->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests->haystack-ai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests->haystack-ai) (2.4.0)\n",
      "Requirement already satisfied: filetype in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-experimental->haystack-ai) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jinja2->haystack-ai) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai) (0.25.1)\n",
      "Requirement already satisfied: datasets>=2.6.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (0.33.2)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets>=2.6.1) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiosignal>=1.1.2->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.6.1) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets>=2.6.1) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.6.1) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.6.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.6.1) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pandas->datasets>=2.6.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pandas->datasets>=2.6.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pandas->datasets>=2.6.1) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.6.1) (1.17.0)\n",
      "Requirement already satisfied: deepeval-haystack in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: deepeval in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval-haystack) (0.20.57)\n",
      "Requirement already satisfied: haystack-ai in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval-haystack) (2.16.0rc0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (4.67.1)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (4.53.1)\n",
      "Requirement already satisfied: pytest in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (8.4.1)\n",
      "Requirement already satisfied: tabulate in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (0.9.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (5.0.0)\n",
      "Requirement already satisfied: typer in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (0.16.0)\n",
      "Requirement already satisfied: rich in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (14.0.0)\n",
      "Requirement already satisfied: protobuf==4.25.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (4.25.1)\n",
      "Requirement already satisfied: pydantic in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (2.11.7)\n",
      "Requirement already satisfied: sentry-sdk in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (2.32.0)\n",
      "Requirement already satisfied: pytest-xdist in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (3.8.0)\n",
      "Requirement already satisfied: portalocker in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (3.2.0)\n",
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (0.3.26)\n",
      "Requirement already satisfied: langchain-core in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (0.3.68)\n",
      "Requirement already satisfied: langchain-openai in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (0.3.27)\n",
      "Requirement already satisfied: rouge-score==0.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (0.1.2)\n",
      "Requirement already satisfied: nltk==3.8.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (3.8.1)\n",
      "Requirement already satisfied: ragas in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval->deepeval-haystack) (0.2.15)\n",
      "Requirement already satisfied: click in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from nltk==3.8.1->deepeval->deepeval-haystack) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from nltk==3.8.1->deepeval->deepeval-haystack) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from nltk==3.8.1->deepeval->deepeval-haystack) (2024.11.6)\n",
      "Requirement already satisfied: absl-py in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from rouge-score==0.1.2->deepeval->deepeval-haystack) (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from rouge-score==0.1.2->deepeval->deepeval-haystack) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from rouge-score==0.1.2->deepeval->deepeval-haystack) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (0.16)\n",
      "Requirement already satisfied: haystack-experimental in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (0.11.0)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (4.24.0)\n",
      "Requirement already satisfied: lazy-imports in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (0.4.0)\n",
      "Requirement already satisfied: more-itertools in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (10.7.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (3.5)\n",
      "Requirement already satisfied: openai>=1.56.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (1.93.1)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (4.2.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-ai->deepeval-haystack) (4.13.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai->deepeval-haystack) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai->deepeval-haystack) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai->deepeval-haystack) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai->deepeval-haystack) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai->deepeval-haystack) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.56.1->haystack-ai->deepeval-haystack) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai->deepeval-haystack) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai->deepeval-haystack) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai->deepeval-haystack) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic->deepeval->deepeval-haystack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic->deepeval->deepeval-haystack) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic->deepeval->deepeval-haystack) (0.4.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from posthog!=3.12.0->haystack-ai->deepeval-haystack) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests->deepeval->deepeval-haystack) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests->deepeval->deepeval-haystack) (2.4.0)\n",
      "Requirement already satisfied: filetype in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from haystack-experimental->haystack-ai->deepeval-haystack) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jinja2->haystack-ai->deepeval-haystack) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai->deepeval-haystack) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai->deepeval-haystack) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai->deepeval-haystack) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonschema->haystack-ai->deepeval-haystack) (0.25.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain->deepeval->deepeval-haystack) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain->deepeval->deepeval-haystack) (0.4.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain->deepeval->deepeval-haystack) (2.0.41)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain-core->deepeval->deepeval-haystack) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain-core->deepeval->deepeval-haystack) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval->deepeval-haystack) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain->deepeval->deepeval-haystack) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain->deepeval->deepeval-haystack) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain->deepeval->deepeval-haystack) (0.23.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain-openai->deepeval->deepeval-haystack) (0.9.0)\n",
      "Requirement already satisfied: iniconfig>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest->deepeval->deepeval-haystack) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest->deepeval->deepeval-haystack) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest->deepeval->deepeval-haystack) (2.19.2)\n",
      "Requirement already satisfied: execnet>=2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest-xdist->deepeval->deepeval-haystack) (2.1.1)\n",
      "Requirement already satisfied: datasets in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from ragas->deepeval->deepeval-haystack) (3.6.0)\n",
      "Requirement already satisfied: langchain-community in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from ragas->deepeval->deepeval-haystack) (0.3.27)\n",
      "Requirement already satisfied: nest-asyncio in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from ragas->deepeval->deepeval-haystack) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from ragas->deepeval->deepeval-haystack) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from ragas->deepeval->deepeval-haystack) (5.6.3)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets->ragas->deepeval->deepeval-haystack) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets->ragas->deepeval->deepeval-haystack) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets->ragas->deepeval->deepeval-haystack) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets->ragas->deepeval->deepeval-haystack) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets->ragas->deepeval->deepeval-haystack) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets->ragas->deepeval->deepeval-haystack) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from datasets->ragas->deepeval->deepeval-haystack) (0.33.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas->deepeval->deepeval-haystack) (1.20.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets->ragas->deepeval->deepeval-haystack) (1.1.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain-community->ragas->deepeval->deepeval-haystack) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain-community->ragas->deepeval->deepeval-haystack) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from langchain-community->ragas->deepeval->deepeval-haystack) (0.4.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval->deepeval-haystack) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval->deepeval-haystack) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval->deepeval-haystack) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval->deepeval-haystack) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pandas->datasets->ragas->deepeval->deepeval-haystack) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pandas->datasets->ragas->deepeval->deepeval-haystack) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from rich->deepeval->deepeval-haystack) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->deepeval->deepeval-haystack) (0.1.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from sentence-transformers->deepeval->deepeval-haystack) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from sentence-transformers->deepeval->deepeval-haystack) (1.7.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from sentence-transformers->deepeval->deepeval-haystack) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from sentence-transformers->deepeval->deepeval-haystack) (11.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from transformers->deepeval->deepeval-haystack) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from transformers->deepeval->deepeval-haystack) (0.5.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->deepeval->deepeval-haystack) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers->deepeval->deepeval-haystack) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->deepeval->deepeval-haystack) (3.6.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from typer->deepeval->deepeval-haystack) (1.5.4)\n",
      "Requirement already satisfied: deepeval in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (0.20.57)\n",
      "Collecting deepeval\n",
      "  Using cached deepeval-3.2.4-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (3.12.13)\n",
      "Collecting anthropic (from deepeval)\n",
      "  Using cached anthropic-0.57.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting click<8.2.0,>=8.0.0 (from deepeval)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting google-genai<2.0.0,>=1.9.0 (from deepeval)\n",
      "  Using cached google_genai-1.24.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting grpcio<2.0.0,>=1.67.1 (from deepeval)\n",
      "  Downloading grpcio-1.73.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: nest_asyncio in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (1.6.0)\n",
      "Collecting ollama (from deepeval)\n",
      "  Using cached ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (1.93.1)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Using cached opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: portalocker in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (3.2.0)\n",
      "Collecting posthog<4.0.0,>=3.23.0 (from deepeval)\n",
      "  Using cached posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pyfiglet (from deepeval)\n",
      "  Using cached pyfiglet-1.0.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pytest in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (8.4.1)\n",
      "Collecting pytest-asyncio (from deepeval)\n",
      "  Using cached pytest_asyncio-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pytest-repeat (from deepeval)\n",
      "  Using cached pytest_repeat-0.9.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pytest-rerunfailures<13.0,>=12.0 (from deepeval)\n",
      "  Using cached pytest_rerunfailures-12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pytest-xdist in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (3.8.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (2.32.3)\n",
      "Collecting rich<14.0.0,>=13.6.0 (from deepeval)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sentry-sdk in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (2.32.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (80.8.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (0.9.0)\n",
      "Collecting tenacity<=9.0.0 (from deepeval)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (4.67.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (0.16.0)\n",
      "Requirement already satisfied: wheel in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from deepeval) (0.45.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (4.9.0)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-genai<2.0.0,>=1.9.0->deepeval)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (2.11.7)\n",
      "Collecting tenacity<=9.0.0 (from deepeval)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.9.0->deepeval)\n",
      "  Using cached websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.9.0->deepeval) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.9.0->deepeval) (1.3.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.16.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.24.0->deepeval)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Using cached opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.34.1->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Using cached protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval)\n",
      "  Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from posthog<4.0.0,>=3.23.0->deepeval) (1.17.0)\n",
      "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.23.0->deepeval)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from posthog<4.0.0,>=3.23.0->deepeval) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from posthog<4.0.0,>=3.23.0->deepeval) (2.9.0.post0)\n",
      "Requirement already satisfied: distro>=1.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from posthog<4.0.0,>=3.23.0->deepeval) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2.0.0,>=1.9.0->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2.0.0,>=1.9.0->deepeval) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2.0.0,>=1.9.0->deepeval) (0.4.1)\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest-rerunfailures<13.0,>=12.0->deepeval) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (2.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from rich<14.0.0,>=13.6.0->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from rich<14.0.0,>=13.6.0->deepeval) (2.19.2)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from typer<1.0.0,>=0.9->deepeval) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->deepeval) (0.1.2)\n",
      "Requirement already satisfied: iniconfig>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest->deepeval) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest->deepeval) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp->deepeval) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp->deepeval) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp->deepeval) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp->deepeval) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp->deepeval) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp->deepeval) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from aiohttp->deepeval) (1.20.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from anthropic->deepeval) (0.10.0)\n",
      "Requirement already satisfied: execnet>=2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Using cached deepeval-3.2.4-py3-none-any.whl (577 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached google_genai-1.24.0-py3-none-any.whl (226 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.73.1-cp311-cp311-macosx_11_0_universal2.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m37.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Using cached posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
      "Using cached protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Using cached pytest_rerunfailures-12.0-py3-none-any.whl (12 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached anthropic-0.57.1-py3-none-any.whl (292 kB)\n",
      "Using cached ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Using cached pyfiglet-1.0.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached pytest_asyncio-1.0.0-py3-none-any.whl (15 kB)\n",
      "Using cached pytest_repeat-0.9.4-py3-none-any.whl (4.2 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade haystack-ai\n",
    "!pip install \"datasets>=2.6.1\"\n",
    "!pip install deepeval-haystack\n",
    "!pip install --upgrade deepeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ8IG4Hc12H3"
   },
   "source": [
    "## Create a RAG pipeline\n",
    "\n",
    "We'll first need to create a RAG pipeline. Refer to this [link](https://haystack.deepset.ai/tutorials/27_first_rag_pipeline) for a detailed tutorial on how to create RAG pipelines.\n",
    "\n",
    "In this notebook, we're using the [SQUAD V2](https://huggingface.co/datasets/rajpurkar/squad_v2) dataset for getting the context, questions and ground truth answers.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do4z1oOdF-cM"
   },
   "source": [
    "**Initialize the document store**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "ecdd3039fab546b98285080b0154fd0b",
      "aa3bbecfe5944da284019aff8baf44ea",
      "2809adab6c6a432fae163c8e8590021c",
      "b8ca49ea0ee3418581c3e0d56e630c85",
      "b49dd1d055e246e8ab0bef9264a43e60",
      "942b6e576097465bac964355006473b1",
      "2e9a94bf99174fd08dc86a5e620b557a",
      "77c714ea90d94d668f76f6d6458af173",
      "556fb0c73f6342c6b40d532ad02d6002",
      "be7d0bc998854467897804c94410c087",
      "975275dbb3d2479e8d317ae14cac0054",
      "6e0b90efbdbe4f06bb4e4606374e24a0",
      "0562644fed5f48e8ad9732ef1147ddd9",
      "a90a1ef04530404fb837328d17a4842f",
      "4b56ff9a99e84d3980c6b941a7015dcb",
      "44caede104434cd5a75a3189d134cd01",
      "b80967d207704c66ac86d4b7bfb8a8c6",
      "32578965fe954d3e906a4e169a4ab018",
      "90df55f944a34dd19c5ef581dd10e8c7",
      "8b9384106cf34271ade70d362baad763",
      "4d89770dfd6440359c5503a7c67b948e",
      "ef55f8e3f86545dd85ffff9f0ec0eec8",
      "0e4232d17e96462e8e1a5ee08392438b",
      "f483cfc37e3943bd9a0437226f62894a",
      "d1ad1d5697214c1e83b11ec195896f0c",
      "1b63a3c82db44c77a17403b1decc2f99",
      "b65f056df8354207b251ab5ef6a707a2",
      "621e6dac0fa6454887265fdf7f8c14d3",
      "365eae22a84f465c9e2640ddd1ddbf31",
      "1244bf8ea208476cb2a1af7e9583cb51",
      "6d812678e25b4ec8abfde1a16d5cad4e",
      "a34410f9ce2a4050bb428c34e5312026",
      "555f0847214548739a4e17dba3ec7c06",
      "a8470fba6ab4420fb592c820906a7579",
      "07902c894aec4233887a1a903b0f112b",
      "27cb89f01c0546a2a06c96af28535448",
      "6dea007209214945b93b6bb9754a3185",
      "54d27ef845b840c7bd632e7616077777",
      "2599b9dffac047f3b8e4763ceb531f3a",
      "15333af214134573a64906c3dc6c650f",
      "b1109dbbca474bd399c2c37b3bbed5d3",
      "085f6a362bea4615a3018120e31e1056",
      "9cd5c8b2e8674dfb8cd82363bbab30fc",
      "476b58f1c20c4f3fa75f7db2d8959f22",
      "355fee969f7e4db5a5a4740321ec4b7f",
      "d8163e5759904ea68c8c2a341b2a7347",
      "3263d38faab14e13914c92e757882d6a",
      "db32838cce5741fabb9ad431fae28953",
      "79c748fea30c46349a7b584a28a12385",
      "df29c5b8cd18449d9f04a6e0ae7bccc1",
      "5e5bdc4043184b08a949a573bb20c0ec",
      "3ed06598cd5e46dc8252a3b066a348c4",
      "4f098711cab84ed9affd29e0ae89d020",
      "5a4659cf76c1464bac21f7b47b4234d6",
      "fc8f2d9d5e544036bcb41e9bf3ad4327"
     ]
    },
    "id": "Uj9layE_156i",
    "outputId": "c4df980e-7d34-40b0-a488-c9a00103f601"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "dataset = load_dataset(\"rajpurkar/squad_v2\", split=\"validation\")\n",
    "documents = list(set(dataset[\"context\"]))\n",
    "docs = [Document(content=doc) for doc in documents]\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6gKe995C3i7w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store, top_k=3)\n",
    "\n",
    "chat_message = ChatMessage.from_user(\n",
    "    text=\"\"\"Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "chat_prompt_builder = ChatPromptBuilder(template=[chat_message], required_variables=\"*\")\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6y3zWPoANjF"
   },
   "source": [
    "**Build the RAG pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kS4LMd_34-nF",
    "outputId": "45aac034-c86f-4607-9d31-96f6c5055b82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x14dbabc90>\n",
       "🚅 Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - chat_prompt_builder: ChatPromptBuilder\n",
       "  - llm: OpenAIChatGenerator\n",
       "  - answer_builder: AnswerBuilder\n",
       "🛤️ Connections\n",
       "  - retriever.documents -> chat_prompt_builder.documents (List[Document])\n",
       "  - retriever.documents -> answer_builder.documents (List[Document])\n",
       "  - chat_prompt_builder.prompt -> llm.messages (List[ChatMessage])\n",
       "  - llm.replies -> answer_builder.replies (List[ChatMessage])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"chat_prompt_builder\", chat_prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", chat_generator)\n",
    "rag_pipeline.add_component(name=\"answer_builder\", instance=AnswerBuilder())\n",
    "\n",
    "# Now, connect the components to each other\n",
    "rag_pipeline.connect(\"retriever\", \"chat_prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"chat_prompt_builder\", \"llm\")\n",
    "rag_pipeline.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "rag_pipeline.connect(\"retriever\", \"answer_builder.documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwr-T40DGF8G"
   },
   "source": [
    "**Running the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "162d29297c5f4dad98baca0794bb93fc",
      "acaa9927fcde4bcdb606107ac0265c6b",
      "d99d1dd68071439a966f63bd4e998db9",
      "efd288e1422142bc9bfe87c5528342ad",
      "c0764d64aa2f4e2484d8b2e2d228213c",
      "a2fff18ac8104547afd5d8d5369db7b7",
      "55b84b06a9fc417a90ee08ad622e3e92",
      "98d6d1ff6fe94c2889503aa6f03d2019",
      "3080f12af2814a1985146de24da50d99",
      "6cbfaa160fef4aeeb4f273d14ea896dd",
      "4a4ab3a911e747209b7520d72bbf9bfa"
     ]
    },
    "id": "7oo0rUas5Dvy",
    "outputId": "e033ddf0-5ed9-4c8c-ecbd-072240b46df0"
   },
   "outputs": [],
   "source": [
    "question = \"In what country is Normandy located?\"\n",
    "\n",
    "response = rag_pipeline.run(\n",
    "    {\"retriever\": {\"query\": question}, \"chat_prompt_builder\": {\"question\": question}, \"answer_builder\": {\"query\": question}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4RPE8zM_1G_",
    "outputId": "c5ca7276-39b8-4e16-dc86-1d107c5eb698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normandy is located in France.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer_builder\"][\"answers\"][0].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDciGcXVGNJD"
   },
   "source": [
    "We're done building our RAG pipeline. Let's evaluate it now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efVio5Dvlbto"
   },
   "source": [
    "## Get questions, contexts, responses and ground truths for evaluation\n",
    "\n",
    "For computing most metrics, we will need to provide the following to the evaluator:\n",
    "1. Questions\n",
    "2. Generated responses\n",
    "3. Retrieved contexts\n",
    "4. Ground truth (Specifically, this is needed for `context precision`, `context recall` and `answer correctness` metrics)\n",
    "\n",
    "We'll start with random three questions from the dataset (see below) and now we'll get the matching `contexts` and `responses` for those questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RC36ICOAXoI"
   },
   "source": [
    "### Helper function to get context and responses for our questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pXdJ6ZiGARyW"
   },
   "outputs": [],
   "source": [
    "def get_contexts_and_responses(questions, pipeline):\n",
    "    contexts = []\n",
    "    responses = []\n",
    "    for question in questions:\n",
    "        response = pipeline.run(\n",
    "            {\n",
    "                \"retriever\": {\"query\": question},\n",
    "                \"chat_prompt_builder\": {\"question\": question},\n",
    "                \"answer_builder\": {\"query\": question},\n",
    "            }\n",
    "        )\n",
    "\n",
    "        contexts.append([d.content for d in response[\"answer_builder\"][\"answers\"][0].documents])\n",
    "        responses.append(response[\"answer_builder\"][\"answers\"][0].data)\n",
    "    return contexts, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82350be333ab4ec49f0f3f26162e02be",
      "b210ca088d55443389cc03fcda3cc166",
      "3da15c7e57fa461bad6ee4a41a7ee6be",
      "4fc7fe98ed9e43fa96c3e862f24518a5",
      "420fb1c93d2b4b5daffb4bd40261172e",
      "d56fd76a836c4f8f82b5a7c808db0a53",
      "27f25685cd504798b38ad8147b0bd6e0",
      "fe57e53818254848bd2dbb062fed1eca",
      "8770ef290a2b4174845a8307197e0701",
      "21a6ebf4d82645b5b4182ac62f6bb8a3",
      "675904b673ca4c578ef16a777995b8d4",
      "f0c3a912ceaa4c1b8a7c52bea3828164",
      "fa3931c092f34303af88c945b8140e04",
      "59b9c475c5cd44aa845a7dda92969997",
      "d9dd9e05c1b94bf280a0b3bf1b6e526c",
      "5426fbb2f2fd457c98e943b59d214d2c",
      "74f15702bb124e90b8881bc416c5d2e2",
      "9037f3bdb47947f18ac3a324148a25ba",
      "fa08ed9dbc194258941821dd61025870",
      "1e21a8520b1a49d1a53e63404381711a",
      "27f6523d465644fcaf5304299a8c163e",
      "0dd84bad8d224269828a0c1ec0a582fc",
      "25e0e8b60e394420b8cf05f16e4a6ca6",
      "b09fb1900d114728ad51fe27f93ae23b",
      "9c536b1ace0e44ef8c16b0578fd6b3af",
      "f0fa88ba58084418a8cfa3e8cd39ef5b",
      "9525696cd0b848f7a0213d774d221081",
      "9b235a93badf4901ad3f5b8c9c5d1cb4",
      "8949db0390d942a0a13269e6aba5bc9d",
      "e40d267e3ef44557a4b0eab36e0ce339",
      "5a6df8e408d143ff86952d6b3150632f",
      "bba0ef9673ed46b79c051b0befa1139b",
      "7ac2fa06b6af43ce8c93d45bd09410cc"
     ]
    },
    "id": "EiZjPznwAU5p",
    "outputId": "d8b0f4aa-a49a-4e04-cfbf-f7dce18f2173"
   },
   "outputs": [],
   "source": [
    "question_map = {\n",
    "    \"Which mountain range influenced the split of the regions?\": 0,\n",
    "    \"What is the prize offered for finding a solution to P=NP?\": 1,\n",
    "    \"Which Californio is located in the upper part?\": 2\n",
    "}\n",
    "questions = list(question_map.keys())\n",
    "contexts, responses = get_contexts_and_responses(questions, rag_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5Ju5G8KlxMr"
   },
   "source": [
    "### Ground truths, review all fields\n",
    "\n",
    "Now that we have questions, contexts, and responses we'll also get the matching ground truth answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C5N0SxnCbwQj"
   },
   "outputs": [],
   "source": [
    "ground_truths = [\"\"] * len(question_map)\n",
    "\n",
    "for question, index in question_map.items():\n",
    "    idx = dataset[\"question\"].index(question)\n",
    "    ground_truths[index] = dataset[\"answers\"][idx][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaTQo7tpbxyw",
    "outputId": "7de7c544-c6ce-4d7e-96ea-4e63310b25a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "\n",
      "Which mountain range influenced the split of the regions?\n",
      "What is the prize offered for finding a solution to P=NP?\n",
      "Which Californio is located in the upper part?\n"
     ]
    }
   ],
   "source": [
    "print(\"Questions:\\n\")\n",
    "print(\"\\n\".join(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DkbMXXkdzEC",
    "outputId": "83ea0f55-5f9d-430e-a219-c6fdae6c9ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexts:\n",
      "\n",
      "The state is most commonly divided and promoted by its regional tourism groups as consisting of northern, central, and southern California regions. The two AAA Auto Clubs of the state, the California State Automobile Association and the Automobile Club of Southern California, choose to simplify matters by dividing the state along the lines where their jurisdictions for membership apply, as either northern or southern California, in contrast to the three-region point of view. Another influence is the geographical phrase South of the Tehachapis, which would split the southern region off at the crest of that transverse range, but in that definition, the desert portions of north Los Angeles County and eastern Kern and San Bernardino Counties would be included in the southern California region due to their remoteness from the central valley and interior desert landscape.\n",
      "If a problem X is in C and hard for C, then X is said to be complete for C. This means that X is the hardest problem in C. (Since many problems could be equally hard, one might say that X is one of the hardest problems in C.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce a known NP-complete problem, Π2, to another problem, Π1, would indicate that there is no known polynomial-time solution for Π1. This is because a polynomial-time solution to Π1 would yield a polynomial-time solution to Π2. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that can be solved in polynomial time would mean that P = NP.\n",
      "In the centre of Basel, the first major city in the course of the stream, is located the \"Rhine knee\"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin.\n"
     ]
    }
   ],
   "source": [
    "print(\"Contexts:\\n\")\n",
    "for c in contexts:\n",
    "  print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_ssY9IAfc9U",
    "outputId": "d69a561a-e98e-40e0-9a89-e4db4af61086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses:\n",
      "\n",
      "The Tehachapi Mountains influenced the split of the regions, specifically the division between northern and southern California.\n",
      "The prize offered for finding a solution to the P vs NP problem is US$1,000,000.\n",
      "The term \"Californio\" typically refers to the Spanish-speaking inhabitants of California during the period of Mexican rule from 1821 to 1848. However, the provided context does not contain information relevant to Californios or their geographical locations. If you are referring to a specific aspect related to Californios or a particular individual, please provide more context or clarity for a more accurate response.\n"
     ]
    }
   ],
   "source": [
    "print(\"Responses:\\n\")\n",
    "print(\"\\n\".join(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qT8fBFwYNUX",
    "outputId": "454ee979-0ae4-439a-8482-7245b5dec72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truths:\n",
      "\n",
      "Tehachapis\n",
      "$1,000,000\n",
      "Monterey\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground truths:\\n\")\n",
    "print(\"\\n\".join(ground_truths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geGTaUYtAf05"
   },
   "source": [
    "## Evaluate the RAG pipeline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MixUQOMJGprR"
   },
   "source": [
    "Now that we have the `questions`, `contexts`,`responses` and the `ground truths`, we can begin our pipeline evaluation and compute all the supported metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ge_aouohGBo"
   },
   "source": [
    "## Metrics computation\n",
    "\n",
    "In addition to evaluating the final responses of the LLM, it is important that we also evaluate the individual components of the RAG pipeline as they can significantly impact the overall performance. Therefore, there are different metrics to evaluate the retriever, the generator and the overall pipeline. For a full list of available metrics and their expected inputs, check out the [DeepEvalEvaluator Docs](https://docs.haystack.deepset.ai/docs/deepevalevaluator)\n",
    "\n",
    "The [DeepEval documentation](https://docs.confident-ai.com/docs/metrics-introduction) provides explanation of the individual metrics with simple examples for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PllEAyisEG2l"
   },
   "source": [
    "### Contextul Precision\n",
    "\n",
    "The contextual precision metric measures our RAG pipeline's retriever by evaluating whether items in our contexts that are relevant to the given input are ranked higher than irrelevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6qmXfqmnFaSH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/__init__.py:39: UserWarning: You are using deepeval version 0.20.57, however version 3.2.4 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepeval.evaluate.types'; 'deepeval.evaluate' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhaystack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhaystack_integrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomponents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeepeval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepEvalEvaluator, DeepEvalMetric\n\u001b[32m      4\u001b[39m context_precision_pipeline = Pipeline()\n\u001b[32m      5\u001b[39m evaluator = DeepEvalEvaluator(metric=DeepEvalMetric.CONTEXTUAL_PRECISION, metric_params={\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/haystack_integrations/components/evaluators/deepeval/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepEvalEvaluator\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepEvalMetric\n\u001b[32m      4\u001b[39m __all__ = (\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDeepEvalEvaluator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDeepEvalMetric\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/haystack_integrations/components/evaluators/deepeval/evaluator.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhaystack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeserializationError, component, default_from_dict, default_to_dict\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepeval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepeval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluate\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvaluationResult\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepeval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseMetric\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepeval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtest_case\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMTestCase\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'deepeval.evaluate.types'; 'deepeval.evaluate' is not a package"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.deepeval import DeepEvalEvaluator, DeepEvalMetric\n",
    "\n",
    "context_precision_pipeline = Pipeline()\n",
    "evaluator = DeepEvalEvaluator(metric=DeepEvalMetric.CONTEXTUAL_PRECISION, metric_params={\"model\":\"gpt-4o-mini\"})\n",
    "context_precision_pipeline.add_component(\"evaluator\", evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0e7eafde72c34a58a822af793b4bfeb9",
      "60d1e49ed7564aa0a3ae5fb87287a118",
      "6dccecdd0a82418a987914dddc64dc92",
      "0e0ee9fb22d648b2b1c2acb4b6a09732",
      "f353551fe7894653b2c1a7d9c6a449a7",
      "67dc3c5b24fc433e9c34ab8faa5e58e0",
      "6dcc415dd1e5430dbfdba67a94f81aac",
      "e2c57c3decf744afa591e6021ec9b1c0"
     ]
    },
    "id": "KAanj3XTFeIz",
    "outputId": "c7ea13fd-a7e8-46e2-8c50-fc2251b8b1c4"
   },
   "outputs": [],
   "source": [
    "evaluation_results = context_precision_pipeline.run(\n",
    "    {\"evaluator\": {\"questions\": questions, \"contexts\": contexts, \"ground_truths\": ground_truths, \"responses\": responses}}\n",
    ")\n",
    "print(evaluation_results[\"evaluator\"][\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6T-x33AERO1"
   },
   "source": [
    "### Contextual Recall\n",
    "\n",
    "Contextual recall measures the extent to which the contexts aligns with the `ground truth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UFB89BwJFs1O"
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.deepeval import DeepEvalEvaluator, DeepEvalMetric\n",
    "\n",
    "context_recall_pipeline = Pipeline()\n",
    "evaluator = DeepEvalEvaluator(metric=DeepEvalMetric.CONTEXTUAL_RECALL, metric_params={\"model\":\"gpt-4\"})\n",
    "context_recall_pipeline.add_component(\"evaluator\", evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "36010e88333341d69c6bffb22658a99f",
      "391619c636794697ac60d3b7c9cc04a6",
      "bc0a96ed84f24f91ac9ec7877459c5ee",
      "62107ac42cd64349859a040cf54e960a",
      "d56c6ef249884e22a5bc580cc2f26576",
      "dc28afbdea4a4c94b24bbada0f693096",
      "99d9b2c90ca541249deca02e8878abac",
      "9a8c1fa4fda74964b3cd1a00f97df713"
     ]
    },
    "id": "L_0vM4ryFuOc",
    "outputId": "3e01d702-fe52-4349-dcab-88e2233e6857"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - input: Which Californio is located in the upper part?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - input: Which Californio is located in the upper part?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - actual output: The provided context does not give any specific information regarding Californios or their \n",
       "locations. Therefore, I cannot determine which Californio is located in the upper part based on the information \n",
       "given. If you have additional context or specific details about Californios that you would like to share, I would \n",
       "be happy to assist further.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - actual output: The provided context does not give any specific information regarding Californios or their \n",
       "locations. Therefore, I cannot determine which Californio is located in the upper part based on the information \n",
       "given. If you have additional context or specific details about Californios that you would like to share, I would \n",
       "be happy to assist further.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - expected output: Monterey\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - expected output: Monterey\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - context: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - context: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - retrieval context: ['In the centre of Basel, the first major city in the course of the stream, is located the \n",
       "\"Rhine knee\"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the \n",
       "High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows \n",
       "North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most \n",
       "important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from\n",
       "Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin.', 'From the death of \n",
       "Augustus in AD 14 until after AD 70, Rome accepted as her Germanic frontier the water-boundary of the Rhine and \n",
       "upper Danube. Beyond these rivers she held only the fertile plain of Frankfurt, opposite the Roman border fortress \n",
       "of Moguntiacum (Mainz), the southernmost slopes of the Black Forest and a few scattered bridge-heads. The northern \n",
       "section of this frontier, where the Rhine is deep and broad, remained the Roman boundary until the empire fell. The\n",
       "southern part was different. The upper Rhine and upper Danube are easily crossed. The frontier which they form is \n",
       "inconveniently long, enclosing an acute-angled wedge of foreign territory between the modern Baden and Württemberg.\n",
       "The Germanic populations of these lands seem in Roman times to have been scanty, and Roman subjects from the modern\n",
       "Alsace-Lorraine had drifted across the river eastwards.', \"In the 1960s, a series of discoveries, the most \n",
       "important of which was seafloor spreading, showed that the Earth's lithosphere, which includes the crust and rigid \n",
       "uppermost portion of the upper mantle, is separated into a number of tectonic plates that move across the \n",
       "plastically deforming, solid, upper mantle, which is called the asthenosphere. There is an intimate coupling \n",
       "between the movement of the plates on the surface and the convection of the mantle: oceanic plate motions and \n",
       "mantle convection currents always move in the same direction, because the oceanic lithosphere is the rigid upper \n",
       "thermal boundary layer of the convecting mantle. This coupling between rigid plates moving on the surface of the \n",
       "Earth and the convecting mantle is called plate tectonics.\"]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - retrieval context: ['In the centre of Basel, the first major city in the course of the stream, is located the \n",
       "\"Rhine knee\"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the \n",
       "High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows \n",
       "North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most \n",
       "important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from\n",
       "Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin.', 'From the death of \n",
       "Augustus in AD 14 until after AD 70, Rome accepted as her Germanic frontier the water-boundary of the Rhine and \n",
       "upper Danube. Beyond these rivers she held only the fertile plain of Frankfurt, opposite the Roman border fortress \n",
       "of Moguntiacum (Mainz), the southernmost slopes of the Black Forest and a few scattered bridge-heads. The northern \n",
       "section of this frontier, where the Rhine is deep and broad, remained the Roman boundary until the empire fell. The\n",
       "southern part was different. The upper Rhine and upper Danube are easily crossed. The frontier which they form is \n",
       "inconveniently long, enclosing an acute-angled wedge of foreign territory between the modern Baden and Württemberg.\n",
       "The Germanic populations of these lands seem in Roman times to have been scanty, and Roman subjects from the modern\n",
       "Alsace-Lorraine had drifted across the river eastwards.', \"In the 1960s, a series of discoveries, the most \n",
       "important of which was seafloor spreading, showed that the Earth's lithosphere, which includes the crust and rigid \n",
       "uppermost portion of the upper mantle, is separated into a number of tectonic plates that move across the \n",
       "plastically deforming, solid, upper mantle, which is called the asthenosphere. There is an intimate coupling \n",
       "between the movement of the plates on the surface and the convection of the mantle: oceanic plate motions and \n",
       "mantle convection currents always move in the same direction, because the oceanic lithosphere is the rigid upper \n",
       "thermal boundary layer of the convecting mantle. This coupling between rigid plates moving on the surface of the \n",
       "Earth and the convecting mantle is called plate tectonics.\"]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇</span> Evaluating testcases...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m⠇\u001b[0m Evaluating testcases...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'name': 'contextual_recall', 'score': 1.0, 'explanation': \"The score is 1.00 because every aspect of the expected output was successfully found in the retrieval context. Great work matching 'Tehachapis' to the information provided in the 1st node!\"}], [{'name': 'contextual_recall', 'score': 1.0, 'explanation': \"The score is 1.00 because the expected output, '$1,000,000', is precisely matched in the 2nd node in retrieval context which makes it perfectly accurate. There's no element missing or unaccounted for, hence the perfect score. Well done!\"}], [{'name': 'contextual_recall', 'score': 0.0, 'explanation': \"The score is 0.00 because the sentence 'Monterey' in the expected output could not be attributed to any node in the retrieval context.\"}]]\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = context_recall_pipeline.run(\n",
    "    {\"evaluator\": {\"questions\": questions, \"contexts\": contexts, \"ground_truths\": ground_truths, \"responses\": responses}}\n",
    ")\n",
    "print(evaluation_results[\"evaluator\"][\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_91cVvZEfuk"
   },
   "source": [
    "### Contextual Relevancy\n",
    "\n",
    "The contextual relevancy metric measures the quality of our RAG pipeline's retriever by evaluating the overall relevance of the context for a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eIQqeX7cF_a6"
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.deepeval import DeepEvalEvaluator, DeepEvalMetric\n",
    "\n",
    "context_relevancy_pipeline = Pipeline()\n",
    "evaluator = DeepEvalEvaluator(metric=DeepEvalMetric.CONTEXTUAL_RELEVANCE, metric_params={\"model\":\"gpt-4\"})\n",
    "context_relevancy_pipeline.add_component(\"evaluator\", evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "529e0a3f1bb94633b3a7ef3465025eb1",
      "f037a8d0089a4628991a70ed217095b0",
      "713f9175346140a6a8b5a60915ec3eb2",
      "35da6c45d95540c883b87df1985a530d",
      "72fa3d3d04f54f91be7dd6429721c6e5",
      "191ecf80edfd4653b01a69428d560032",
      "afed416a13094ef69b4cdebb0bb056bc",
      "9de852d380924ba4a8ffd526b18babf5"
     ]
    },
    "id": "XCfENS79GCsj",
    "outputId": "61ab013d-d7d5-4651-ddce-a02fca56ac63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠙</span> Evaluating testcases...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m⠙\u001b[0m Evaluating testcases...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "======================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Metrics Summary\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Metrics Summary\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - ✅ Contextual Relevancy (score: 0.5, threshold: 0.0, evaluation model: gpt-4, reason: The score is 0.50 because\n",
       "the irrelevant sentences mainly discuss temperature data in Victoria and regional divisions in California, instead \n",
       "of addressing the influence of a mountain range on the splitting of regions. Although these sentences pertain to \n",
       "geographical features and characteristics, they do not directly respond to the specific query regarding mountain \n",
       "ranges' impact on regional splits.)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - ✅ Contextual Relevancy (score: 0.5, threshold: 0.0, evaluation model: gpt-4, reason: The score is 0.50 because\n",
       "the irrelevant sentences mainly discuss temperature data in Victoria and regional divisions in California, instead \n",
       "of addressing the influence of a mountain range on the splitting of regions. Although these sentences pertain to \n",
       "geographical features and characteristics, they do not directly respond to the specific query regarding mountain \n",
       "ranges' impact on regional splits.)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For test case:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "For test case:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - input: Which mountain range influenced the split of the regions?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - input: Which mountain range influenced the split of the regions?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - actual output: The mountain range that influenced the split of the regions is the Tehachapi Mountains.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - actual output: The mountain range that influenced the split of the regions is the Tehachapi Mountains.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - expected output: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - expected output: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - context: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - context: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - retrieval context: ['The state is most commonly divided and promoted by its regional tourism groups as \n",
       "consisting of northern, central, and southern California regions. The two AAA Auto Clubs of the state, the \n",
       "California State Automobile Association and the Automobile Club of Southern California, choose to simplify matters \n",
       "by dividing the state along the lines where their jurisdictions for membership apply, as either northern or \n",
       "southern California, in contrast to the three-region point of view. Another influence is the geographical phrase \n",
       "South of the Tehachapis, which would split the southern region off at the crest of that transverse range, but in \n",
       "that definition, the desert portions of north Los Angeles County and eastern Kern and San Bernardino Counties would\n",
       "be included in the southern California region due to their remoteness from the central valley and interior desert \n",
       "landscape.', 'Among the most well-known experiments in structural geology are those involving orogenic wedges, \n",
       "which are zones in which mountains are built along convergent tectonic plate boundaries. In the analog versions of \n",
       "these experiments, horizontal layers of sand are pulled along a lower surface into a back stop, which results in \n",
       "realistic-looking patterns of faulting and the growth of a critically tapered (all angles remain the same) orogenic\n",
       "wedge. Numerical models work in the same way as these analog models, though they are often more sophisticated and \n",
       "can include patterns of erosion and uplift in the mountain belt. This helps to show the relationship between \n",
       "erosion and the shape of the mountain range. These studies can also give useful information about pathways for \n",
       "metamorphism through pressure, temperature, space, and time.', \"The Mallee and upper Wimmera are Victoria's warmest\n",
       "regions with hot winds blowing from nearby semi-deserts. Average temperatures exceed 32 °C (90 °F) during summer \n",
       "and 15 °C (59 °F) in winter. Except at cool mountain elevations, the inland monthly temperatures are 2–7 °C (4–13 \n",
       "°F) warmer than around Melbourne (see chart). Victoria's highest maximum temperature since World War II, of 48.8 °C\n",
       "(119.8 °F) was recorded in Hopetoun on 7 February 2009, during the 2009 southeastern Australia heat wave.\"]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - retrieval context: ['The state is most commonly divided and promoted by its regional tourism groups as \n",
       "consisting of northern, central, and southern California regions. The two AAA Auto Clubs of the state, the \n",
       "California State Automobile Association and the Automobile Club of Southern California, choose to simplify matters \n",
       "by dividing the state along the lines where their jurisdictions for membership apply, as either northern or \n",
       "southern California, in contrast to the three-region point of view. Another influence is the geographical phrase \n",
       "South of the Tehachapis, which would split the southern region off at the crest of that transverse range, but in \n",
       "that definition, the desert portions of north Los Angeles County and eastern Kern and San Bernardino Counties would\n",
       "be included in the southern California region due to their remoteness from the central valley and interior desert \n",
       "landscape.', 'Among the most well-known experiments in structural geology are those involving orogenic wedges, \n",
       "which are zones in which mountains are built along convergent tectonic plate boundaries. In the analog versions of \n",
       "these experiments, horizontal layers of sand are pulled along a lower surface into a back stop, which results in \n",
       "realistic-looking patterns of faulting and the growth of a critically tapered (all angles remain the same) orogenic\n",
       "wedge. Numerical models work in the same way as these analog models, though they are often more sophisticated and \n",
       "can include patterns of erosion and uplift in the mountain belt. This helps to show the relationship between \n",
       "erosion and the shape of the mountain range. These studies can also give useful information about pathways for \n",
       "metamorphism through pressure, temperature, space, and time.', \"The Mallee and upper Wimmera are Victoria's warmest\n",
       "regions with hot winds blowing from nearby semi-deserts. Average temperatures exceed 32 °C (90 °F) during summer \n",
       "and 15 °C (59 °F) in winter. Except at cool mountain elevations, the inland monthly temperatures are 2–7 °C (4–13 \n",
       "°F) warmer than around Melbourne (see chart). Victoria's highest maximum temperature since World War II, of 48.8 °C\n",
       "(119.8 °F) was recorded in Hopetoun on 7 February 2009, during the 2009 southeastern Australia heat wave.\"]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "======================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Metrics Summary\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Metrics Summary\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - ✅ Contextual Relevancy (score: 0.46153846153846156, threshold: 0.0, evaluation model: gpt-4, reason: The score\n",
       "is 0.46 because the irrelevant sentences, drawn from nodes 2 and 3 of the retrieval context, delve into discussions\n",
       "and complex examples of computational problem-solving, without directly addressing the specific query of the prize \n",
       "offered for a solution to P=NP.)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - ✅ Contextual Relevancy (score: 0.46153846153846156, threshold: 0.0, evaluation model: gpt-4, reason: The score\n",
       "is 0.46 because the irrelevant sentences, drawn from nodes 2 and 3 of the retrieval context, delve into discussions\n",
       "and complex examples of computational problem-solving, without directly addressing the specific query of the prize \n",
       "offered for a solution to P=NP.)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For test case:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "For test case:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - input: What is the prize offered for finding a solution to P=NP?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - input: What is the prize offered for finding a solution to P=NP?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - actual output: The prize offered for finding a solution to the P versus NP problem is US$1,000,000.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - actual output: The prize offered for finding a solution to the P versus NP problem is US$1,000,000.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - expected output: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - expected output: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - context: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - context: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - retrieval context: ['If a problem X is in C and hard for C, then X is said to be complete for C. This means \n",
       "that X is the hardest problem in C. (Since many problems could be equally hard, one might say that X is one of the \n",
       "hardest problems in C.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the \n",
       "sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to \n",
       "reduce a known NP-complete problem, Π2, to another problem, Π1, would indicate that there is no known \n",
       "polynomial-time solution for Π1. This is because a polynomial-time solution to Π1 would yield a polynomial-time \n",
       "solution to Π2. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that \n",
       "can be solved in polynomial time would mean that P = NP.', 'The question of whether P equals NP is one of the most \n",
       "important open questions in theoretical computer science because of the wide implications of a solution. If the \n",
       "answer is yes, many important problems can be shown to have more efficient solutions. These include various types \n",
       "of integer programming problems in operations research, many problems in logistics, protein structure prediction in\n",
       "biology, and the ability to find formal proofs of pure mathematics theorems. The P versus NP problem is one of the \n",
       "Millennium Prize Problems proposed by the Clay Mathematics Institute. There is a US$1,000,000 prize for resolving \n",
       "the problem.', 'What intractability means in practice is open to debate. Saying that a problem is not in P does not\n",
       "imply that all large cases of the problem are hard or even that most of them are. For example, the decision problem\n",
       "in Presburger arithmetic has been shown not to be in P, yet algorithms have been written that solve the problem in \n",
       "reasonable times in most cases. Similarly, algorithms can solve the NP-complete knapsack problem over a wide range \n",
       "of sizes in less than quadratic time and SAT solvers routinely handle large instances of the NP-complete Boolean \n",
       "satisfiability problem.']\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - retrieval context: ['If a problem X is in C and hard for C, then X is said to be complete for C. This means \n",
       "that X is the hardest problem in C. (Since many problems could be equally hard, one might say that X is one of the \n",
       "hardest problems in C.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the \n",
       "sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to \n",
       "reduce a known NP-complete problem, Π2, to another problem, Π1, would indicate that there is no known \n",
       "polynomial-time solution for Π1. This is because a polynomial-time solution to Π1 would yield a polynomial-time \n",
       "solution to Π2. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that \n",
       "can be solved in polynomial time would mean that P = NP.', 'The question of whether P equals NP is one of the most \n",
       "important open questions in theoretical computer science because of the wide implications of a solution. If the \n",
       "answer is yes, many important problems can be shown to have more efficient solutions. These include various types \n",
       "of integer programming problems in operations research, many problems in logistics, protein structure prediction in\n",
       "biology, and the ability to find formal proofs of pure mathematics theorems. The P versus NP problem is one of the \n",
       "Millennium Prize Problems proposed by the Clay Mathematics Institute. There is a US$1,000,000 prize for resolving \n",
       "the problem.', 'What intractability means in practice is open to debate. Saying that a problem is not in P does not\n",
       "imply that all large cases of the problem are hard or even that most of them are. For example, the decision problem\n",
       "in Presburger arithmetic has been shown not to be in P, yet algorithms have been written that solve the problem in \n",
       "reasonable times in most cases. Similarly, algorithms can solve the NP-complete knapsack problem over a wide range \n",
       "of sizes in less than quadratic time and SAT solvers routinely handle large instances of the NP-complete Boolean \n",
       "satisfiability problem.']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "======================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Metrics Summary\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Metrics Summary\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - ✅ Contextual Relevancy (score: 0.0, threshold: 0.0, evaluation model: gpt-4, reason: The score is 0.00 because\n",
       "the input question is asking about a Californio in a specific location, however, all of the provided sentences in \n",
       "the retrieval context are discussing geological topics, such as plate tectonics, and geographical locations, like \n",
       "the Rhine River and Roman boundaries. None of these details are relevant to the Californio the question is \n",
       "referring to, hence, a score of zero.)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - ✅ Contextual Relevancy (score: 0.0, threshold: 0.0, evaluation model: gpt-4, reason: The score is 0.00 because\n",
       "the input question is asking about a Californio in a specific location, however, all of the provided sentences in \n",
       "the retrieval context are discussing geological topics, such as plate tectonics, and geographical locations, like \n",
       "the Rhine River and Roman boundaries. None of these details are relevant to the Californio the question is \n",
       "referring to, hence, a score of zero.)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For test case:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "For test case:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - input: Which Californio is located in the upper part?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - input: Which Californio is located in the upper part?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - actual output: The provided context does not give any specific information regarding Californios or their \n",
       "locations. Therefore, I cannot determine which Californio is located in the upper part based on the information \n",
       "given. If you have additional context or specific details about Californios that you would like to share, I would \n",
       "be happy to assist further.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - actual output: The provided context does not give any specific information regarding Californios or their \n",
       "locations. Therefore, I cannot determine which Californio is located in the upper part based on the information \n",
       "given. If you have additional context or specific details about Californios that you would like to share, I would \n",
       "be happy to assist further.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - expected output: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - expected output: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - context: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - context: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - retrieval context: ['In the centre of Basel, the first major city in the course of the stream, is located the \n",
       "\"Rhine knee\"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the \n",
       "High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows \n",
       "North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most \n",
       "important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from\n",
       "Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin.', 'From the death of \n",
       "Augustus in AD 14 until after AD 70, Rome accepted as her Germanic frontier the water-boundary of the Rhine and \n",
       "upper Danube. Beyond these rivers she held only the fertile plain of Frankfurt, opposite the Roman border fortress \n",
       "of Moguntiacum (Mainz), the southernmost slopes of the Black Forest and a few scattered bridge-heads. The northern \n",
       "section of this frontier, where the Rhine is deep and broad, remained the Roman boundary until the empire fell. The\n",
       "southern part was different. The upper Rhine and upper Danube are easily crossed. The frontier which they form is \n",
       "inconveniently long, enclosing an acute-angled wedge of foreign territory between the modern Baden and Württemberg.\n",
       "The Germanic populations of these lands seem in Roman times to have been scanty, and Roman subjects from the modern\n",
       "Alsace-Lorraine had drifted across the river eastwards.', \"In the 1960s, a series of discoveries, the most \n",
       "important of which was seafloor spreading, showed that the Earth's lithosphere, which includes the crust and rigid \n",
       "uppermost portion of the upper mantle, is separated into a number of tectonic plates that move across the \n",
       "plastically deforming, solid, upper mantle, which is called the asthenosphere. There is an intimate coupling \n",
       "between the movement of the plates on the surface and the convection of the mantle: oceanic plate motions and \n",
       "mantle convection currents always move in the same direction, because the oceanic lithosphere is the rigid upper \n",
       "thermal boundary layer of the convecting mantle. This coupling between rigid plates moving on the surface of the \n",
       "Earth and the convecting mantle is called plate tectonics.\"]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - retrieval context: ['In the centre of Basel, the first major city in the course of the stream, is located the \n",
       "\"Rhine knee\"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the \n",
       "High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows \n",
       "North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most \n",
       "important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from\n",
       "Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin.', 'From the death of \n",
       "Augustus in AD 14 until after AD 70, Rome accepted as her Germanic frontier the water-boundary of the Rhine and \n",
       "upper Danube. Beyond these rivers she held only the fertile plain of Frankfurt, opposite the Roman border fortress \n",
       "of Moguntiacum (Mainz), the southernmost slopes of the Black Forest and a few scattered bridge-heads. The northern \n",
       "section of this frontier, where the Rhine is deep and broad, remained the Roman boundary until the empire fell. The\n",
       "southern part was different. The upper Rhine and upper Danube are easily crossed. The frontier which they form is \n",
       "inconveniently long, enclosing an acute-angled wedge of foreign territory between the modern Baden and Württemberg.\n",
       "The Germanic populations of these lands seem in Roman times to have been scanty, and Roman subjects from the modern\n",
       "Alsace-Lorraine had drifted across the river eastwards.', \"In the 1960s, a series of discoveries, the most \n",
       "important of which was seafloor spreading, showed that the Earth's lithosphere, which includes the crust and rigid \n",
       "uppermost portion of the upper mantle, is separated into a number of tectonic plates that move across the \n",
       "plastically deforming, solid, upper mantle, which is called the asthenosphere. There is an intimate coupling \n",
       "between the movement of the plates on the surface and the convection of the mantle: oceanic plate motions and \n",
       "mantle convection currents always move in the same direction, because the oceanic lithosphere is the rigid upper \n",
       "thermal boundary layer of the convecting mantle. This coupling between rigid plates moving on the surface of the \n",
       "Earth and the convecting mantle is called plate tectonics.\"]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'name': 'contextual_relevance', 'score': 0.5, 'explanation': \"The score is 0.50 because the irrelevant sentences mainly discuss temperature data in Victoria and regional divisions in California, instead of addressing the influence of a mountain range on the splitting of regions. Although these sentences pertain to geographical features and characteristics, they do not directly respond to the specific query regarding mountain ranges' impact on regional splits.\"}], [{'name': 'contextual_relevance', 'score': 0.46153846153846156, 'explanation': 'The score is 0.46 because the irrelevant sentences, drawn from nodes 2 and 3 of the retrieval context, delve into discussions and complex examples of computational problem-solving, without directly addressing the specific query of the prize offered for a solution to P=NP.'}], [{'name': 'contextual_relevance', 'score': 0.0, 'explanation': 'The score is 0.00 because the input question is asking about a Californio in a specific location, however, all of the provided sentences in the retrieval context are discussing geological topics, such as plate tectonics, and geographical locations, like the Rhine River and Roman boundaries. None of these details are relevant to the Californio the question is referring to, hence, a score of zero.'}]]\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = context_relevancy_pipeline.run(\n",
    "    {\"evaluator\": {\"questions\": questions, \"contexts\": contexts, \"responses\": responses}}\n",
    ")\n",
    "print(evaluation_results[\"evaluator\"][\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKkYIq3OEivN"
   },
   "source": [
    "### Answer relevancy\n",
    "\n",
    "The answer relevancy metric measures the quality of our RAG pipeline's response by evaluating how relevant the response is compared to the provided question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "WV67fOajMbkF"
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.deepeval import DeepEvalEvaluator, DeepEvalMetric\n",
    "\n",
    "answer_relevancy_pipeline = Pipeline()\n",
    "evaluator = DeepEvalEvaluator(metric=DeepEvalMetric.ANSWER_RELEVANCY, metric_params={\"model\":\"gpt-4\"})\n",
    "answer_relevancy_pipeline.add_component(\"evaluator\", evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f1639c9c99a846d7a17aee870ff80d98",
      "3bb9e44e17ec4f3986378ddb3c1255c4",
      "e36f222e6b3946e6a1ed1e4c71ea31be",
      "1559b47643e4481483256713396bf4da",
      "d87df86ef2804f83b0c11fca2a37fd49",
      "5ae473c91e084c339e339bba168d52cc",
      "da36b58414074e409c049c73f4e07d94",
      "ca67b112541f4c0ebc104572d3a2492b"
     ]
    },
    "id": "9h5OBTI7MhFj",
    "outputId": "6e41e11c-ae7e-40b7-b41d-b32c3dac9787"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠙</span> ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m⠙\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m evaluation_results = \u001b[43manswer_relevancy_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevaluator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontexts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(evaluation_results[\u001b[33m\"\u001b[39m\u001b[33mevaluator\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/deepset/code/haystack/haystack/core/pipeline/pipeline.py:235\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, data, include_outputs_from)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# We need to add missing defaults using default values from input sockets because the run signature\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# might not provide these defaults for components with inputs defined dynamically upon component\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# initialization\u001b[39;00m\n\u001b[32m    233\u001b[39m component_inputs = \u001b[38;5;28mself\u001b[39m._add_missing_input_defaults(component_inputs, component[\u001b[33m\"\u001b[39m\u001b[33minput_sockets\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m component_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_component\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponent_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponent_visits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_visits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparent_span\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Updates global input state with component outputs and returns outputs that should go to\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# pipeline outputs.\u001b[39;00m\n\u001b[32m    246\u001b[39m component_pipeline_outputs = \u001b[38;5;28mself\u001b[39m._write_component_outputs(\n\u001b[32m    247\u001b[39m     component_name=component_name,\n\u001b[32m    248\u001b[39m     component_outputs=component_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m     include_outputs_from=include_outputs_from,\n\u001b[32m    252\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/deepset/code/haystack/haystack/core/pipeline/pipeline.py:60\u001b[39m, in \u001b[36mPipeline._run_component\u001b[39m\u001b[34m(component_name, component, inputs, component_visits, parent_span)\u001b[39m\n\u001b[32m     58\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mRunning component \u001b[39m\u001b[38;5;132;01m{component_name}\u001b[39;00m\u001b[33m\"\u001b[39m, component_name=component_name)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     component_output = \u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineRuntimeError.from_exception(component_name, instance.\u001b[34m__class__\u001b[39m, error) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/haystack_integrations/components/evaluators/deepeval/evaluator.py:95\u001b[39m, in \u001b[36mDeepEvalEvaluator.run\u001b[39m\u001b[34m(self, **inputs)\u001b[39m\n\u001b[32m     92\u001b[39m InputConverters.validate_input_parameters(\u001b[38;5;28mself\u001b[39m.metric, \u001b[38;5;28mself\u001b[39m.descriptor.input_parameters, inputs)\n\u001b[32m     93\u001b[39m converted_inputs: List[LLMTestCase] = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.descriptor.input_converter(**inputs))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m converted_results = [[result.to_dict() \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.descriptor.output_converter(x)] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m: converted_results}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/haystack_integrations/components/evaluators/deepeval/evaluator.py:141\u001b[39m, in \u001b[36mDeepEvalEvaluator._invoke_deepeval\u001b[39m\u001b[34m(test_cases, metric)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke_deepeval\u001b[39m(test_cases: List[LLMTestCase], metric: BaseMetric) -> List[TestResult]:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/evaluate.py:124\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(test_cases, metrics)\u001b[39m\n\u001b[32m    122\u001b[39m test_run_manager.reset()\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m progress_context(\u001b[33m\"\u001b[39m\u001b[33mEvaluating testcases...\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     test_results = \u001b[43mexecute_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     capture_evaluation_count()\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m test_result \u001b[38;5;129;01min\u001b[39;00m test_results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/evaluate.py:60\u001b[39m, in \u001b[36mexecute_test\u001b[39m\u001b[34m(test_cases, metrics, save_to_disk)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[32m     59\u001b[39m     test_start_time = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mmetric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     test_end_time = time.perf_counter()\n\u001b[32m     62\u001b[39m     run_duration = test_end_time - test_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/metrics/answer_relevancy.py:45\u001b[39m, in \u001b[36mAnswerRelevancyMetric.measure\u001b[39m\u001b[34m(self, test_case)\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     42\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInput, actual output, or retrieval context cannot be None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m     )\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m metrics_progress_context(\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m.evaluation_model):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28mself\u001b[39m.key_points: List[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_key_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactual_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieval_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m.verdicts: List[\n\u001b[32m     49\u001b[39m         AnswerRelvancyVerdict\n\u001b[32m     50\u001b[39m     ] = \u001b[38;5;28mself\u001b[39m._generate_verdicts(test_case.input)\n\u001b[32m     52\u001b[39m     answer_relevancy_score = \u001b[38;5;28mself\u001b[39m._generate_score()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/metrics/answer_relevancy.py:120\u001b[39m, in \u001b[36mAnswerRelevancyMetric._generate_key_points\u001b[39m\u001b[34m(self, answer, retrieval_context)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_key_points\u001b[39m(\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m, answer: \u001b[38;5;28mstr\u001b[39m, retrieval_context: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    115\u001b[39m ) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    116\u001b[39m     prompt = AnswerRelevancyTemplate.generate_key_points(\n\u001b[32m    117\u001b[39m         answer=answer, retrieval_context=retrieval_context\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     json_output = trimToJson(res)\n\u001b[32m    122\u001b[39m     data = json.loads(json_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/models/base.py:20\u001b[39m, in \u001b[36mDeepEvalBaseModel.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/chat_completion/retry.py:24\u001b[39m, in \u001b[36mretry_with_exponential_backoff.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Retry on specified errors\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m errors \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     28\u001b[39m         \u001b[38;5;66;03m# Increment retries\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/deepeval/models/gpt_model.py:85\u001b[39m, in \u001b[36mGPTModel._call\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;129m@retry_with_exponential_backoff\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     84\u001b[39m     chat_model = \u001b[38;5;28mself\u001b[39m.load_model()\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1130\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1128\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1087\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1044\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1085\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1086\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1087\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/openai/_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    978\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/haystack_fresh/lib/python3.11/ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "evaluation_results = answer_relevancy_pipeline.run(\n",
    "    {\"evaluator\": {\"questions\": questions, \"responses\": responses, \"contexts\": contexts}}\n",
    ")\n",
    "print(evaluation_results[\"evaluator\"][\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6vX1z8iyswB"
   },
   "source": [
    "#### Note\n",
    "\n",
    "When this notebook was created, the version 0.20.57 of [deepeval](https://github.com/confident-ai/deepeval/tree/v0.20.57) required the use of contexts for calculating Answer Relevancy. Please note that future versions will no longer require the context field. Specifically, the upcoming release of deepeval-haystack will eliminate the context field as a mandatory requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJFAehqJD6fB"
   },
   "source": [
    "### Faithfulness\n",
    "\n",
    "The faithfulness metric measures the quality of our RAG pipeline's responses by evaluating whether the response factually aligns with the contents of context we provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYtc-Y-_NpbG"
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.deepeval import DeepEvalEvaluator, DeepEvalMetric\n",
    "\n",
    "faithfulness_pipeline = Pipeline()\n",
    "evaluator = DeepEvalEvaluator(metric=DeepEvalMetric.FAITHFULNESS, metric_params={\"model\":\"gpt-4\"} )\n",
    "faithfulness_pipeline.add_component(\"evaluator\", evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c0358b409098420da7bfe302f9f48c5c",
      "ebf2e2e45d53410e9126677c1cf61267",
      "bb98efd743c84bdab5cb275e3ac8e6b9",
      "167d5d9446f04530babc624ca48befb1",
      "5ae8eaa505ca48ad8eee06b8175c5a98",
      "cc764ae9496f45b39a3a5b40029b9196",
      "a3b496d277f74df69464a5e9dda63c23",
      "98c3859bfe82482e87d5798eddd51f61"
     ]
    },
    "id": "o7obq_DSNsKo",
    "outputId": "fa62e280-e110-446c-e900-9c936ae5aeaa"
   },
   "outputs": [],
   "source": [
    "evaluation_results = faithfulness_pipeline.run(\n",
    "    {\"evaluator\": {\"questions\": questions, \"contexts\": contexts, \"responses\": responses}}\n",
    ")\n",
    "print(evaluation_results[\"evaluator\"][\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkHTvZ5lIGI7"
   },
   "source": [
    "**Our pipeline evaluation using DeepEval is now complete!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0EnH7dbFT3i"
   },
   "source": [
    "**Haystack Useful Sources**\n",
    "\n",
    "* [Docs](https://docs.haystack.deepset.ai/docs/intro)\n",
    "* [Tutorials](https://haystack.deepset.ai/tutorials)\n",
    "* [Other Cookbooks](https://github.com/deepset-ai/haystack-cookbook)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0562644fed5f48e8ad9732ef1147ddd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b80967d207704c66ac86d4b7bfb8a8c6",
      "placeholder": "​",
      "style": "IPY_MODEL_32578965fe954d3e906a4e169a4ab018",
      "value": "Downloading data: 100%"
     }
    },
    "07902c894aec4233887a1a903b0f112b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2599b9dffac047f3b8e4763ceb531f3a",
      "placeholder": "​",
      "style": "IPY_MODEL_15333af214134573a64906c3dc6c650f",
      "value": "Generating train split: 100%"
     }
    },
    "085f6a362bea4615a3018120e31e1056": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0dd84bad8d224269828a0c1ec0a582fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e0ee9fb22d648b2b1c2acb4b6a09732": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e4232d17e96462e8e1a5ee08392438b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f483cfc37e3943bd9a0437226f62894a",
       "IPY_MODEL_d1ad1d5697214c1e83b11ec195896f0c",
       "IPY_MODEL_1b63a3c82db44c77a17403b1decc2f99"
      ],
      "layout": "IPY_MODEL_b65f056df8354207b251ab5ef6a707a2"
     }
    },
    "0e7eafde72c34a58a822af793b4bfeb9": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_60d1e49ed7564aa0a3ae5fb87287a118",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇</span> Evaluating testcases...\n</pre>\n",
         "text/plain": "\u001b[32m⠇\u001b[0m Evaluating testcases...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "1244bf8ea208476cb2a1af7e9583cb51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15333af214134573a64906c3dc6c650f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1559b47643e4481483256713396bf4da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "162d29297c5f4dad98baca0794bb93fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acaa9927fcde4bcdb606107ac0265c6b",
       "IPY_MODEL_d99d1dd68071439a966f63bd4e998db9",
       "IPY_MODEL_efd288e1422142bc9bfe87c5528342ad"
      ],
      "layout": "IPY_MODEL_c0764d64aa2f4e2484d8b2e2d228213c"
     }
    },
    "167d5d9446f04530babc624ca48befb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "191ecf80edfd4653b01a69428d560032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b63a3c82db44c77a17403b1decc2f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a34410f9ce2a4050bb428c34e5312026",
      "placeholder": "​",
      "style": "IPY_MODEL_555f0847214548739a4e17dba3ec7c06",
      "value": " 1.35M/1.35M [00:00&lt;00:00, 2.84MB/s]"
     }
    },
    "1e21a8520b1a49d1a53e63404381711a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21a6ebf4d82645b5b4182ac62f6bb8a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2599b9dffac047f3b8e4763ceb531f3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25e0e8b60e394420b8cf05f16e4a6ca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b09fb1900d114728ad51fe27f93ae23b",
       "IPY_MODEL_9c536b1ace0e44ef8c16b0578fd6b3af",
       "IPY_MODEL_f0fa88ba58084418a8cfa3e8cd39ef5b"
      ],
      "layout": "IPY_MODEL_9525696cd0b848f7a0213d774d221081"
     }
    },
    "27cb89f01c0546a2a06c96af28535448": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1109dbbca474bd399c2c37b3bbed5d3",
      "max": 130319,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_085f6a362bea4615a3018120e31e1056",
      "value": 130319
     }
    },
    "27f25685cd504798b38ad8147b0bd6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27f6523d465644fcaf5304299a8c163e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2809adab6c6a432fae163c8e8590021c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77c714ea90d94d668f76f6d6458af173",
      "max": 8916,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_556fb0c73f6342c6b40d532ad02d6002",
      "value": 8916
     }
    },
    "2e9a94bf99174fd08dc86a5e620b557a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3080f12af2814a1985146de24da50d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32578965fe954d3e906a4e169a4ab018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3263d38faab14e13914c92e757882d6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ed06598cd5e46dc8252a3b066a348c4",
      "max": 11873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f098711cab84ed9affd29e0ae89d020",
      "value": 11873
     }
    },
    "355fee969f7e4db5a5a4740321ec4b7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8163e5759904ea68c8c2a341b2a7347",
       "IPY_MODEL_3263d38faab14e13914c92e757882d6a",
       "IPY_MODEL_db32838cce5741fabb9ad431fae28953"
      ],
      "layout": "IPY_MODEL_79c748fea30c46349a7b584a28a12385"
     }
    },
    "35da6c45d95540c883b87df1985a530d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36010e88333341d69c6bffb22658a99f": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_391619c636794697ac60d3b7c9cc04a6",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠴</span> Evaluating testcases...\n</pre>\n",
         "text/plain": "\u001b[32m⠴\u001b[0m Evaluating testcases...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "365eae22a84f465c9e2640ddd1ddbf31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "391619c636794697ac60d3b7c9cc04a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bb9e44e17ec4f3986378ddb3c1255c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3da15c7e57fa461bad6ee4a41a7ee6be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe57e53818254848bd2dbb062fed1eca",
      "max": 1204,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8770ef290a2b4174845a8307197e0701",
      "value": 1204
     }
    },
    "3ed06598cd5e46dc8252a3b066a348c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "420fb1c93d2b4b5daffb4bd40261172e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44caede104434cd5a75a3189d134cd01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "476b58f1c20c4f3fa75f7db2d8959f22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a4ab3a911e747209b7520d72bbf9bfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b56ff9a99e84d3980c6b941a7015dcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d89770dfd6440359c5503a7c67b948e",
      "placeholder": "​",
      "style": "IPY_MODEL_ef55f8e3f86545dd85ffff9f0ec0eec8",
      "value": " 16.4M/16.4M [00:01&lt;00:00, 14.5MB/s]"
     }
    },
    "4d89770dfd6440359c5503a7c67b948e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f098711cab84ed9affd29e0ae89d020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4fc7fe98ed9e43fa96c3e862f24518a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21a6ebf4d82645b5b4182ac62f6bb8a3",
      "placeholder": "​",
      "style": "IPY_MODEL_675904b673ca4c578ef16a777995b8d4",
      "value": " 1204/1204 [00:00&lt;00:00, 5281.46 docs/s]"
     }
    },
    "529e0a3f1bb94633b3a7ef3465025eb1": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f037a8d0089a4628991a70ed217095b0",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span> Evaluating testcases...\n</pre>\n",
         "text/plain": "\u001b[32m⠹\u001b[0m Evaluating testcases...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "5426fbb2f2fd457c98e943b59d214d2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54d27ef845b840c7bd632e7616077777": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "555f0847214548739a4e17dba3ec7c06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "556fb0c73f6342c6b40d532ad02d6002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55b84b06a9fc417a90ee08ad622e3e92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59b9c475c5cd44aa845a7dda92969997": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa08ed9dbc194258941821dd61025870",
      "max": 1204,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e21a8520b1a49d1a53e63404381711a",
      "value": 1204
     }
    },
    "5a4659cf76c1464bac21f7b47b4234d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a6df8e408d143ff86952d6b3150632f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ae473c91e084c339e339bba168d52cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ae8eaa505ca48ad8eee06b8175c5a98": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_cc764ae9496f45b39a3a5b40029b9196",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠴</span> ✨ 🍰 ✨ You're using DeepEval's latest Faithfulness Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠴\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Faithfulness Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "5e5bdc4043184b08a949a573bb20c0ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60d1e49ed7564aa0a3ae5fb87287a118": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62107ac42cd64349859a040cf54e960a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "621e6dac0fa6454887265fdf7f8c14d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "675904b673ca4c578ef16a777995b8d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67dc3c5b24fc433e9c34ab8faa5e58e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cbfaa160fef4aeeb4f273d14ea896dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d812678e25b4ec8abfde1a16d5cad4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6dcc415dd1e5430dbfdba67a94f81aac": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_e2c57c3decf744afa591e6021ec9b1c0",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠴</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Precision Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠴\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Precision Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "6dccecdd0a82418a987914dddc64dc92": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0e0ee9fb22d648b2b1c2acb4b6a09732",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Precision Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠹\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Precision Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "6dea007209214945b93b6bb9754a3185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cd5c8b2e8674dfb8cd82363bbab30fc",
      "placeholder": "​",
      "style": "IPY_MODEL_476b58f1c20c4f3fa75f7db2d8959f22",
      "value": " 130319/130319 [00:00&lt;00:00, 251683.43 examples/s]"
     }
    },
    "6e0b90efbdbe4f06bb4e4606374e24a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0562644fed5f48e8ad9732ef1147ddd9",
       "IPY_MODEL_a90a1ef04530404fb837328d17a4842f",
       "IPY_MODEL_4b56ff9a99e84d3980c6b941a7015dcb"
      ],
      "layout": "IPY_MODEL_44caede104434cd5a75a3189d134cd01"
     }
    },
    "713f9175346140a6a8b5a60915ec3eb2": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_35da6c45d95540c883b87df1985a530d",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Relevancy Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠇\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Relevancy Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "72fa3d3d04f54f91be7dd6429721c6e5": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_191ecf80edfd4653b01a69428d560032",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Relevancy Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠹\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Relevancy Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "74f15702bb124e90b8881bc416c5d2e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77c714ea90d94d668f76f6d6458af173": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79c748fea30c46349a7b584a28a12385": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ac2fa06b6af43ce8c93d45bd09410cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82350be333ab4ec49f0f3f26162e02be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b210ca088d55443389cc03fcda3cc166",
       "IPY_MODEL_3da15c7e57fa461bad6ee4a41a7ee6be",
       "IPY_MODEL_4fc7fe98ed9e43fa96c3e862f24518a5"
      ],
      "layout": "IPY_MODEL_420fb1c93d2b4b5daffb4bd40261172e"
     }
    },
    "8770ef290a2b4174845a8307197e0701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8949db0390d942a0a13269e6aba5bc9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b9384106cf34271ade70d362baad763": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9037f3bdb47947f18ac3a324148a25ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90df55f944a34dd19c5ef581dd10e8c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "942b6e576097465bac964355006473b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9525696cd0b848f7a0213d774d221081": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "975275dbb3d2479e8d317ae14cac0054": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98c3859bfe82482e87d5798eddd51f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98d6d1ff6fe94c2889503aa6f03d2019": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99d9b2c90ca541249deca02e8878abac": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_9a8c1fa4fda74964b3cd1a00f97df713",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠋</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Recall Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠋\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Recall Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "9a8c1fa4fda74964b3cd1a00f97df713": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b235a93badf4901ad3f5b8c9c5d1cb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c536b1ace0e44ef8c16b0578fd6b3af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e40d267e3ef44557a4b0eab36e0ce339",
      "max": 1204,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a6df8e408d143ff86952d6b3150632f",
      "value": 1204
     }
    },
    "9cd5c8b2e8674dfb8cd82363bbab30fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9de852d380924ba4a8ffd526b18babf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2fff18ac8104547afd5d8d5369db7b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a34410f9ce2a4050bb428c34e5312026": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3b496d277f74df69464a5e9dda63c23": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_98c3859bfe82482e87d5798eddd51f61",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠋</span> ✨ 🍰 ✨ You're using DeepEval's latest Faithfulness Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠋\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Faithfulness Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "a8470fba6ab4420fb592c820906a7579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_07902c894aec4233887a1a903b0f112b",
       "IPY_MODEL_27cb89f01c0546a2a06c96af28535448",
       "IPY_MODEL_6dea007209214945b93b6bb9754a3185"
      ],
      "layout": "IPY_MODEL_54d27ef845b840c7bd632e7616077777"
     }
    },
    "a90a1ef04530404fb837328d17a4842f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90df55f944a34dd19c5ef581dd10e8c7",
      "max": 16369982,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b9384106cf34271ade70d362baad763",
      "value": 16369982
     }
    },
    "aa3bbecfe5944da284019aff8baf44ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_942b6e576097465bac964355006473b1",
      "placeholder": "​",
      "style": "IPY_MODEL_2e9a94bf99174fd08dc86a5e620b557a",
      "value": "Downloading readme: 100%"
     }
    },
    "acaa9927fcde4bcdb606107ac0265c6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2fff18ac8104547afd5d8d5369db7b7",
      "placeholder": "​",
      "style": "IPY_MODEL_55b84b06a9fc417a90ee08ad622e3e92",
      "value": "Ranking by BM25...: 100%"
     }
    },
    "afed416a13094ef69b4cdebb0bb056bc": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_9de852d380924ba4a8ffd526b18babf5",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Relevancy Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠇\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Relevancy Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "b09fb1900d114728ad51fe27f93ae23b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b235a93badf4901ad3f5b8c9c5d1cb4",
      "placeholder": "​",
      "style": "IPY_MODEL_8949db0390d942a0a13269e6aba5bc9d",
      "value": "Ranking by BM25...: 100%"
     }
    },
    "b1109dbbca474bd399c2c37b3bbed5d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b210ca088d55443389cc03fcda3cc166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d56fd76a836c4f8f82b5a7c808db0a53",
      "placeholder": "​",
      "style": "IPY_MODEL_27f25685cd504798b38ad8147b0bd6e0",
      "value": "Ranking by BM25...: 100%"
     }
    },
    "b49dd1d055e246e8ab0bef9264a43e60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b65f056df8354207b251ab5ef6a707a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b80967d207704c66ac86d4b7bfb8a8c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8ca49ea0ee3418581c3e0d56e630c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be7d0bc998854467897804c94410c087",
      "placeholder": "​",
      "style": "IPY_MODEL_975275dbb3d2479e8d317ae14cac0054",
      "value": " 8.92k/8.92k [00:00&lt;00:00, 116kB/s]"
     }
    },
    "bb98efd743c84bdab5cb275e3ac8e6b9": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_167d5d9446f04530babc624ca48befb1",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇</span> ✨ 🍰 ✨ You're using DeepEval's latest Faithfulness Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠇\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Faithfulness Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "bba0ef9673ed46b79c051b0befa1139b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc0a96ed84f24f91ac9ec7877459c5ee": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_62107ac42cd64349859a040cf54e960a",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠙</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Recall Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠙\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Recall Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "be7d0bc998854467897804c94410c087": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0358b409098420da7bfe302f9f48c5c": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_ebf2e2e45d53410e9126677c1cf61267",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - ✅ Faithfulness (score: 1.0, threshold: 0.0, evaluation model: gpt-4, reason: The score is 1.00 because the \nactual output perfectly aligns with all the nodes in the retrieval context, without any contradictions.)\n</pre>\n",
         "text/plain": "  - ✅ Faithfulness (score: 1.0, threshold: 0.0, evaluation model: gpt-4, reason: The score is 1.00 because the \nactual output perfectly aligns with all the nodes in the retrieval context, without any contradictions.)\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n",
         "text/plain": "\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For test case:\n</pre>\n",
         "text/plain": "For test case:\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n",
         "text/plain": "\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - input: What is the prize offered for finding a solution to P=NP?\n</pre>\n",
         "text/plain": "  - input: What is the prize offered for finding a solution to P=NP?\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - actual output: The prize offered for finding a solution to P=NP is US$1,000,000.\n</pre>\n",
         "text/plain": "  - actual output: The prize offered for finding a solution to P=NP is US$1,000,000.\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - expected output: None\n</pre>\n",
         "text/plain": "  - expected output: None\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - context: None\n</pre>\n",
         "text/plain": "  - context: None\n"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠏</span> Evaluating testcases...\n</pre>\n",
         "text/plain": "\u001b[32m⠏\u001b[0m Evaluating testcases...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "c0764d64aa2f4e2484d8b2e2d228213c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca67b112541f4c0ebc104572d3a2492b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc764ae9496f45b39a3a5b40029b9196": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ad1d5697214c1e83b11ec195896f0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1244bf8ea208476cb2a1af7e9583cb51",
      "max": 1350511,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d812678e25b4ec8abfde1a16d5cad4e",
      "value": 1350511
     }
    },
    "d56c6ef249884e22a5bc580cc2f26576": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_dc28afbdea4a4c94b24bbada0f693096",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠏</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Recall Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠏\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Recall Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "d56fd76a836c4f8f82b5a7c808db0a53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8163e5759904ea68c8c2a341b2a7347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df29c5b8cd18449d9f04a6e0ae7bccc1",
      "placeholder": "​",
      "style": "IPY_MODEL_5e5bdc4043184b08a949a573bb20c0ec",
      "value": "Generating validation split: 100%"
     }
    },
    "d87df86ef2804f83b0c11fca2a37fd49": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_5ae473c91e084c339e339bba168d52cc",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠦</span> ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠦\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "d99d1dd68071439a966f63bd4e998db9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98d6d1ff6fe94c2889503aa6f03d2019",
      "max": 1204,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3080f12af2814a1985146de24da50d99",
      "value": 1204
     }
    },
    "d9dd9e05c1b94bf280a0b3bf1b6e526c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27f6523d465644fcaf5304299a8c163e",
      "placeholder": "​",
      "style": "IPY_MODEL_0dd84bad8d224269828a0c1ec0a582fc",
      "value": " 1204/1204 [00:00&lt;00:00, 5538.53 docs/s]"
     }
    },
    "da36b58414074e409c049c73f4e07d94": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_ca67b112541f4c0ebc104572d3a2492b",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠋</span> ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠋\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "db32838cce5741fabb9ad431fae28953": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a4659cf76c1464bac21f7b47b4234d6",
      "placeholder": "​",
      "style": "IPY_MODEL_fc8f2d9d5e544036bcb41e9bf3ad4327",
      "value": " 11873/11873 [00:00&lt;00:00, 91282.14 examples/s]"
     }
    },
    "dc28afbdea4a4c94b24bbada0f693096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df29c5b8cd18449d9f04a6e0ae7bccc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2c57c3decf744afa591e6021ec9b1c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e36f222e6b3946e6a1ed1e4c71ea31be": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_1559b47643e4481483256713396bf4da",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠏</span> ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠏\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Answer Relevancy Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "e40d267e3ef44557a4b0eab36e0ce339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebf2e2e45d53410e9126677c1cf61267": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecdd3039fab546b98285080b0154fd0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa3bbecfe5944da284019aff8baf44ea",
       "IPY_MODEL_2809adab6c6a432fae163c8e8590021c",
       "IPY_MODEL_b8ca49ea0ee3418581c3e0d56e630c85"
      ],
      "layout": "IPY_MODEL_b49dd1d055e246e8ab0bef9264a43e60"
     }
    },
    "ef55f8e3f86545dd85ffff9f0ec0eec8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efd288e1422142bc9bfe87c5528342ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cbfaa160fef4aeeb4f273d14ea896dd",
      "placeholder": "​",
      "style": "IPY_MODEL_4a4ab3a911e747209b7520d72bbf9bfa",
      "value": " 1204/1204 [00:00&lt;00:00, 8864.45 docs/s]"
     }
    },
    "f037a8d0089a4628991a70ed217095b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c3a912ceaa4c1b8a7c52bea3828164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa3931c092f34303af88c945b8140e04",
       "IPY_MODEL_59b9c475c5cd44aa845a7dda92969997",
       "IPY_MODEL_d9dd9e05c1b94bf280a0b3bf1b6e526c"
      ],
      "layout": "IPY_MODEL_5426fbb2f2fd457c98e943b59d214d2c"
     }
    },
    "f0fa88ba58084418a8cfa3e8cd39ef5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bba0ef9673ed46b79c051b0befa1139b",
      "placeholder": "​",
      "style": "IPY_MODEL_7ac2fa06b6af43ce8c93d45bd09410cc",
      "value": " 1204/1204 [00:00&lt;00:00, 10884.51 docs/s]"
     }
    },
    "f1639c9c99a846d7a17aee870ff80d98": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_3bb9e44e17ec4f3986378ddb3c1255c4",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠏</span> Evaluating testcases...\n</pre>\n",
         "text/plain": "\u001b[32m⠏\u001b[0m Evaluating testcases...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "f353551fe7894653b2c1a7d9c6a449a7": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_67dc3c5b24fc433e9c34ab8faa5e58e0",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠦</span> ✨ 🍰 ✨ You're using DeepEval's latest Contextual Precision Metric (using gpt-4)! This may take a minute...\n</pre>\n",
         "text/plain": "\u001b[32m⠦\u001b[0m ✨ 🍰 ✨ You're using DeepEval's latest Contextual Precision Metric (using gpt-4)! This may take a minute...\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "f483cfc37e3943bd9a0437226f62894a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_621e6dac0fa6454887265fdf7f8c14d3",
      "placeholder": "​",
      "style": "IPY_MODEL_365eae22a84f465c9e2640ddd1ddbf31",
      "value": "Downloading data: 100%"
     }
    },
    "fa08ed9dbc194258941821dd61025870": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3931c092f34303af88c945b8140e04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74f15702bb124e90b8881bc416c5d2e2",
      "placeholder": "​",
      "style": "IPY_MODEL_9037f3bdb47947f18ac3a324148a25ba",
      "value": "Ranking by BM25...: 100%"
     }
    },
    "fc8f2d9d5e544036bcb41e9bf3ad4327": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe57e53818254848bd2dbb062fed1eca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
