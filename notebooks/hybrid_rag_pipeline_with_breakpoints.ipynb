{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid RAG Pipeline with Breakpoints\n",
    "\n",
    "This notebook demonstrates how to setup breakpoints in a Haystack pipeline. In this case, we will set up break points in a hybrid retrieval-augmented generation (RAG) pipeline. The pipeline combines BM25 and embedding-based retrieval methods, then uses a transformer-based reranker and an LLM to generate answers.\n",
    "\n",
    "## NOTE: This feature is a part of `haystack-experimental`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haystack-experimental in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: haystack-ai in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-experimental) (2.12.2)\n",
      "Requirement already satisfied: pydantic in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-experimental) (2.11.3)\n",
      "Requirement already satisfied: jinja2 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (4.23.0)\n",
      "Requirement already satisfied: lazy-imports in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (0.4.0)\n",
      "Requirement already satisfied: more-itertools in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (10.6.0)\n",
      "Requirement already satisfied: networkx in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (3.4.2)\n",
      "Requirement already satisfied: numpy in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (2.2.4)\n",
      "Requirement already satisfied: openai>=1.56.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (1.74.0)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (3.24.3)\n",
      "Requirement already satisfied: python-dateutil in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (9.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from haystack-ai->haystack-experimental) (4.13.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from pydantic->haystack-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from pydantic->haystack-experimental) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from pydantic->haystack-experimental) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from openai>=1.56.1->haystack-ai->haystack-experimental) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from openai>=1.56.1->haystack-ai->haystack-experimental) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from openai>=1.56.1->haystack-ai->haystack-experimental) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from openai>=1.56.1->haystack-ai->haystack-experimental) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from openai>=1.56.1->haystack-ai->haystack-experimental) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from posthog!=3.12.0->haystack-ai->haystack-experimental) (1.17.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from posthog!=3.12.0->haystack-ai->haystack-experimental) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from posthog!=3.12.0->haystack-ai->haystack-experimental) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->haystack-ai->haystack-experimental) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->haystack-ai->haystack-experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->haystack-ai->haystack-experimental) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->haystack-ai->haystack-experimental) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from jinja2->haystack-ai->haystack-experimental) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from jsonschema->haystack-ai->haystack-experimental) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from jsonschema->haystack-ai->haystack-experimental) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from jsonschema->haystack-ai->haystack-experimental) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from jsonschema->haystack-ai->haystack-experimental) (0.24.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai->haystack-experimental) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai->haystack-experimental) (0.14.0)\n",
      "Requirement already satisfied: transformers[sentencepiece,torch] in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (4.67.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (6.30.2)\n",
      "Requirement already satisfied: torch>=2.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[sentencepiece,torch]) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[sentencepiece,torch]) (4.13.2)\n",
      "Requirement already satisfied: networkx in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0->transformers[sentencepiece,torch]) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->transformers[sentencepiece,torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->transformers[sentencepiece,torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->transformers[sentencepiece,torch]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->transformers[sentencepiece,torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0->transformers[sentencepiece,torch]) (3.0.2)\n",
      "Requirement already satisfied: sentence-transformers>=3.0.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sentence-transformers>=3.0.0) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2.32.3)\n",
      "Requirement already satisfied: networkx in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=3.0.0) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=3.0.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=3.0.0) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3.0.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U haystack-experimental\n",
    "!pip install \"transformers[torch,sentencepiece]\"\n",
    "!pip install \"sentence-transformers>=3.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup OpenAI API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary components from Haystack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amna.mubashar/haystack-cookbook/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline # Note that we need to import the pipeline from haystack-experimental\n",
    "\n",
    "from haystack import Document\n",
    "from haystack.components.builders import AnswerBuilder, ChatPromptBuilder\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.rankers import TransformersSimilarityRanker\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.document_stores.types import DuplicatePolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Store Initializations\n",
    "\n",
    "Let's create a simple document store with some sample documents and their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing():\n",
    "    \"\"\"\n",
    "    Indexing documents in a DocumentStore.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Indexing documents...\")\n",
    "\n",
    "    # Create sample documents\n",
    "    documents = [\n",
    "        Document(content=\"My name is Jean and I live in Paris. The weather today is 25°C.\"),\n",
    "        Document(content=\"My name is Mark and I live in Berlin. The weather today is 15°C.\"),\n",
    "        Document(content=\"My name is Giorgio and I live in Rome. The weather today is 30°C.\"),\n",
    "    ]\n",
    "\n",
    "    # Initialize document store and components\n",
    "    document_store = InMemoryDocumentStore()\n",
    "    doc_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "    doc_embedder = SentenceTransformersDocumentEmbedder(model=\"intfloat/e5-base-v2\", progress_bar=False)\n",
    "\n",
    "    # Build and run the ingestion pipeline\n",
    "    ingestion_pipe = Pipeline()\n",
    "    ingestion_pipe.add_component(instance=doc_embedder, name=\"doc_embedder\")\n",
    "    ingestion_pipe.add_component(instance=doc_writer, name=\"doc_writer\")\n",
    "\n",
    "    ingestion_pipe.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
    "    ingestion_pipe.run({\"doc_embedder\": {\"documents\": documents}})\n",
    "\n",
    "    return document_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hybrid Retrieval Pipeline\n",
    "\n",
    "Now let's build a hybrid RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retrieval(doc_store):\n",
    "    \"\"\"\n",
    "    A simple pipeline for hybrid retrieval using BM25 and embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize query embedder\n",
    "    query_embedder = SentenceTransformersTextEmbedder(model=\"intfloat/e5-base-v2\", progress_bar=False)\n",
    "\n",
    "    # Define the prompt template for the LLM\n",
    "    template = [\n",
    "        ChatMessage.from_system(\n",
    "            \"You are a helpful AI assistant. Answer the following question based on the given context information only. If the context is empty or just a '\\n' answer with None, example: 'None'.\"\n",
    "        ),\n",
    "        ChatMessage.from_user(\n",
    "            \"\"\"\n",
    "            Context:\n",
    "            {% for document in documents %}\n",
    "                {{ document.content }}\n",
    "            {% endfor %}\n",
    "    \n",
    "            Question: {{question}}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Build the RAG pipeline\n",
    "    rag_pipeline = Pipeline()\n",
    "    \n",
    "    # Add components to the pipeline\n",
    "    rag_pipeline.add_component(instance=InMemoryBM25Retriever(document_store=doc_store), name=\"bm25_retriever\")\n",
    "    rag_pipeline.add_component(instance=query_embedder, name=\"query_embedder\")\n",
    "    rag_pipeline.add_component(instance=InMemoryEmbeddingRetriever(document_store=doc_store), name=\"embedding_retriever\")\n",
    "    rag_pipeline.add_component(instance=DocumentJoiner(sort_by_score=False), name=\"doc_joiner\")\n",
    "    rag_pipeline.add_component(instance=TransformersSimilarityRanker(model=\"intfloat/simlm-msmarco-reranker\", top_k=5), name=\"ranker\")    \n",
    "    rag_pipeline.add_component(instance=ChatPromptBuilder(template=template, required_variables=[\"question\", \"documents\"]), name=\"prompt_builder\", )    \n",
    "    rag_pipeline.add_component(instance=OpenAIChatGenerator(), name=\"llm\")\n",
    "    rag_pipeline.add_component(instance=AnswerBuilder(), name=\"answer_builder\")\n",
    "\n",
    "    # Connect the components\n",
    "    rag_pipeline.connect(\"query_embedder\", \"embedding_retriever.query_embedding\")\n",
    "    rag_pipeline.connect(\"embedding_retriever\", \"doc_joiner.documents\")\n",
    "    rag_pipeline.connect(\"bm25_retriever\", \"doc_joiner.documents\")\n",
    "    rag_pipeline.connect(\"doc_joiner\", \"ranker.documents\")\n",
    "    rag_pipeline.connect(\"ranker\", \"prompt_builder.documents\")\n",
    "    rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "    rag_pipeline.connect(\"llm.replies\", \"answer_builder.replies\")    \n",
    "    rag_pipeline.connect(\"doc_joiner\", \"answer_builder.documents\")\n",
    "\n",
    "    return rag_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pipeline with breakpoints\n",
    "\n",
    "Now we demonstrate how to set breakpoints in a Haystack pipeline to inspect and debug the pipeline execution at specific points. Breakpoints allow you to pause execution, save the current state of pipeline, and later resume from where you left off.\n",
    "\n",
    "We'll run the pipeline with a breakpoint set at the `query_embedder` component. This will save the pipeline state before executing the `query_embedder` and raise `PipelineBreakpointException` to stop execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing documents...\n"
     ]
    },
    {
     "ename": "PipelineBreakpointException",
     "evalue": "Breaking at component query_embedder visit count 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPipelineBreakpointException\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhere does Mark live?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_embedder\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: question},\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbm25_retriever\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: question},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_builder\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: question},\n\u001b[1;32m     13\u001b[0m }\n\u001b[0;32m---> 16\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbreakpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery_embedder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_states\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/haystack-experimental/haystack_experimental/core/pipeline/pipeline.py:321\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, include_outputs_from, breakpoints, resume_state, debug_path)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# keep track of the original input to save it in case of a breakpoint when running the component\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_input_data \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 321\u001b[0m component_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_component\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomponent_visits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidated_breakpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Updates global input state with component outputs and returns outputs that should go to\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# pipeline outputs.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m component_pipeline_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_component_outputs(\n\u001b[1;32m    332\u001b[0m     component_name\u001b[38;5;241m=\u001b[39mcomponent_name,\n\u001b[1;32m    333\u001b[0m     component_outputs\u001b[38;5;241m=\u001b[39mcomponent_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     include_outputs_from\u001b[38;5;241m=\u001b[39minclude_outputs_from,\n\u001b[1;32m    337\u001b[0m )\n",
      "File \u001b[0;32m~/haystack-experimental/haystack_experimental/core/pipeline/pipeline.py:90\u001b[0m, in \u001b[0;36mPipeline._run_component\u001b[0;34m(self, component, inputs, component_visits, breakpoints, parent_span)\u001b[0m\n\u001b[1;32m     88\u001b[0m breakpoint_inputs[component_name] \u001b[38;5;241m=\u001b[39m Pipeline\u001b[38;5;241m.\u001b[39m_remove_unserializable_data(component_inputs)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m breakpoints \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_state:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_breakpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbreakpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent_visits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbreakpoint_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracing\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mtrace(\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaystack.component.run\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     tags\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# We deepcopy the inputs otherwise we might lose that information\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# when we delete them in case they're sent to other Components\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     span\u001b[38;5;241m.\u001b[39mset_content_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaystack.component.input\u001b[39m\u001b[38;5;124m\"\u001b[39m, deepcopy(component_inputs))\n",
      "File \u001b[0;32m~/haystack-experimental/haystack_experimental/core/pipeline/pipeline.py:425\u001b[0m, in \u001b[0;36mPipeline._check_breakpoints\u001b[0;34m(self, breakpoints, component_name, component_visits, inputs)\u001b[0m\n\u001b[1;32m    423\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(msg)\n\u001b[1;32m    424\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_state(inputs, \u001b[38;5;28mstr\u001b[39m(component_name), component_visits)\n\u001b[0;32m--> 425\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m PipelineBreakpointException(msg, component\u001b[38;5;241m=\u001b[39mcomponent_name, state\u001b[38;5;241m=\u001b[39mstate)\n",
      "\u001b[0;31mPipelineBreakpointException\u001b[0m: Breaking at component query_embedder visit count 0"
     ]
    }
   ],
   "source": [
    "# Initialize document store and pipeline\n",
    "doc_store = indexing()\n",
    "pipeline = hybrid_retrieval(doc_store)\n",
    "\n",
    "# Define the query\n",
    "question = \"Where does Mark live?\"\n",
    "data = {\n",
    "    \"query_embedder\": {\"text\": question},\n",
    "    \"bm25_retriever\": {\"query\": question},\n",
    "    \"ranker\": {\"query\": question, \"top_k\": 10},\n",
    "    \"prompt_builder\": {\"question\": question},\n",
    "    \"answer_builder\": {\"query\": question},\n",
    "}\n",
    "\n",
    "\n",
    "pipeline.run(data, breakpoints={(\"query_embedder\", 0)}, debug_path=\"saved_states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This run shall break with a `PipelineBreakpointException: Breaking at component query_embedder visit count 0` - and this will generate a JSON file (e.g.: `query_embedder_2025_04_15_15_00_20.json`) in a new directory `saved_stated` containing the pipeline running states before running the component `query_embedder`.\n",
    "\n",
    "This file can be explored and used to inspect the pipeline at that execution point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming from a break point\n",
    "\n",
    "We can then resume a pipeline from a `saved_state` by passing it to the `Pipeline.run()` method. This will run the pipeline to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark lives in Berlin.\n",
      "{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 6, 'prompt_tokens': 74, 'total_tokens': 80, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}}\n"
     ]
    }
   ],
   "source": [
    " # Load the saved state and continue execution\n",
    "resume_state = pipeline.load_state(\"saved_states/query_embedder_2025_04_15_15_00_20.json\")\n",
    "result = pipeline.run(data={}, resume_state=resume_state)\n",
    "    \n",
    "# Print the results\n",
    "print(result['answer_builder']['answers'][0].data)\n",
    "print(result['answer_builder']['answers'][0].meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Use Cases for Pipeline Breakpoints\n",
    "\n",
    "Here are some advanced scenarios where pipeline breakpoints can be particularly valuable:\\n\",\n",
    "1. Set a breakpoint at the LLM to try results of different prompts and iterate in real time.\n",
    "\n",
    "2. Place a breakpoint after the document retriever to examine and modify retrieved documents.\n",
    "\n",
    "3. Set a breakpoint before a component to inject gold-standard inputs and isolate whether issues stem from input quality or downstream logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the use case stated in first point, we reuse the same query pipeline with a new question. First, we run the pipeline with the set prompt. Then, we set a breakpoint at the `prompt_builder` to try an alternative prompt. This allows us to compare the results generated by different prompts without running the whole pipeline again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize document store and pipeline\n",
    "doc_store = indexing()\n",
    "pipeline = hybrid_retrieval(doc_store)\n",
    "\n",
    "# Define the query\n",
    "question = \"What's the temperature difference between the warmest and coldest city?\"\n",
    "data = {\n",
    "    \"query_embedder\": {\"text\": question},\n",
    "    \"bm25_retriever\": {\"query\": question},\n",
    "    \"ranker\": {\"query\": question, \"top_k\": 10},\n",
    "    \"prompt_builder\": {\"question\": question},\n",
    "    \"answer_builder\": {\"query\": question},\n",
    "}\n",
    "\n",
    "\n",
    "pipeline.run(data, breakpoints={(\"prompt_builder\", 0)}, debug_path=\"saved_states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can manually insert a different template into the `prompt_builder` and inspect the results. To do this, we update the template input within the `prompt_builder` component in the state file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatMessage.from_system(\n",
    "    \"\"\"You are a mathematical analysis assistant. Follow these steps:\n",
    "    1. Identify all temperatures mentioned\n",
    "    2. Find the maximum and minimum values\n",
    "    3. Calculate their difference\n",
    "    4. Format response as: 'The temperature difference is X°C (max Y°C in [city] - min Z°C in [city])'\n",
    "    Use ONLY the information provided in the context.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just load the state file and resume the pipeline with the altered state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_state = pipeline.load_state(\"saved_states/query_embedder_2025_04_16_03_43_29.json\")\n",
    "result = pipeline.run(data={}, resume_state=resume_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
