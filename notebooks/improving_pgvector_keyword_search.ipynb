{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ZsKhrZfklw"
      },
      "source": [
        "# Tutorial: Improving Postgres keyword search to avoid zero results(PgvectorKeywordRetriever)\n",
        "\n",
        "- **Level**: Intermediate\n",
        "- **Time to complete**: 30 minutes\n",
        "- **Nodes Used**: PgvectorKeywordRetriever, Document\n",
        "- **Goal**: As per haystack documents this Retriever does not apply fuzzy search out of the box, so it's necessary to carefully formulate the query in order to avoid getting zero results. After this tutorial you'll have learned to improve the default implementation and how to better transform your query to avoid getting zero results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQllW6GIfklx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "As mentioned in the Haystack documentation for [PgvectorKeywordRetriever](https://docs.haystack.deepset.ai/docs/pgvectorkeywordretriever), unlike similar components such as `ElasticsearchBM25Retriever`, `PgvectorKeywordRetriever` does not apply fuzzy search out of the box. This means it's necessary to carefully formulate queries to avoid getting zero results. The process invloves subclassing PgvectorKeywordRetriever to use websearch_to_tsquery and using nltk to get keywords to transform the query. Haystack is a wonderfully flexible framework—when results aren't in line with expectations, it's easy to extend or modify its components to fit our needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHZV5A7Jfkly"
      },
      "source": [
        "## Preparing the Colab Environment\n",
        "\n",
        "\n",
        "- [Set logging level to INFO](https://docs.haystack.deepset.ai/docs/log-level)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing haystack"
      ],
      "metadata": {
        "id": "xBtQpazHyr1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install haystack-ai pgvector-haystack psycopg\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTEssDnnywZ9",
        "outputId": "4e38dcfd-0d3a-40c0-fd3d-6f77cd238538"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: haystack-ai in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: pgvector-haystack in /usr/local/lib/python3.12/dist-packages (5.3.0)\n",
            "Requirement already satisfied: psycopg in /usr/local/lib/python3.12/dist-packages (3.2.12)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (0.17.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (1.2.0)\n",
            "Requirement already satisfied: haystack-experimental in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (0.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (4.25.1)\n",
            "Requirement already satisfied: lazy-imports in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (1.0.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (10.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (2.0.2)\n",
            "Requirement already satisfied: openai>=1.99.2 in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (1.109.1)\n",
            "Requirement already satisfied: posthog!=3.12.0 in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (6.7.10)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (2.11.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (8.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from haystack-ai) (4.15.0)\n",
            "Requirement already satisfied: pgvector>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from pgvector-haystack) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.2->haystack-ai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.2->haystack-ai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.2->haystack-ai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.2->haystack-ai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.2->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog!=3.12.0->haystack-ai) (1.17.0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog!=3.12.0->haystack-ai) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->haystack-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->haystack-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->haystack-ai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->haystack-ai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->haystack-ai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->haystack-ai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->haystack-ai) (2025.10.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from haystack-experimental->haystack-ai) (13.9.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->haystack-ai) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->haystack-ai) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->haystack-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->haystack-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->haystack-ai) (0.27.1)\n",
            "Requirement already satisfied: psycopg-binary==3.2.12 in /usr/local/lib/python3.12/dist-packages (from psycopg[binary]->pgvector-haystack) (3.2.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai) (0.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->haystack-experimental->haystack-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->haystack-experimental->haystack-ai) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->haystack-experimental->haystack-ai) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXTgNtjxfkly"
      },
      "source": [
        "## Installing postgres\n",
        "\n",
        "Install and set up postgres\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySQFKJsufklz",
        "outputId": "a8be5495-c178-4b9e-ba0a-9ad4129cfa3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "fatal: destination path 'pgvector' already exists and is not an empty directory.\n",
            "make: Nothing to be done for 'all'.\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  vector.so '/usr/lib/postgresql/14/lib/vector.so'\n",
            "/usr/bin/install -c -m 644 .//vector.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//sql/vector--0.1.0--0.1.1.sql .//sql/vector--0.1.1--0.1.3.sql .//sql/vector--0.1.3--0.1.4.sql .//sql/vector--0.1.4--0.1.5.sql .//sql/vector--0.1.5--0.1.6.sql .//sql/vector--0.1.6--0.1.7.sql .//sql/vector--0.1.7--0.1.8.sql .//sql/vector--0.1.8--0.2.0.sql .//sql/vector--0.2.0--0.2.1.sql .//sql/vector--0.2.1--0.2.2.sql .//sql/vector--0.2.2--0.2.3.sql .//sql/vector--0.2.3--0.2.4.sql .//sql/vector--0.2.4--0.2.5.sql .//sql/vector--0.2.5--0.2.6.sql .//sql/vector--0.2.6--0.2.7.sql .//sql/vector--0.2.7--0.3.0.sql .//sql/vector--0.3.0--0.3.1.sql .//sql/vector--0.3.1--0.3.2.sql .//sql/vector--0.3.2--0.4.0.sql .//sql/vector--0.4.0--0.4.1.sql .//sql/vector--0.4.1--0.4.2.sql .//sql/vector--0.4.2--0.4.3.sql .//sql/vector--0.4.3--0.4.4.sql .//sql/vector--0.4.4--0.5.0.sql .//sql/vector--0.5.0--0.5.1.sql .//sql/vector--0.5.1--0.6.0.sql .//sql/vector--0.6.0--0.6.1.sql .//sql/vector--0.6.1--0.6.2.sql .//sql/vector--0.6.2--0.7.0.sql .//sql/vector--0.7.0--0.7.1.sql .//sql/vector--0.7.1--0.7.2.sql .//sql/vector--0.7.2--0.7.3.sql .//sql/vector--0.7.3--0.7.4.sql .//sql/vector--0.7.4--0.8.0.sql .//sql/vector--0.8.0--0.8.1.sql sql/vector--0.8.1.sql '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/usr/bin/install -c -m 644   .//src/halfvec.h .//src/sparsevec.h .//src/vector.h '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/vector'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/bitutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/bitvec.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/halfutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/halfvec.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnsw.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfflat.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfkmeans.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/sparsevec.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/vector.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o vector.index.bc vector/src/bitutils.bc vector/src/bitvec.bc vector/src/halfutils.bc vector/src/halfvec.bc vector/src/hnsw.bc vector/src/hnswbuild.bc vector/src/hnswinsert.bc vector/src/hnswscan.bc vector/src/hnswutils.bc vector/src/hnswvacuum.bc vector/src/ivfbuild.bc vector/src/ivfflat.bc vector/src/ivfinsert.bc vector/src/ivfkmeans.bc vector/src/ivfscan.bc vector/src/ivfutils.bc vector/src/ivfvacuum.bc vector/src/sparsevec.bc vector/src/vector.bc\n",
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "ALTER ROLE\n",
            "NOTICE:  extension \"vector\" already exists, skipping\n",
            "CREATE EXTENSION\n"
          ]
        }
      ],
      "source": [
        "#The output of the installation is not displayed when %%capture is used at the start of the cell\n",
        "%%capture\n",
        "# Install PostgreSQL and pgvector (version-agnostic)\n",
        "!sudo apt-get -y -qq update\n",
        "!sudo apt-get -y -qq install postgresql postgresql-server-dev-all git make gcc\n",
        "\n",
        "# Build and install pgvector manually (works for any PostgreSQL version)\n",
        "!git clone --quiet https://github.com/pgvector/pgvector.git\n",
        "!cd pgvector && make && sudo make install\n",
        "\n",
        "# Start PostgreSQL service\n",
        "!sudo service postgresql start\n",
        "\n",
        "# Set password for default user\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres';\"\n",
        "\n",
        "# Create database only if it doesn't exist\n",
        "!sudo -u postgres psql -tc \"SELECT 1 FROM pg_database WHERE datname = 'sampledb'\" | grep -q 1 || \\\n",
        "sudo -u postgres psql -c \"CREATE DATABASE sampledb;\"\n",
        "\n",
        "# Enable pgvector extension in sampledb\n",
        "!sudo -u postgres psql -d sampledb -c \"CREATE EXTENSION IF NOT EXISTS vector;\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set an environment variable PG_CONN_STR with the connection string to your PostgreSQL database. This is needed for haystack."
      ],
      "metadata": {
        "id": "3YNQ1_MllrQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set connection\n",
        "import os\n",
        "os.environ[\"PG_CONN_STR\"] = \"postgresql://postgres:postgres@localhost:5432/sampledb\"\n"
      ],
      "metadata": {
        "id": "RAuddSHHl9dg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgYlL9qXfklz"
      },
      "source": [
        "## Subclassing PgvectorDocumentStore to enable websearch-style queries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why not plainto_tsquery? Why websearch_to_tsquery?\n",
        "\n",
        "plainto_tsquery transforms the unformatted text querytext to a tsquery value. The text is parsed and normalized much as for to_tsvector, then the & (AND) tsquery operator is inserted between surviving words. so all your keywords need to be present in the document.\n",
        "\n",
        "websearch_to_tsquery creates a tsquery value from querytext using an alternative syntax in which simple unformatted text is a valid query. Unlike plainto_tsquery and phraseto_tsquery, it also recognizes certain operators. Moreover, this function will never raise syntax errors, which makes it possible to use raw user-supplied input for search. The following syntax is supported:\n",
        "\n",
        "**unquoted text**: text not inside quote marks will be converted to terms separated by & operators, as if processed by plainto_tsquery.\n",
        "\n",
        "**\"quoted text\"**: text inside quote marks will be converted to terms separated by <-> operators, as if processed by phraseto_tsquery.\n",
        "\n",
        "**OR**: the word “or” will be converted to the | operator.\n",
        "\n",
        "**-**: a dash will be converted to the ! operator.\n",
        "\n"
      ],
      "metadata": {
        "id": "54XP-n3Rw3-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack_integrations.document_stores.pgvector import PgvectorDocumentStore\n",
        "from psycopg.sql import SQL, Composed, Identifier, Literal as SQLLiteral\n",
        "from typing import Dict, Any, Optional, Tuple, Union\n",
        "\n",
        "class CustomPgvectorDocumentStore(PgvectorDocumentStore):\n",
        "    def _build_keyword_retrieval_query(\n",
        "        self, query: str, top_k: int, filters: Optional[Dict[str, Any]] = None\n",
        "    ) -> Tuple[Composed, tuple]:\n",
        "\n",
        "        # Replace plainto_tsquery with websearch_to_tsquery\n",
        "        KEYWORD_QUERY_CUSTOM = \"\"\"\n",
        "        SELECT {table_name}.*, ts_rank_cd(to_tsvector({language}, content), query) AS score\n",
        "        FROM {schema_name}.{table_name}, websearch_to_tsquery({language}, %s) query\n",
        "        WHERE to_tsvector({language}, content) @@ query\n",
        "        \"\"\"\n",
        "        sql_select = SQL(KEYWORD_QUERY_CUSTOM).format(\n",
        "            schema_name=Identifier(self.schema_name),\n",
        "            table_name=Identifier(self.table_name),\n",
        "            language=SQLLiteral(self.language),\n",
        "            query=SQLLiteral(query),\n",
        "        )\n",
        "\n",
        "        where_params = ()\n",
        "        sql_where_clause: Union[Composed, SQL] = SQL(\"\")\n",
        "        if filters:\n",
        "            sql_where_clause, where_params = self._convert_filters_to_where_clause_and_params(\n",
        "                filters=filters, operator=\"AND\"\n",
        "            )\n",
        "\n",
        "        sql_sort = SQL(\" ORDER BY score DESC LIMIT {top_k}\").format(top_k=SQLLiteral(top_k))\n",
        "        sql_query = sql_select + sql_where_clause + sql_sort\n",
        "\n",
        "        return sql_query, where_params\n"
      ],
      "metadata": {
        "id": "QrLmhrf6mzCr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcWJu3pMfklz"
      },
      "source": [
        "## Use nltk to get keywords, you can use a better keyword detector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecting keywords make sure we use only the relevant words. So even if you decide to use the default implementation with plainto_tsquery which uses AND operator, you stil have better chances of not getting zero results."
      ],
      "metadata": {
        "id": "osBpnjr6xmIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download required packages"
      ],
      "metadata": {
        "id": "ioTu4XlCoy_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaYeFjEOo1jk",
        "outputId": "1c1cae98-1d9b-4d9b-f36f-2797223088e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple keyword detector"
      ],
      "metadata": {
        "id": "AMluHSWyo-nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "def extract_keywords(query: str):\n",
        "    tokens = word_tokenize(query)\n",
        "    nouns = [word for word, pos in pos_tag(tokens) if pos.startswith(\"NN\")]\n",
        "    return nouns[:5]"
      ],
      "metadata": {
        "id": "FSpsnpd0oozv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvAzR5czp6DX"
      },
      "source": [
        "## Test our implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Document\n",
        "from haystack_integrations.components.retrievers.pgvector import PgvectorKeywordRetriever\n",
        "import psycopg\n",
        "\n",
        "#use our custom store instead of PgvectorDocumentStore, that's it\n",
        "document_store = CustomPgvectorDocumentStore()\n",
        "\n",
        "#rest of the flow/pipeline will remain the same\n",
        "retriever = PgvectorKeywordRetriever(document_store=document_store,top_k = 1)\n",
        "\n",
        "document_store.write_documents([\n",
        "    Document(id = \"1\" ,content=\"My name is Jean and I live in Paris.\"),\n",
        "    Document(id = \"2\", content=\"My name is Mark and I live in Berlin.\"),\n",
        "    Document(id = \"3\", content=\"My name is Giorgio and I live in Rome.\")\n",
        "])\n",
        "\n",
        "query = \"Do you think Jean, Mayank and Alex live in Paris?\"\n",
        "keywords = extract_keywords(query)\n",
        "transformed_query =  \" OR \".join(keywords)\n",
        "print(\"transformed query\",transformed_query)\n",
        "res = retriever.run(query=transformed_query)\n",
        "print(\"result\",res)\n",
        "\n",
        "#just delete the data\n",
        "schema_name = \"public\"\n",
        "vec_table_name = \"haystack_documents\"\n",
        "vec_full_table_name = f\"{schema_name}.{vec_table_name}\"\n",
        "db_url = os.environ.get(\"PG_CONN_STR\")\n",
        "with psycopg.connect(db_url) as conn:\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(f\"TRUNCATE TABLE {vec_full_table_name} RESTART IDENTITY CASCADE;\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMVwCos0qC1Y",
        "outputId": "dc16d650-fb3d-4e55-f9aa-1bd19ac086d1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformed query Jean OR Mayank OR Alex OR Paris\n",
            "result {'documents': [Document(id=1, content: 'My name is Jean and I live in Paris.', score: 0.2)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare with default"
      ],
      "metadata": {
        "id": "Nk10BgqB5Gim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use default store\n",
        "document_store = PgvectorDocumentStore()\n",
        "\n",
        "\n",
        "retriever = PgvectorKeywordRetriever(document_store=document_store,top_k = 1)\n",
        "\n",
        "document_store.write_documents([\n",
        "    Document(id = \"1\" ,content=\"My name is Jean and I live in Paris.\"),\n",
        "    Document(id = \"2\", content=\"My name is Mark and I live in Berlin.\"),\n",
        "    Document(id = \"3\", content=\"My name is Giorgio and I live in Rome.\")\n",
        "])\n",
        "\n",
        "query = \"Do you think Jean, Mayank and Alex live in Paris?\"\n",
        "res = retriever.run(query=transformed_query)\n",
        "print(\"result\",res)\n",
        "\n",
        "#just delete the data\n",
        "schema_name = \"public\"\n",
        "vec_table_name = \"haystack_documents\"\n",
        "vec_full_table_name = f\"{schema_name}.{vec_table_name}\"\n",
        "db_url = os.environ.get(\"PG_CONN_STR\")\n",
        "with psycopg.connect(db_url) as conn:\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(f\"TRUNCATE TABLE {vec_full_table_name} RESTART IDENTITY CASCADE;\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95M4KAjQ5Fqn",
        "outputId": "030ef81c-9a8a-4e23-d958-7bf367f66f14"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result {'documents': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see the results are empty."
      ],
      "metadata": {
        "id": "BPt4uPAM5ZRE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJMFrdZ6fkl0"
      },
      "source": [
        "## About us\n",
        "\n",
        "*Leave this section as is. It's a footer that we add to all our tutorials.*\n",
        "\n",
        "\n",
        "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
        "\n",
        "We bring NLP to the industry via open source!  \n",
        "Our focus: Industry specific language models & large scale QA systems.  \n",
        "  \n",
        "Some of our other work:\n",
        "- [German BERT](https://deepset.ai/german-bert)\n",
        "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
        "\n",
        "Get in touch:\n",
        "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Discord](https://discord.com/invite/VBpFzsgRVF) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Haystack Website](https://deepset.ai)\n",
        "\n",
        "By the way: [we're hiring!](https://www.deepset.ai/jobs)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}