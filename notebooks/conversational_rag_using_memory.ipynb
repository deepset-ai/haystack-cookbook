{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmuZmn1hN3NB"
   },
   "source": [
    "# üó£Ô∏è Conversational RAG using a Chat Message Store\n",
    "\n",
    "_by [Sebastian Husch Lee](https://www.linkedin.com/in/sebastian-husch-lee) and [Vladimir Blagojevic](https://www.linkedin.com/in/blagojevicvladimir)_\n",
    "\n",
    "In this notebook, we'll show how to incorporate a conversational history into a RAG pipeline to enable multi-turn conversations with our documents, using our experimental components: `InMemoryChatMessageStore`, `ChatMessageRetriever`, and `ChatMessageWriter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LRwBMJdF_d1"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install Haystack, `haystack-experimental` and `datasets` with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQbU8GUfO-qZ"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"haystack-experimental>=0.15.0\" datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJokyTRiPifH"
   },
   "source": [
    "## Enter OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnaLI90LIhu2",
    "outputId": "8a0b2ab8-3521-43f1-f590-c6b910867ff1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Conversational Pipeline\n",
    "\n",
    "- Just show basic setup with new components plus Chat Generator to do multi-turn conversations\n",
    "- Highlight how the `chat_history_id` can be used to manage session histories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYgmgJplan3h"
   },
   "source": [
    "### Create a Chat Message Store\n",
    "\n",
    "The conversation history is saved as `ChatMessage` objects in a `InMemoryChatMessageStore`. You can retrieve the conversation history from the chat message store using `ChatMessageRetriever`.\n",
    "\n",
    "To store the conversation history, initialize an `InMemoryChatMessageStore`, a `ChatMessageRetriever` and a `ChatMessageWriter`. Import these components from the [`haystack-experimental`](https://github.com/deepset-ai/haystack-experimental) package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "M_RVnVCpaiKA"
   },
   "outputs": [],
   "source": [
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "\n",
    "# Chat History components\n",
    "message_store = InMemoryChatMessageStore()\n",
    "message_retriever = ChatMessageRetriever(memory_store)\n",
    "message_writer = ChatMessageWriter(memory_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsafe mode is enabled. This allows execution of arbitrary code in the Jinja template. Use this only if you trust the source of the template.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x15d3e9b20>\n",
       "üöÖ Components\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OpenAIChatGenerator\n",
       "  - message_retriever: ChatMessageRetriever\n",
       "  - message_writer: ChatMessageWriter\n",
       "  - message_joiner: OutputAdapter\n",
       "üõ§Ô∏è Connections\n",
       "  - prompt_builder.prompt -> message_retriever.current_messages (list[ChatMessage])\n",
       "  - prompt_builder.prompt -> message_joiner.prompt (list[ChatMessage])\n",
       "  - llm.replies -> message_joiner.replies (list[ChatMessage])\n",
       "  - message_retriever.messages -> llm.messages (list[ChatMessage])\n",
       "  - message_joiner.output -> message_writer.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.converters import OutputAdapter\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# components for RAG\n",
    "pipeline.add_component(\n",
    "    \"prompt_builder\",\n",
    "    ChatPromptBuilder(\n",
    "        template=[\n",
    "            ChatMessage.from_system(\"You are a helpful AI assistant that answers users questions.\"),\n",
    "            ChatMessage.from_user(\"{{query}}\")\n",
    "        ],\n",
    "        required_variables=\"*\"\n",
    "    )\n",
    ")\n",
    "pipeline.add_component(\"llm\", OpenAIChatGenerator())\n",
    "\n",
    "# components for chat history retrieval and storage\n",
    "pipeline.add_component(\"message_retriever\", ChatMessageRetriever(memory_store))\n",
    "pipeline.add_component(\"message_writer\", ChatMessageWriter(memory_store))\n",
    "pipeline.add_component(\n",
    "    \"message_joiner\",\n",
    "    OutputAdapter(template=\"{{ prompt + replies }}\", output_type=list[ChatMessage], unsafe=True)\n",
    ")\n",
    "\n",
    "# connections\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"message_retriever.current_messages\")\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"message_joiner.prompt\")\n",
    "pipeline.connect(\"message_retriever.messages\", \"llm.messages\")\n",
    "pipeline.connect(\"llm.replies\", \"message_joiner.replies\")\n",
    "pipeline.connect(\"message_joiner\", \"message_writer.messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba0EFLSfpwFE"
   },
   "source": [
    "### Visualize the pipeline\n",
    "\n",
    "Visualize the pipeline with the [`show()`](https://docs.haystack.deepset.ai/docs/visualizing-pipelines) method to confirm the connections are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline\n",
    "\n",
    "- Test the pipeline with some queries. \n",
    "- Ensure that in every request we add a `chat_history_id` parameter so that we know which conversational history we'd like to retrieve and write to.\n",
    "\n",
    "Here are example queries you can try:\n",
    "\n",
    "* *Describe Haystack by deepset in a few words.*\n",
    "* *What do people use it for?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Describe Haystack by deepset in a few words.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Open-source framework for document-based semantic search and question answering.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  What do people use it for?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ - Building semantic search over documents (PDFs, Word, HTML, databases) so users can find relevant passages, not just keyword matches.  \n",
      "- Question answering systems that retrieve relevant contexts and generate concise answers from corpora (RAG pipelines).  \n",
      "- Chatbots and conversational assistants that answer domain-specific questions using company knowledge bases.  \n",
      "- Enterprise knowledge bases and internal help desks (employee onboarding, policy lookup, support).  \n",
      "- Document-based summarization and long-document understanding (extract key points, generate summaries).  \n",
      "- Information extraction and QA over structured and unstructured content (contracts, medical records, invoices).  \n",
      "- Prototyping and deploying production retrieval pipelines with vector stores, embeddings, and large language models.  \n",
      "- Experimenting with and evaluating different retrievers, readers, and rerankers for research and development.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Q\n"
     ]
    }
   ],
   "source": [
    "chat_history_id = \"user_123_session_1\"\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter your question or Q to exit.\\nüßë \")\n",
    "    if question == \"Q\":\n",
    "        break\n",
    "\n",
    "    res = pipeline.run(\n",
    "        data={\n",
    "            \"prompt_builder\": {\"query\": question},\n",
    "            \"message_retriever\": {\"chat_history_id\": chat_history_id},\n",
    "            \"message_writer\": {\"chat_history_id\": chat_history_id},\n",
    "        },\n",
    "        include_outputs_from={\"llm\"}\n",
    "    )\n",
    "    print(f'ü§ñ {res[\"llm\"][\"replies\"][0].text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching to a New Chat Session\n",
    "- Now we can update the `chat_history_id` to change to a new chat session with an empty chat history\n",
    "\n",
    "Here are example queries you can try:\n",
    "\n",
    "* *When was it published?*\n",
    "* *When was Haystack the open source framework by deepset published?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  How old is it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ I‚Äôm missing what ‚Äúit‚Äù refers to ‚Äî can you tell me what object or thing you mean? \n",
      "\n",
      "Here are quick ways to find the age for common items; tell me which one matches and any details (photo, serial/model number, label, date stamp, location, etc.) and I‚Äôll help more precisely:\n",
      "\n",
      "- Electronics (phones, laptops, appliances): check model/serial number, manufacture date on label, warranty/receipt, or EXIF/firmware info.\n",
      "- Cars/motorcycles: decode the VIN (manufacture year is embedded) or check title/registration.\n",
      "- Clothing/shoes: look for care tags, brand seasonal codes, or provenance/receipt.\n",
      "- Furniture/antiques: maker‚Äôs mark/stamps, construction techniques, joinery, or consult an appraiser.\n",
      "- Documents/photos: check metadata/EXIF or printed/handwritten dates; paper/ink analysis for older items.\n",
      "- People/pets: birth certificate, vaccination records, or vet exam/teeth estimate for animals.\n",
      "- Trees/wood: count rings in a cross-section or use an increment borer; dendrochronology for precision.\n",
      "- Archaeological artifacts/fossils: radiocarbon dating, stratigraphy, or professional lab analysis.\n",
      "\n",
      "Tell me what ‚Äúit‚Äù is and any identifiers or photos and I‚Äôll walk through how to determine the age.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  How old is Haystack?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Which \"Haystack\" do you mean? A few common ones:\n",
      "\n",
      "- Haystack Rock (the sea stack at Cannon Beach, OR)\n",
      "- Haystack Observatory (MIT Haystack Observatory in Massachusetts)\n",
      "- Haystack Mountain (there are several ‚Äî e.g., Vermont, Colorado)\n",
      "- Haystack (a company, app, or other organization)\n",
      "- Something else (a person, pet, building, etc.)\n",
      "\n",
      "Tell me which one or paste a photo/link or any other detail and I‚Äôll give the age or how to find it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Haystack by deepset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Do you mean the open‚Äësource Haystack project from deepset (the NLP/RAI framework)? If so ‚Äî I can show you exactly how to find its creation/release date. Quick summary: Haystack was first published around 2019‚Äì2020, so it‚Äôs roughly 5‚Äì6 years old as of late 2025.\n",
      "\n",
      "If you want the exact date, run one of these:\n",
      "\n",
      "- GitHub API (gives repo creation timestamp)\n",
      "  curl -s https://api.github.com/repos/deepset-ai/haystack | jq .created_at\n",
      "\n",
      "- Or clone and check the first commit date (shows when development started)\n",
      "  git clone https://github.com/deepset-ai/haystack.git\n",
      "  cd haystack\n",
      "  git log --reverse --format=%ai | head -n1\n",
      "\n",
      "- Or check the first PyPI release date (if you care about the first published package)\n",
      "  curl -s https://pypi.org/pypi/farm-haystack/json | jq '.releases | keys[0]'\n",
      "\n",
      "Tell me if you want me to look up the exact date for you (and whether you mean the GitHub repo, the first PyPI release, or something else) ‚Äî I‚Äôll give the precise age.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Q\n"
     ]
    }
   ],
   "source": [
    "# Update the chat history ID\n",
    "chat_history_id = \"user_123_session_2\"\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter your question or Q to exit.\\nüßë \")\n",
    "    if question == \"Q\":\n",
    "        break\n",
    "\n",
    "    res = pipeline.run(\n",
    "        data={\n",
    "            \"prompt_builder\": {\"query\": question},\n",
    "            \"message_retriever\": {\"chat_history_id\": chat_history_id},\n",
    "            \"message_writer\": {\"chat_history_id\": chat_history_id},\n",
    "        },\n",
    "        include_outputs_from={\"llm\"}\n",
    "    )\n",
    "    print(f'ü§ñ {res[\"llm\"][\"replies\"][0].text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational RAG Pipeline\n",
    "\n",
    "- This is to highlight how we can incorporate RAG into our conversational pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avfIcgYlP5BE"
   },
   "source": [
    "### Create a Document Store and Index Documents\n",
    "\n",
    "Create an index with [seven-wonders](https://huggingface.co/datasets/bilgeyucel/seven-wonders) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235,
     "referenced_widgets": [
      "73a190ad645f424595ed510b0a065f6c",
      "a0595172cf69419da8906519b67044fc",
      "de6320ec52bd428481cc2c3d5a0cc990",
      "178c72eb13ea4713b61f78d6e23845ac",
      "ad90be66bdc04459aad56d18ae06053d",
      "dc62faede541456693b9f04b014f903e",
      "36ca73d9350e4a1c8074c0f774a54990",
      "322220538e2e468c8ec1d1a394b1e468",
      "4b3ae1c3a76a4fbda2515fc1dc2f7fab",
      "4584e2f8a56b4c8aba7bc3ac83fcf465",
      "e3731778144a4dbd994b4fb69964c8fc",
      "21362aa8df4442a29896367d6cf67e00",
      "437ab0f7e2504928a4b11eea3c294876",
      "882c76f6986d4e4fb91f67d82332ccf3",
      "e9dbe0e711c942feb0d4c317f501352a",
      "c929a3d83e9d4309b7c9485e11608a64",
      "6749eb3bb0e94942b7e9e096e62ec8cb",
      "1d541df644074f5fa44628daf3b5bb0f",
      "b294f69f8aa64e448cff87a12b473a40",
      "13777155bedb426196506e9f99a0e58b",
      "fb40fd788e234340a5ea5a67a1468633",
      "ce31567067f54dcdb7e76996a1f85711",
      "57c6e81875754b20b20ded8242b3416f",
      "5da9420916f24ac8b414f40bd2bf9278",
      "87e0f724cfd342a696a9a472e6cae440",
      "649c0abcb8ae4028b982c67b8c25d49b",
      "4eafb4852c0b465b98bc9aa714a65c55",
      "bf44c3ba864e4b06a6c7ce99175b6f76",
      "8f5ebd3d7c9a4937a80e4732a4421306",
      "edf1188e561b44089d1f33a4ab06da2d",
      "67c1e3a03d8a4cc3aa1f306aeacbf7d3",
      "5e1c026cacd146c5b865407e65fa3da4",
      "ca7fcb3a93154a0ab91ffd440a5eec07"
     ]
    },
    "id": "E1LKl2TmFuzs",
    "outputId": "0dbe2798-cf10-4768-994c-3c3fc61bd2c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Document\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "document_store.write_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCOdSoAAQBb6"
   },
   "source": [
    "### Build the Pipeline\n",
    "\n",
    "- Add components for RAG and chat history retreival and storage to build your pipeline.\n",
    "- Incorporate an `OutputAdapter` component into your pipeline to handle messages from both the user and the LLM, writing them to the memory store.\n",
    "- The previous conversation history will be retrieved by `ChatMessageRetriever` from the `InMemoryChatMessageStore` given a `chat_history_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SkN-lRUa4_i",
    "outputId": "dd6fcb9a-12ca-4a56-c909-4d679d1707e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsafe mode is enabled. This allows execution of arbitrary code in the Jinja template. Use this only if you trust the source of the template.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x15d7139b0>\n",
       "üöÖ Components\n",
       "  - doc_retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OpenAIChatGenerator\n",
       "  - message_retriever: ChatMessageRetriever\n",
       "  - message_writer: ChatMessageWriter\n",
       "  - message_joiner: OutputAdapter\n",
       "üõ§Ô∏è Connections\n",
       "  - doc_retriever.documents -> prompt_builder.documents (list[Document])\n",
       "  - prompt_builder.prompt -> message_retriever.current_messages (list[ChatMessage])\n",
       "  - prompt_builder.prompt -> message_joiner.prompt (list[ChatMessage])\n",
       "  - llm.replies -> message_joiner.replies (list[ChatMessage])\n",
       "  - message_retriever.messages -> llm.messages (list[ChatMessage])\n",
       "  - message_joiner.output -> message_writer.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.converters import OutputAdapter\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Create the system and user message\n",
    "system_message = ChatMessage.from_system(\n",
    "    \"You are a helpful AI assistant that answers users questions grounded in a set supporting documents.\"\n",
    ")\n",
    "user_message_template =\"\"\"Give a brief answer to the question grounded in the supporting documents.\n",
    "If question can't be answered from supporting documents, say so.\n",
    "\n",
    "Supporting documents:\n",
    "{%- if documents|length > 0 %}\n",
    "{%- for doc in documents %}\n",
    "Document [{{ loop.index }}] :\n",
    "{{ doc.content }}\n",
    "{% endfor -%}\n",
    "{%- else %}\n",
    "No relevant documents found.\n",
    "{% endif %}\n",
    "\n",
    "Question: {{query}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "user_message = ChatMessage.from_user(user_message_template)\n",
    "\n",
    "# components for RAG\n",
    "pipeline.add_component(\"doc_retriever\", InMemoryBM25Retriever(document_store=document_store, top_k=3))\n",
    "pipeline.add_component(\n",
    "    \"prompt_builder\", ChatPromptBuilder(template=[system_message, user_message], required_variables=\"*\")\n",
    ")\n",
    "pipeline.add_component(\"llm\", OpenAIChatGenerator())\n",
    "\n",
    "# components for chat history retrieval and storage\n",
    "pipeline.add_component(\"message_retriever\", ChatMessageRetriever(memory_store))\n",
    "pipeline.add_component(\"message_writer\", ChatMessageWriter(memory_store))\n",
    "pipeline.add_component(\n",
    "    \"message_joiner\",\n",
    "    OutputAdapter(template=\"{{ prompt + replies }}\", output_type=list[ChatMessage], unsafe=True)\n",
    ")\n",
    "\n",
    "# connections\n",
    "pipeline.connect(\"doc_retriever.documents\", \"prompt_builder.documents\")\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"message_retriever.current_messages\")\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"message_joiner.prompt\")\n",
    "pipeline.connect(\"message_retriever.messages\", \"llm.messages\")\n",
    "pipeline.connect(\"llm.replies\", \"message_joiner.replies\")\n",
    "pipeline.connect(\"message_joiner\", \"message_writer.messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWBPo5VbcOck"
   },
   "source": [
    "### Run the Pipeline\n",
    "\n",
    "Test the pipeline with some queries. Here are example queries you can try:\n",
    "\n",
    "* *What does Rhodes Statue look like?*\n",
    "* *Who built it?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tZI94Ocbgcz",
    "outputId": "2f2f498f-2653-427e-be76-d7c52484a01f"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  What does Rhodes Statue look like?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Scholars do not know the Colossus‚Äô full appearance. It represented Helios; the head and face are thought to have had curly hair with evenly spaced bronze or silver spikes (a radiating ‚Äúsun‚Äù crown) like images on contemporary Rhodian coins. Anecdotes of it straddling the harbour lack historical/scientific support.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Who built it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Which monument do you mean?\n",
      "\n",
      "- Hanging Gardens of Babylon: legend credits Neo‚ÄëBabylonian King Nebuchadnezzar II.  \n",
      "- Mausoleum at Halicarnassus: it was the tomb of Mausolus ‚Äî construction was begun by/for Mausolus (continued after his death) and, per Vitruvius, built by the architects Satyros and Pytheus (and traditionally finished by his wife).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Q\n"
     ]
    }
   ],
   "source": [
    "chat_history_id = \"user_123_session_3\"\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter your question or Q to exit.\\nüßë \")\n",
    "    if question == \"Q\":\n",
    "        break\n",
    "\n",
    "    res = pipeline.run(\n",
    "        data={\n",
    "            \"doc_retriever\": {\"query\": question},\n",
    "            \"prompt_builder\": {\"query\": question},\n",
    "            \"message_retriever\": {\"chat_history_id\": chat_history_id},\n",
    "            \"message_writer\": {\"chat_history_id\": chat_history_id},\n",
    "        },\n",
    "        include_outputs_from={\"llm\"}\n",
    "    )\n",
    "    print(f'ü§ñ {res[\"llm\"][\"replies\"][0].text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "felG4tdtcSpP"
   },
   "source": [
    "‚ö†Ô∏è If you followed the example queries, you'll notice that the second question was answered incorrectly. This happened because the retrieved documents weren't relevant to the user's query. The retrieval was based on the query \"*Who built it?*\", which doesn't have enough context to retrieve the relevant documents.\n",
    "\n",
    "Let's fix this by using an **Agent** equipped with a RAG tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Agent with a RAG Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoNwSoFIsdGf"
   },
   "source": [
    "### Create RAG Tool\n",
    "\n",
    "In conversational systems, simply pre-pending the chat history to the new user message is not enough to perform RAG effectively. There needs to be a mechanism to rephrase the user's query based on the conversation history to ensure relevant documents are retrieved. For instance, if the first user query is \"*What's the first name of Einstein?*\" and the second query is \"*Where was he born?*\", the system should understand that \"he\" refers to Einstein. The rephrasing mechanism should then modify the second query to \"*Where was Einstein born?*\" to retrieve the correct documents.\n",
    "\n",
    "We can use an Agent to call its RAG tool with a rephrased version of the user's query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ElRIAJ_smRFb"
   },
   "outputs": [],
   "source": [
    "query_rephrase_template = \"\"\"\n",
    "Rewrite the question for search while keeping its meaning and key terms intact.\n",
    "If there is no conversation history, DO NOT change the query.\n",
    "Use conversation history only if necessary, and avoid extending the query with your own knowledge.\n",
    "If no changes are needed, output the current question as is.\n",
    "\n",
    "User Query: {{query}}\n",
    "Rewritten Query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTUkl594ejnK"
   },
   "source": [
    "### Build the Conversational Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3q0vLO1GLNL",
    "outputId": "e64d3b4d-bbeb-46f4-945d-0e516c1639fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x15e39af30>\n",
       "üöÖ Components\n",
       "  - agent: Agent\n",
       "  - message_retriever: ChatMessageRetriever\n",
       "  - message_writer: ChatMessageWriter\n",
       "üõ§Ô∏è Connections\n",
       "  - agent.messages -> message_writer.messages (list[ChatMessage])\n",
       "  - message_retriever.messages -> agent.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.agents import Agent\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.tools import PipelineTool\n",
    "from haystack.components.generators.utils import print_streaming_chunk\n",
    "\n",
    "# Build the RAG Tool\n",
    "rag_pipeline = Pipeline()\n",
    "\n",
    "rag_pipeline.add_component(\n",
    "    \"doc_retriever\", InMemoryBM25Retriever(document_store=document_store, top_k=3)\n",
    ")\n",
    "rag_pipeline.add_component(\n",
    "    \"builder\",\n",
    "    PromptBuilder(\n",
    "        template=\"\"\"Supporting documents:\n",
    "{%- if documents|length > 0 %}\n",
    "{%- for doc in documents %}\n",
    "Document [{{ loop.index }}] :\n",
    "{{ doc.content }}\n",
    "{% endfor -%}\n",
    "{%- else %}\n",
    "No relevant documents found.\n",
    "{% endif %}\"\"\",\n",
    "        required_variables=\"*\"\n",
    "    )\n",
    ")\n",
    "\n",
    "rag_pipeline.connect(\"doc_retriever.documents\", \"builder.documents\")\n",
    "\n",
    "rag_tool = PipelineTool(\n",
    "    pipeline=rag_pipeline,\n",
    "    name=\"rag_tool\",\n",
    "    description=\"A tool for fetching information on the seven wonders of the ancient world.\",\n",
    "    input_mapping={\"query\": [\"doc_retriever.query\"]},\n",
    "    output_mapping={\"builder.prompt\": \"rag_output\"},\n",
    ")\n",
    "\n",
    "# Build the Agent\n",
    "conversational_agent = Pipeline()\n",
    "\n",
    "conversational_agent.add_component(\n",
    "    \"agent\",\n",
    "    Agent(\n",
    "        system_prompt=\"\"\"You are a helpful AI assistant that answers users questions grounded in a set supporting documents.\n",
    "If any questions are asked about the seven wonders always use the `rag_tool` to fetch supporting documents.\n",
    "Stay concise in your answers.\n",
    "\"\"\",\n",
    "        chat_generator=OpenAIChatGenerator(),\n",
    "        tools=[rag_tool],\n",
    "        streaming_callback=print_streaming_chunk,\n",
    "    )\n",
    ")\n",
    "\n",
    "# components for chat history storage and retrieval\n",
    "conversational_agent.add_component(\"message_retriever\", ChatMessageRetriever(memory_store))\n",
    "conversational_agent.add_component(\"message_writer\", ChatMessageWriter(memory_store))\n",
    "\n",
    "# connections for Agent\n",
    "conversational_agent.connect(\"message_retriever.messages\", \"agent.messages\")\n",
    "conversational_agent.connect(\"agent.messages\", \"message_writer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmtRP897RgOc"
   },
   "source": [
    "### Let's have a conversation üòÄ\n",
    "\n",
    "Now, run the pipeline with the relevant inputs.\n",
    "\n",
    "Here are some example queries and follow ups you can try:\n",
    "\n",
    "* *What does Rhodes Statue look like?* - *Who built it?* - *Did he destroy it?*\n",
    "* *Where is Gardens of Babylon?* - *When was it built?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scx_J3jr3f7q",
    "outputId": "bd81d796-3763-47bc-97a4-3769f2960a5f"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  What does Rhodes Statue look like?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOOL CALL]\n",
      "Tool: rag_tool \n",
      "Arguments: {\"query\":\"Colossus of Rhodes appearance description Helios statue pose torch crown straddling harbour ancient sources\"}\n",
      "\n",
      "[TOOL RESULT]\n",
      "{'rag_output': 'Supporting documents:\\nDocument [1] :\\nAlso, the fallen statue would have blocked the harbour, and since the ancient Rhodians did not have the ability to remove the fallen statue from the harbour, it would not have remained visible on land for the next 800 years, as discussed above. Even neglecting these objections, the statue was made of bronze, and engineering analyses indicate that it could not have been built with its legs apart without collapsing under its own weight.[29]\\nMany researchers have considered alternative positions for the statue which would have made it more feasible for actual construction by the ancients.[29][30] There is also no evidence that the statue held a torch aloft; the records simply say that after completion, the Rhodians kindled the \"torch of freedom\". A relief in a nearby temple shows Helios standing with one hand shielding his eyes, similar to the way a person shields their eyes when looking toward the sun, and it is quite possible that the colossus was constructed in the same pose.\\n\\n\\n\\nDocument [2] :\\nThe Colossus of Rhodes (Ancient Greek: ·ΩÅ ŒöŒøŒªŒøœÉœÉ·Ω∏œÇ ·ø¨œåŒ¥ŒπŒøœÇ, romanized:\\xa0ho Koloss√≤s Rh√≥dios Greek: ŒöŒøŒªŒøœÉœÉœåœÇ œÑŒ∑œÇ Œ°œåŒ¥ŒøœÖ, romanized:\\xa0Koloss√≥s tes Rh√≥dou)[a] was a statue of the Greek sun-god Helios, erected in the city of Rhodes, on the Greek island of the same name, by Chares of Lindos in 280\\xa0BC. One of the Seven Wonders of the Ancient World, it was constructed to celebrate the successful defence of Rhodes city against an attack by Demetrius Poliorcetes, who had besieged it for a year with a large army and navy.\\nAccording to most contemporary descriptions, the Colossus stood approximately 70 cubits, or 33 metres (108 feet) high ‚Äì approximately the height of the modern Statue of Liberty from feet to crown ‚Äì making it the tallest statue in the ancient world.[2] It collapsed during the earthquake of 226 BC, although parts of it were preserved. In accordance with a certain oracle, the Rhodians did not build it again.[3] John Malalas wrote that Hadrian in his reign re-erected the Colossus,[4] but he was mistaken.[5] According to the Suda, the Rhodians were called Colossaeans (ŒöŒøŒªŒøœÉœÉŒ±Œµ·øñœÇ), because they erected the statue on the island.\\n\\nDocument [3] :\\nSilver tetradrachm of Rhodes showing Helios and a rose (205‚Äì190 BC, 13.48 g)\\nWhile scholars do not know what the statue looked like, they do have a good idea of what the head and face looked like, as it was of a standard rendering at the time. The head would have had curly hair with evenly spaced spikes of bronze or silver flame radiating, similar to the images found on contemporary Rhodian coins.[29]\\n\\nPossible locations[edit]\\nThe old harbour entrance from inner embankment. The Fortress of St Nicholas is on right\\nWhile scholars generally agree that anecdotal depictions of the Colossus straddling the harbour\\'s entry point have no historic or scientific basis,[29] the monument\\'s actual location remains a matter of debate. As mentioned above the statue is thought locally to have stood where two pillars now stand at the Mandraki port entrance.\\nThe floor of the Fortress of St Nicholas, near the harbour entrance, contains a circle of sandstone blocks of unknown origin or purpose. \\n'}\n",
      "\n",
      "[ASSISTANT]\n",
      "Short answer\n",
      "- The Colossus of Rhodes was a huge bronze statue of the sun‚Äëgod Helios, about 33 m (‚âà108 ft) tall ‚Äî roughly the Statue of Liberty‚Äôs height from feet to crown.\n",
      "\n",
      "What it likely looked like\n",
      "- A standing, life‚Äësize (very large) bronze figure of Helios, usually shown with curly hair and a radiating solar crown (spikes of bronze or silver like flames, seen on Rhodian coins).  \n",
      "- The head/face followed a standard contemporary type; a nearby relief shows Helios with one hand shading his eyes, and the Colossus may have been posed similarly (looking toward the sea).  \n",
      "- There is no reliable ancient evidence that it straddled the harbour or held a torch aloft; those are later dramatizations and are considered unlikely.\n",
      "\n",
      "Key facts\n",
      "- Erected in 280 BC by Chares of Lindos, stood ~54 years, and collapsed in the 226 BC earthquake. The exact pose and precise appearance are not securely recorded, so modern reconstructions vary.\n",
      "\n",
      "If you want, I can show common artistic reconstructions and point out which details are well supported and which are speculative.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Who built it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOOL CALL]\n",
      "Tool: rag_tool \n",
      "Arguments: {\"query\":\"Who built the Colossus of Rhodes Chares of Lindos builder 280 BC\"}\n",
      "\n",
      "[TOOL RESULT]\n",
      "{'rag_output': \"Supporting documents:\\nDocument [1] :\\nThe Colossus of Rhodes (Ancient Greek: ·ΩÅ ŒöŒøŒªŒøœÉœÉ·Ω∏œÇ ·ø¨œåŒ¥ŒπŒøœÇ, romanized:\\xa0ho Koloss√≤s Rh√≥dios Greek: ŒöŒøŒªŒøœÉœÉœåœÇ œÑŒ∑œÇ Œ°œåŒ¥ŒøœÖ, romanized:\\xa0Koloss√≥s tes Rh√≥dou)[a] was a statue of the Greek sun-god Helios, erected in the city of Rhodes, on the Greek island of the same name, by Chares of Lindos in 280\\xa0BC. One of the Seven Wonders of the Ancient World, it was constructed to celebrate the successful defence of Rhodes city against an attack by Demetrius Poliorcetes, who had besieged it for a year with a large army and navy.\\nAccording to most contemporary descriptions, the Colossus stood approximately 70 cubits, or 33 metres (108 feet) high ‚Äì approximately the height of the modern Statue of Liberty from feet to crown ‚Äì making it the tallest statue in the ancient world.[2] It collapsed during the earthquake of 226 BC, although parts of it were preserved. In accordance with a certain oracle, the Rhodians did not build it again.[3] John Malalas wrote that Hadrian in his reign re-erected the Colossus,[4] but he was mistaken.[5] According to the Suda, the Rhodians were called Colossaeans (ŒöŒøŒªŒøœÉœÉŒ±Œµ·øñœÇ), because they erected the statue on the island.\\n\\nDocument [2] :\\n[6]\\nIn 653, an Arab force under Muslim general Muawiyah I conquered Rhodes, and according to the Chronicle of Theophanes the Confessor,[7] the statue was completely destroyed and the remains sold;[8] this account may be unreliable.[9]\\nSince 2008, a series of as-yet-unrealized proposals to build a new Colossus at Rhodes Harbour have been announced, although the actual location of the original monument remains in dispute.[10][11]\\n\\nSiege of Rhodes[edit]\\nMain article: Siege of Rhodes (305‚Äì304\\xa0BC)\\nIn the early fourth century BC, Rhodes, allied with Ptolemy I of Egypt, prevented a mass invasion staged by their common enemy, Antigonus I Monophthalmus.\\nIn 304\\xa0BC a relief force of ships sent by Ptolemy arrived, and Demetrius (son of Antigonus) and his army abandoned the siege, leaving behind most of their siege equipment. To celebrate their victory, the Rhodians sold the equipment left behind for 300 talents[12] and decided to use the money to build a colossal statue of their patron god, Helios. Construction was left to the direction of Chares, a native of Lindos in Rhodes, who had been involved with large-scale statues before. His teacher, the sculptor Lysippos, had constructed a 22-metre-high (72-foot)[13] bronze statue of Zeus at Tarentum.\\n\\n\\n\\nDocument [3] :\\nConstruction[edit]\\nTimeline and map of the Seven Wonders of the Ancient World, including the Colossus of Rhodes\\nConstruction began in 292\\xa0BC. Ancient accounts, which differ to some degree, describe the structure as being built with iron tie bars to which brass plates were fixed to form the skin. The interior of the structure, which stood on a 15-metre-high (49-foot) white marble pedestal near the Rhodes harbour entrance, was then filled with stone blocks as construction progressed.[14] Other sources place the Colossus on a breakwater in the harbour. According to most contemporary descriptions, the statue itself was about 70 cubits, or 32 metres (105 feet) tall.[15] Much of the iron and bronze was reforged from the various weapons Demetrius's army left behind, and the abandoned second siege tower may have been used for scaffolding around the lower levels during construction.\\n\\n\"}\n",
      "\n",
      "[ASSISTANT]\n",
      "The Colossus of Rhodes was built under the direction of the sculptor Chares of Lindos. Construction began around 292 BC and the finished bronze statue was erected about 280 BC [Document 1; Document 3].\n",
      "\n",
      "Brief context: the project used bronze and iron reworked from the siege equipment left by Demetrius‚Äôs army after the Siege of Rhodes, and Chares ‚Äî a pupil of the sculptor Lysippos ‚Äî oversaw the work [Document 2; Document 3].\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question or Q to exit.\n",
      "üßë  Q\n"
     ]
    }
   ],
   "source": [
    "chat_history_id = \"user_123_session_4\"\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter your question or Q to exit.\\nüßë \")\n",
    "    if question == \"Q\":\n",
    "        break\n",
    "\n",
    "    conversational_agent.run(\n",
    "        data={\n",
    "            \"message_retriever\": {\"current_messages\": [ChatMessage.from_user(question)], \"chat_history_id\": chat_history_id},\n",
    "            \"message_writer\": {\"chat_history_id\": chat_history_id}\n",
    "        }\n",
    "    )\n",
    "    # No need to print the output since we are streaming it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crZGcWUfizPp"
   },
   "source": [
    "‚úÖ Notice that this time, with the help of query rephrasing, we've built a conversational RAG pipeline that can handle follow-up queries and retrieve the relevant documents."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13777155bedb426196506e9f99a0e58b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "178c72eb13ea4713b61f78d6e23845ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4584e2f8a56b4c8aba7bc3ac83fcf465",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e3731778144a4dbd994b4fb69964c8fc",
      "value": "‚Äá46.0/46.0‚Äá[00:00&lt;00:00,‚Äá2.23kB/s]"
     }
    },
    "1d541df644074f5fa44628daf3b5bb0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21362aa8df4442a29896367d6cf67e00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_437ab0f7e2504928a4b11eea3c294876",
       "IPY_MODEL_882c76f6986d4e4fb91f67d82332ccf3",
       "IPY_MODEL_e9dbe0e711c942feb0d4c317f501352a"
      ],
      "layout": "IPY_MODEL_c929a3d83e9d4309b7c9485e11608a64"
     }
    },
    "322220538e2e468c8ec1d1a394b1e468": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36ca73d9350e4a1c8074c0f774a54990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "437ab0f7e2504928a4b11eea3c294876": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6749eb3bb0e94942b7e9e096e62ec8cb",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1d541df644074f5fa44628daf3b5bb0f",
      "value": "(‚Ä¶)-00000-of-00001-4077bd623d55100a.parquet:‚Äá100%"
     }
    },
    "4584e2f8a56b4c8aba7bc3ac83fcf465": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b3ae1c3a76a4fbda2515fc1dc2f7fab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4eafb4852c0b465b98bc9aa714a65c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57c6e81875754b20b20ded8242b3416f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5da9420916f24ac8b414f40bd2bf9278",
       "IPY_MODEL_87e0f724cfd342a696a9a472e6cae440",
       "IPY_MODEL_649c0abcb8ae4028b982c67b8c25d49b"
      ],
      "layout": "IPY_MODEL_4eafb4852c0b465b98bc9aa714a65c55"
     }
    },
    "5da9420916f24ac8b414f40bd2bf9278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf44c3ba864e4b06a6c7ce99175b6f76",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8f5ebd3d7c9a4937a80e4732a4421306",
      "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
     }
    },
    "5e1c026cacd146c5b865407e65fa3da4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "649c0abcb8ae4028b982c67b8c25d49b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e1c026cacd146c5b865407e65fa3da4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ca7fcb3a93154a0ab91ffd440a5eec07",
      "value": "‚Äá151/151‚Äá[00:00&lt;00:00,‚Äá1979.58‚Äáexamples/s]"
     }
    },
    "6749eb3bb0e94942b7e9e096e62ec8cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67c1e3a03d8a4cc3aa1f306aeacbf7d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73a190ad645f424595ed510b0a065f6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0595172cf69419da8906519b67044fc",
       "IPY_MODEL_de6320ec52bd428481cc2c3d5a0cc990",
       "IPY_MODEL_178c72eb13ea4713b61f78d6e23845ac"
      ],
      "layout": "IPY_MODEL_ad90be66bdc04459aad56d18ae06053d"
     }
    },
    "87e0f724cfd342a696a9a472e6cae440": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edf1188e561b44089d1f33a4ab06da2d",
      "max": 151,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67c1e3a03d8a4cc3aa1f306aeacbf7d3",
      "value": 151
     }
    },
    "882c76f6986d4e4fb91f67d82332ccf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b294f69f8aa64e448cff87a12b473a40",
      "max": 118915,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13777155bedb426196506e9f99a0e58b",
      "value": 118915
     }
    },
    "8f5ebd3d7c9a4937a80e4732a4421306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0595172cf69419da8906519b67044fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc62faede541456693b9f04b014f903e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_36ca73d9350e4a1c8074c0f774a54990",
      "value": "README.md:‚Äá100%"
     }
    },
    "ad90be66bdc04459aad56d18ae06053d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b294f69f8aa64e448cff87a12b473a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf44c3ba864e4b06a6c7ce99175b6f76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c929a3d83e9d4309b7c9485e11608a64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca7fcb3a93154a0ab91ffd440a5eec07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce31567067f54dcdb7e76996a1f85711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc62faede541456693b9f04b014f903e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6320ec52bd428481cc2c3d5a0cc990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_322220538e2e468c8ec1d1a394b1e468",
      "max": 46,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b3ae1c3a76a4fbda2515fc1dc2f7fab",
      "value": 46
     }
    },
    "e3731778144a4dbd994b4fb69964c8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9dbe0e711c942feb0d4c317f501352a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb40fd788e234340a5ea5a67a1468633",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ce31567067f54dcdb7e76996a1f85711",
      "value": "‚Äá119k/119k‚Äá[00:00&lt;00:00,‚Äá2.54MB/s]"
     }
    },
    "edf1188e561b44089d1f33a4ab06da2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb40fd788e234340a5ea5a67a1468633": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
